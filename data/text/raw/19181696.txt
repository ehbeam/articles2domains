
 properties manuscript? 
 
 
 9110718 
 2171 
 Cereb Cortex 
 Cerebral cortex (New York, N.Y. : 1991) 
 1047-3211 
 1460-2199 
 
 
 19181696 
 2722428 
 10.1093/cercor/bhn239 
 NIHMS92517 
 
 
 Article 
 
 
 
 From Phonemes to Articulatory scores: an fMRI study on the role of Broca’s area in speech production 
 
 
 
 
 Papoutsi 
 Marina 
 
 
 
 
 De Zwart 
 Jacco 
 
 
 
 
 Jansma 
 Martijn 
 
 
 
 
 Pickering 
 Martin 
 
 
 
 
 Bednar 
 James 
 
 
 
 
 Horwitz 
 Barry 
 
 
 
 
 2 
 2 
 2009 
 
 
 29 
 1 
 2009 
 
 
 9 
 2009 
 
 
 1 
 9 
 2010 
 
 19 
 9 
 2156 
 2165 
 
 
 This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law. 
 
 
 
 We used event-related functional magnetic resonance imaging to investigate the neuroanatomical substrates of phonetic encoding and the generation of articulatory codes from abstract phonological representations. Our focus was on the role of the left Inferior Frontal Gyrus (L IFG) and in particular whether the L IFG is part of the mechanism responsible for sub-lexical phonological processing such as syllabification and segmentation or whether it is directly involved in a sensory-motor mapping and the generation of articulatory codes, either by being the site of storage for the codes or by being involved in the mechanism of generating the codes. To answer this question we compared high vs. low frequency pseudowords, which we expected would only activate areas related to the generation of the articulatory codes, but areas related to phonological segmentation. We found activation of a premotor network consisting of the dorsal Precentral Gyrus, the IFG bilaterally and the Supplementary Motor Area for low vs. high frequency words. Our findings support the role of the posterior L IFG in sensory-motor mapping, but also provide evidence to support a further functional segregation of the posterior part of Broca’s Area, the pars Opercularis. We further discuss the meaning and significance of the findings. 
 
 
 Broca’s area 
 phonological processing 
 articulation 
 fMRI 
 pars Opercularis 
 
 
 
 
 Introduction 
 Speech has meaning, but it also has form to support and express the meaning. At the level of the word form successful articulation consists of correctly generating an appropriate articulatory plan. Thus, an abstract, internal representation of a word, a phonological representation, is transformed into an articulatory representation. This transformation is by no means simple. It involves at least two layers of representation, phonological and phonetic encoding, and the engagement of a wide perisylvian network in the cerebrum before it reaches the final form of the articulatory code ( Indefrey and W.J.M Levelt 2000 ;  Hickok and Poeppel 2004 ). There is a large consent that the posterior portion of the left hemisphere Inferior Frontal Gyrus (L IFG), also known as Broca’s area, and in particular its pars Opercularis, is one of the areas involved in the generation of the articulatory code. However, the precise role of the region in the process is still a matter of debate. In this study, we investigated the processes related to the transformation of phonemic representations to gestural patterns and particularly the role of Broca’s area. 
 The precise processes that lead to the generation of an articulatory motor plan are a matter of debate amongst researchers; as is the timing and interaction between these processes ( Goldrick and Rapp 2007 ). Irrespective of the precise details, it is commonly accepted that prior to the generation of an articulatory motor plan syllabic, metrical and featural (even if just the non-redundant ones) information have been specified in a phonological representation to facilitate the generation of the motor plan ( Levelt 1999 ). What is of interest is the question which cortical areas are involved in the generation of the phonological representation and which are involved in the generation of the articulatory representation. Once the cortical network has been specified examining the temporal characteristics of the regions could shed more light on the timing and interaction of the processes. 
 In an extended review of studies on word production by Indefrey and Levelt ( Indefrey and W.J.M Levelt 2000 ;  Indefrey and W. J M Levelt 2004 ) it was suggested that in the final stages prior to phonetic encoding and the generation of the articulatory representation, the retrieved phonological code is spelled-out into its different phonemic segments, incrementally clustered into syllables and assigned a metrical structure. As syllables are created, they are also rapidly turned into sequences of motor gestures, also know as gestural scores ( Browman and Goldstein 1988 ). For example, if one wanted to produce the noun ‘cat’, after retrieving the phonological form of the word and separating it into segments, i.e. /k h / /æ/ /t/, the segments would then be clustered together to create a syllable. For each syllable a gestural code is then either retrieved or compiled and articulation can begin as soon as the first syllable is fully phonetically encoded ( Bachoud-Lévi et al. 1998 ). In this account of word production syllables are the fundamental units in constructing the articulatory representation and it is also assumed that there is a different mechanism in dealing with high and low frequency syllables. Based on the notion that speakers tend to re-use only a small number of syllables and on evidence that pseudowords with high frequency (onset) syllables are faster to produce than their low frequency counterparts ( Cholin et al. 2006 ), it has been proposed that the articulatory scores for frequent syllables are pre-compiled and stored in a repository called the ‘mental syllabary’. In contrast, the articulatory representation for less frequent syllables has to be compiled online ( Levelt 1999 ). 
 Neuro-anatomically the processes of generating lexical phonological representations have been linked to the middle and posterior Superior Temporal Gyrus ( Fiez et al. 1999 ;  Indefrey and W.J.M Levelt 2000 ;  Hickok and Poeppel 2004 ) also known as “Wernicke’s Area”, but they have also been linked to Broca’s area and specifically the posterior, opercular part of the L IFG, roughly corresponding to Brodmann Area 44 ( Zatorre et al. 1996 ;  Poldrack et al. 1999 ;  Burton et al. 2000 ). The latter region in particular has been related to syllabification ( Indefrey and W.J.M Levelt 2000 ) and more generally sub-lexical processes that require explicit segmentation, such as tasks when subjects perform phonological decision, e.g. phoneme monitoring, phoneme discrimination, or phoneme sequencing ( Zatorre et al. 1992 ;  Demonet et al. 1996 ;  Zatorre et al. 1996 ;  Poldrack et al. 1999 ;  Burton, Small, and Blumstein 2000 ). With respect to phonetic encoding, the regions that have been proposed are classical motor and premotor regions and subcortical structures such as bilateral ventral motor and sensory areas, supplementary motor area (SMA), thalamus and the cerebellum ( Indefrey and W. J M Levelt 2004 ;  Riecker et al. 2005 ). The premotor cortex is said to be specifically involved in compiling the motor codes and it is also thought to be the location of the “mental syllabary”. 
 In recent review papers by Hickok and Poeppel ( Hickok and Poeppel 2004 ;  Hickok and Poeppel 2007 ) a different approach has been followed to understanding linguistic processes. The Hickok and Poeppel model has been inspired by new data on the ‘mirror neuron system’ (M.  Iacoboni 2005 ) and the idea of sensory-motor integration. What is being proposed is the fact that there is a common interface between speech perception and production, which would also facilitate the phonemic-to-articulatory code translation. Broca’s area is part of the sensory-motor integration interface and in this sense it is directly involved in generation or retrieval of the articulatory codes. Following a computation model on speech production, the proposed role of the posterior Broca’s area along with the ventral premotor cortex is to hold a “speech sound map”, i.e. representations of phonemes or frequent syllables and their associated motor programs ( Guenther et al. 2006 ). 
 The concept of the “speech sound map” is similar to the idea of the “mental syllabary” presented above. However, two different views are being proposed about the role of the posterior part of Broca’s area. According to Hickock and Poeppel, the role of Broca’s area would be mostly related to phonetic encoding and the generation of the articulatory scores, since it serves as a store for articulatory representations. In contrast to that, according to Indefrey and Levelt the role of Broca’s area is mainly to support syllabification and post-lexical phonological processing, i.e. processes that are a step before the retrieval/compilation of the articulatory codes. 
 To support their claims, Indefrey and Levelt ( Indefrey and W.J.M Levelt 2000 ) referred to the fact that activations in Broca’s area are independent of whether the task requires overt or covert response and are therefore not directly related to the generation of articulatory codes. Based on their proposed model segmental processing and syllabification are the last common steps in the process of word production and prior to generating the articulatory code. However, as the authors themselves have claimed it is still possible that in cases of a covert response the articulatory code is also being retrieved; it seems to be highly depended on the task instructions. For example, when covert repetition is defined as covert rehearsal of the target stimulus, then it is assumed that the complete articulatory code is generated, as in the case of the “articulatory loop” ( Baddeley 2003 ). However, based on the theory of sensory-motor integration during speech ( Hickok and Poeppel 2004 ), as well as the “motor theory of speech” ( Liberman and Mattingly 1985 ), articulatory codes could be retrieved/compiled not only during word production, but also during comprehension. Therefore, it is possible that the articulatory code is generated independent of the specific task demands on overt response (for a review on evidence for the motor theory of speech see Galantucci et al. ( Galantucci et al. 2006 )). 
 For this study we were interested in investigating the role of Broca’s area in the process of generating an articulatory motor plan. We specifically wanted to address whether the posterior part Broca’s area (pars Opercularis) is involved in phonological processes, such as syllabification, or in directly retrieving/compiling the articulatory gestures. The two theories would make different predictions about the sensitivity of the region in syllable frequency effects, which would allow us to test them. If the posterior part of Broca’s area is only involved in the process of syllabification, it should not show a significant effect for sub-lexical (e.g. syllable) frequency manipulations. On the other hand, if the area is involved in syllable production, we expect the effect to be significant. Based on the theory on the existence of a “mental syllabary” or “speech sound map”, we expect that high frequency syllables would be pre-compiled and stored in the area, while low-frequency ones would need to be compiled on-line based on their segmental features (i.e. phonemes). We would therefore expect to see higher activation for low vs. high frequency syllables in cortical areas that are involved in compiling the articulatory scores. 
 To address these questions we used event-related functional MRI (fMRI) to monitor the changes in blood oxygenation while subjects performed a delayed phonological word repetition task. During the delay period the subjects were specifically given instructions to covertly rehearse the target stimulus and after the delay period an auditory probe instructed them as to whether they should repeat the presented word overtly or covertly. These instructions ensured that the articulatory code would be fully generated during the delay period. The presented pseudowords were constructed so as to be different in both length and frequency of segments and syllables. This manipulation resulted in a 2 × 2 factorial design with factors length (four vs. two syllables) and frequency (low vs. high frequency). During the construction of the stimuli we also controlled for phonological neighborhood density to ensure that during the performance of the task we would not see any differences related to lexical effects but only related to the processes of generating articulatory codes. Therefore, by manipulating stimulus length we hypothesized that the network underlying phonological and phonetic encoding would show higher activation for longer vs. shorter words, since the processes are considered to be incremental ( Levelt 1999 ;  Guenther, Ghosh, and Tourville 2006 ). However, we also expected that only a subset from this network would show significant activation for the contrast between low and high frequency stimuli. These regions would comprise the network underlying the generation of articulatory codes. Based on the proposed theory we anticipated that we would be able to identify the a. the location of the ‘mental syllabary’ for high vs. low frequency words and b. the regions participated in on-line articulatory code generation for the reverse contrast. Based on previous research on lexical production and the role of the posterior part of Broca’s area, we hypothesized that if Broca’s area is involved in syllabification and phonological processing prior to the encoding of the articulatory scores it would only show a strong effect of length, but not frequency. On the other hand, if Broca’s area is the site of the “mental syllabary” we expect to see significant effects of both length and frequency manipulations. 
 
 
 Materials and Methods 
 
 Participants 
 Fifteen healthy, monolingual native speakers of American English were chosen to participate in the study (7 females, mean age 26 years range=20–35). All the volunteers reported that they were right-handed, with normal hearing and with no history of previous neurologic or psychiatric disease. Volunteers were rewarded with for their participation in the 2-hour scanning session in compliance with the institutional guidelines. Prior to testing subjects provided written informed consent as approved by the NIDCD-NINDS IRB (protocol NIH 92-DC-0178). 
 
 
 Stimulus Materials 
 Four sets of 72 pseudowords were created (a total of 288 items) varying in length (number of syllables) and syllable frequency (phonotactic probability): four-syllable low frequency, four-syllable high frequency, two-syllable low frequency and two-syllable high frequency. Half of the items from each set (36 per set) were used for this experiment and the other half in a subsequent experimental session reported elsewhere. To construct the sets of stimuli we used single-consonant onsets (C), medial rimes that consisted only of a single vowel or diphthong (V), while the final rimes were vowel–consonant (VC) pairs ( Fig.1-C ). As a result all of our stimuli had an alternating CV pattern plus a final consonant ( Frisch et al. 2000 ). Two-syllable pseudowords were stressed in the first syllable, while four-syllable ones had a strong stress on the first and third syllable (the most common metrical pattern). The syllables were mostly chosen from a corpus of previous linguistic studies on the effects of phonotactic probability (M. S.  Vitevitch et al. 1997 ;  Frisch, Large, and David B. Pisoni 2000 ) such that they were not illegal, though rare (in the case of low frequency items), and that they satisfy our criteria for frequency. The phonotactic probability for each biphone and phoneme was calculated ( Michael S Vitevitch and Paul A Luce 2004 ) and pseudowords were created such that each pseudoword consisted entirely of high or low probability segments (depending on its category). The structure of pseudowords was such that onset syllables were corresponding to biphones. 
 Phonotactic probability refers to the frequency with which legal phonological segments and sequences of segments (i.e. biphones) occur in a given language ( Jusczyk et al. 1994 ). As observed in the syllable-frequency effect, low phonotactic probability pseudowords and nonwords have slower response times than high phonotactic probability ones, reflecting the load in the phonetic encoding process (M. S.  Vitevitch et al. 1997 ; M.S. Vitevitch and P.A. Luce 1998 ; M. S. Vitevitch et al. 1999 ). Therefore, between groups items differed only with respect to the positional frequency of their phonemes and segments (biphones and syllables). 
 To reduce the amount of similarity between the stimuli no two syllables occurred in the same word more than once and no pseudoword appeared as a contiguous part within another pseudoword; one of the reasons why we also avoided monosyllabic words. The other reason was phonological neighbors, which tend to be more for monosyllabic words. All items were further checked for immediate phonological neighbors using a one phoneme change rule (substitution, deletion, addition). Even though phonological neighborhood density and phonotactic probability are correlated, we expected that by controlling for immediate neighbors, this effect will not be emphasized and effects related to phonotactic probability would be related to phonetic encoding and not phonological word retrieval, which would arise by manipulating phonological neighborhood density ( Okada and Hickok 2006 ). To also avoid morphological confounds, any sequences that ended with a high probability final rime, e.g., /-@s/ and /-@d/, which could be interpreted as inflectional suffixes, were also omitted from the dataset. 
 To record the stimuli, we recruited a local female, monolingual American English volunteer. Prior to the recording, the volunteer was trained to pronounce the dataset correctly and rehearsed the items a number of times to familiarize her self with the dataset. The stimuli were read from a laptop screen and spoken in isolation as natural and as clear as possible. Two to three recordings were made for every stimulus. All stimuli were recorded in a single session in a non-echoic, sound attenuated booth. They were digitally using a Shure SM58 vocal microphone. Recordings were made at 44.1 kHz sampling rate and saved at 16-bit resolution. After the recording the sound files were edited into individual files and all files were screened for accuracy and fluency. For each item the most accurate recording was chosen to be part of the stimulus list. The final recordings were transcribed and the segment and biphone phonotactic probably was recalculated to include the cases were there were some differences in the pronunciation. In the resulting lists phoneme and biphone phonotactic probability for two-syllable high frequency pseudowords was 0.3 and 0.02, for two-syllable low frequency ones 0.06 and 0.0004, for four-syllable high frequency items 0.7 and 0.06, while for the low frequency ones it was 0.2 and 0.005. The differences between the average segment and biphone probabilities over both four and two-syllable pseudowords were statistically significant (phonemes: F(1,286) = 920.2, p< 0.001; biphones: F(1, 286) = 763.9, p < 0.001). 
 
 
 Experimental Design and Procedure 
 Thirty-six items per condition (in a total of 144 items per participant) were presented in the course of two experimental fMRI runs. Each pseudoword was presented to the subject auditory and after a 6sec. delay a probe (two versions of a bell sound) was heard instructing the subject to repeat the presented word either overtly or covertly (depending on the type of probe). Each trial lasted 8sec ( Fig. 1-B ). The subjects were given specific instructions to covertly rehearse the presented stimulus during the delay period and they did not know whether they would be asked to respond overtly or covertly before the presentation of the relevant probe. During the delay period they are therefore expected to have retrieved the articulatory scores for the presented word. Stimulus presentation was in a pseudorandom, fast event-related fashion whereby the order of occurrence for the conditions was controlled by a combination of three binary shifted versions of an m-sequence (one shifted by 9 bins and the other by 18 from the first one;  Fig. 1-A ). The use of m-sequences to control stimulus deliver allowed for a simple and efficient way to ensure that the experimental conditions would be orthogonal to one another and counterbalanced ( Buracas and Boynton 2002 ;  Kellman et al. 2003 ). The binary m-sequence used in the study had a length of 63-bins (corresponding to the number of trials per run) and was padded in the beginning with 9 more trials (for a total of 72 trials), which were however not analyzed for the purposes of this study. The purpose of these onset trials was to allow for the brain activation to reach a steady state and for the subject to get comfortable with the task and noisy environment in the scanner. 
 Prior to the onset of the experiment all subjects received a short 15 minute practice, outside the scanner, to allow them to become familiar with the structure of the task and its demands. The material used as training set (40 items in four categories) contained pseudowords with similar features as the ones presented during the experimental runs, but from a different unrelated set (different syllables) to avoid habituation and familiarity. During the experimental runs stimuli were presented auditory to the subject while in the scanner booth using an fMRI compatible (pneumatic) system for auditory delivery (Avotec SS-3100, silent scan system). The sound volume was adjusted individually for each subject to ensure both their comfort and clear sound delivery. Because of the concerns that during the scanning session, the scanner noise would be masking out some of the stimuli, prior to the onset of the experimental runs, a quality check run was performed. During this run a set of pseudowords (not used for the experimental set, but recorded in the same session as the experimental set, i.e. same amplitude and recording characteristics) was presented to the subject and the volume or the headset was adjusted based on the subject’s feedback to ensure protection from exposure to a noisy environment, comfort and clear stimulus delivery. Images acquired during this test run were also submitted to a quality check to make sure that they were free from artifacts. Finally, during the scanning session subject responses were recorded using a dual-channel, noise canceling, fiber optic microphone (Dual-Channel Phone-Or by Optoacoustics Ltd., Israel). This system is specifically designed for use in MRI environments and offers real-time adaptive elimination of the EPI acoustic noise from the signal. This allowed us to record both the subject responses and the timing of their responses. However, due to a possible problem with the filtering algorithm and the insertion of random delay in the recording of the responses, we were not able to get a reliable estimate of the subject response timing. Thus, as a behavioral measurement we only use the subject response. 
 
 
 fMRI Data Acquisition 
 Imaging was performed on a 3.0T MRI system (General Electric, Milwaukee, WI, USA), equipped with CRM (Cardiac Resonance Module) whole body gradients. For improved signal-to-noise ratio (SNR) and higher spatial resolution we used a multi-channel (16-channel custom built helmet-type) MRI receive array ( Zwart et al. 2004 ) connected to a custom-built 16-channel MRI receiver. For the functional scans, we used single-shot rate-2 sensitivity-encoded (SENSE) echo-planar imaging (EPI) ( Zwart et al. 2002 ). A modified GE-EPI sequence was used to acquire the functional images (TE=31ms, flip angle of 90 degrees, TR=2s and acquisition bandwidth 250 kHz). The combination of the dedicated receive array with SENSE EPI allowed a 2- to 4-fold improvement in SNR and a 50% reduction in geometric distortions relative to a conventional setup with a birdcage head coil ( Zwart et al. 2004 ). This was a significant advantage for our study, considering that imaging studies of overt speech tend to suffer from artifacts due to task-related subject motion. A total of 32 axial slices were acquired interleaved (slice thickness = 2mm, gap = 0.3mm) with an in-plane resolution of 2.3×2.3mm 2  (96×72 matrix, 22.4cm FOV). Four images were acquired during each trial. 
 To facilitate with subject movement correction we acquired isotropic voxels (2.3mm cube side). However, the size of the slices put a constraint on the brain volume that could be imaged. We did not have a hypothesis about any areas below the superior temporal sulcus (STS) and we therefore acquired images in a slightly oblique position, covering an area from below the STS to the top of the head. By avoiding the lower parts of the cortex, e.g. the inferior temporal areas we also avoid geometrical distortions and artifacts that could be caused as a result of articulatory muscle movement ( Birn et al. 2004 ). To facilitate with slice selection, a sagital two-dimensional anatomical image was acquired prior the onset of the functional runs. This image was inspected for specific anatomical landmarks such as the anterior commissure and was used to make the slice selection. At the end of the scanning session, high-resolution spin-echo T1 anatomical images were acquired at the same location as the functional EPIs. The scanning parameters for the anatomical image were: TR=700ms, TE=min full, 256×192 data matrix with a 22cm FOV and 2mmslice thickness (with 0.3mm gap), resulting in 0.86×0.86mm 2  voxel-size. 
 To restrain head movement during the scanning sessions, head padding and a velcro strap was used, which was mounted on each side of the head coil and positioned on the subjects’ forehead, at the line just above the eyebrows. The purpose of the strap was to act as a motion reference point for the subject. Head movement, especially in the z direction, would cause a strain on the strap that could make the subject aware of the movement and force him/her to restrict it and return to the original position. Prior to the onset of the scanning session subjects were given relevant instructions and tests were also performed to ensure that the strap is properly placed. 
 
 
 Image Preprocessing 
 All analysis and image preprocessing was carried out using the SPM5 software package 1 . Preprocessing included slice-timing correction and an optimized motion correction routine to ensure good quality registration ( Oakes et al. 2005 ). Images were then registered to the anatomical image, which was registered to the Montreal Neurological Institute (MNI) anatomical template and transformed into MNI stereotactic space to allow for group comparisons. The functional data were finally smoothed with an isotropic Gaussian filter kernel of 6mm (full-width at half maximum) to improve SNR. 
 To quantify the effect of subject movement on the quality of our data we inspected the data using the ArtRepair toolbox ( Mazaika et al. 2007 ) and examined the realignment parameters provided by SPM5. A three factor ANOVA (response type, stimulus length and frequency) on the six movement parameters revealed no significant effects for absolute movement (displacement with respect to the first image in the series), but a main effect of response type for incremental (scan-to-scan) movement in all directions (P < 0.001 for all directions). However, overall the movement effects were quite small (mean < 0.06 mm for x, y and z translations and <0.05 degrees for all rotations) and in accordance to other related studies ( Barch et al. 1999 ). Two subjects showed movement greater than 1mm/1º (translation/rotation) and were consequently excluded from the analysis. The examination using the ArtRepair toolbox also revealed that in some cases scan-to-scan movement even as low as 0.5mm induced global signal changes greater than 1.5% of the mean and “stripe-like” artifacts on the image. To ensure the quality of our data, we modeled images that showed changes in the global signal greater 1.5% of the mean followed by a greater than 0.5mm incremental movement as effects of no interest. To further take account of movement related effects, we also included the movement parameters in the design matrix. 
 
 
 Behavioral Data Analysis 
 To calculate subject response accuracy we monitored and phonologically transcribed all subject responses. The transcriptions were then compared to the target stimulus phoneme-by-phoneme and a score was calculated based on the number of correctly identified phonemes. The match was determined based on broad (i.e. phonemic) rather than narrow phonetic criteria (M.S.  Vitevitch and P.A. Luce 1998 ). This result was then mean-corrected to remove any length-related effects and the scores were submitted to a 2-way ANOVA with factors length and frequency. Trials that were incorrectly answered (i.e. overt response instead of covert and vice versa) were excluded from the analysis. 
 
 
 fMRI Data Analysis 
 Statistical analysis of the factorial event-related experiment was also performed using SPM5. The hemodynamic response function (HRF) for each trial was modeled using a finite-impulse response function (FIR) with 12 bins (duration of 2sec.) to capture the temporal components of a delayed response task. Stimulus presentation was modeled as a delta function. A 3-way, random-effects, within-subject ANOVA with factors length (four- vs. two-syllable pseudowords), frequency (low vs. high) and response type (overt vs. covert) was performed. Each of the 8 different resulting types of trials (e.g. four-syllable, low frequency, overt response) was modeled by separate regressors and the main effects and interactions were evaluated by contrasting within or across (interactions) the levels of each factor. To perform group statistics the contrast images for each effect and for all subjects were submitted to a 1-way ANOVA (with 12 levels). T-contrasts testing for the predicted shape of the HRF (a canonical, 2 gamma function ( Friston et al. 1998 )) were performed to produce maximum intensity projections (MIP) and reveal voxels whose differential activity pattern conforms to the shape of the HRF. Two HRF were used, one to model stimulus presentation and delay and the other one to model the response period. The latter was delayed by 6sec modeling the presentation of the response probe and used to test for significant effects during the response type condition. The response type condition was used as a localizer to allow us to define an independent region of interest (ROI) within the left Inferior Frontal Gyrus (LIFG). Statistical parametric maps (SPM) were thresholded at P < 0.001 (uncorrected) at the voxel-level and P <0.05 (FWE corrected) at the cluster-level, with significant clusters having on average more than 85 voxels ( Hayasaka and Nichols 2003 ). 
 In order to analyze the contrast estimates for the left hemisphere Inferior Frontal Gyrus we used the cytoarchitectonic probability map for the left hemisphere BA44 ( Eickhoff et al. 2005 ) to identify the voxels within activated clusters that are part of BA44. Therefore, for each of the main effects (length, frequency and response type) we identified three clusters. We then extracted the average beta weights (over cluster voxels) for each of the four conditions of interest in the design (4 syllable low frequency, 4 syllable high frequency, 2 syllable low frequency and 2 syllable high frequency) and for all subjects. A single value corresponding to the weighted sum of the estimates across the FIR (weighted by the HRF) was then extracted for each of the four conditions and subjects and used in multiple 2-sided t-tests testing for effects of frequency, length or the difference between the two conditions within each region. Significance was determined using a threshold of P < 0.05. Where appropriate (more than one ROI) the p-values were adjusted to correct for multiple comparisons (Bonferroni correction). 
 
 
 
 Results 
 
 Behavioral Results 
 To test for effects of length or frequency on subject performance we measured subject response accuracy. Based on previous results, we expected to find a decrease in response accuracy for low frequency pseudowords, but we did not expect to find an effect of length. We performed a 2-way ANOVA with factors: pseudoword length and frequency. As expected we found that there was a significant main effect only for the frequency condition (F(1, 942) = 36.19, p < 0.001). No other main effects or interactions were significant. Mean accuracy rates for low frequency pseudowords were 57% (SE = 1.5) and for high frequency pseudowords 70% (SE = 1.4). The relatively low accuracy scores were expected, considering the nature of the task (pseudoword repetition) and the noisy environment. However, all subjects performed above chance levels (50%) and there were no subjects whose average accuracy was three standard deviations below the group mean (64%, SE=1). 
 
 
 fMRI Results 
 
 Phonological Encoding 
 To map the areas involved in phonological encoding we compared the activation levels invoked for processing four- vs. two-syllable pseudowords (over both low and high frequency syllables). A significant main effect for length (four- greater than two-syllable stimuli) was observed in a large perisylvian network extending bilaterally across the superior temporal gyrus (STG), the precentral gyrus (PrCG) and the supplementary motor area (SMA), as well as the left inferior frontal gyrus (L IFG) ( Fig. 2-A ). The highest activations are observed in the left hemisphere (L) for a cluster that covered both the PrCG and STG. In particular for the STG, the cluster covered a big portion of the middle and posterior STG including the upper banks of the superior temporal sulcus (STS) and an area in the junction between the parietal and temporal lobe also referred to as Sylvian parieto-temporal area (Spt) (cf.  Table 1  for the region coordinates). The L STG has been previously implicated in phonological processing ( Indefrey and W.J.M Levelt 2000 ;  Indefrey and W. J M Levelt 2004 ;  Graves et al. 2007 ), while the L PrCG is a known premotor area and as such it has been associated with phonetic encoding. A similar effect could also be observed for the L IFG. The activated area was located on the posterior part of the L IFG, also known as pars opercularis and ran along the Inferior Frontal Sulcus (IFS). In accordance to our hypothesis, we expected that both phonological and phonetic encoding processes would show an effect of length. However, what distinguishes the two processes is their sensitivity to syllable frequency. 
 
 
 Phonetic Encoding 
 Comparing pseudowords with low vs. high phonotactic probability syllables and segments revealed regions that showed an effect for syllable frequency. Based on our hypothesis, areas that showed a frequency effect reflect the process of phonetic encoding, i.e. articulatory code generation ( Indefrey and W.J.M Levelt 2000 ). Four regions showed a significant main effect of frequency, the left hemisphere dorsal PrCG and SMA, as well as the IFG bilaterally (cf.  Table 1  for a detailed list of the activated regions;  Fig. 2-B ). Activations in the L STG did not reach significance (p < 0.2 cluster-size corrected), which highlights the role of this area in phonological rather than phonetic processing. No effects were observed for the opposite contrast, high vs. low frequency pseudowords and no regions showed an interaction for length and frequency. 
 
 
 Left Inferior Frontal Gyrus 
 To further confirm our hypothesis about the involvement of Broca’s area in phonetic processing, we performed an ROI analysis on an independently identified ROI corresponding to the L IFG for the contrast overt vs. covert repetition (center of mass x = −55, y = 9, z = 13, size = 138 voxels). In a random effects two-way ANOVA with factors length (four- vs. two-syllables) and frequency (low vs. high phonotactic probability) the L IFG showed a main effect for both factors (t(12) = 3.46, p < 0.003 and t(12) = 2.22, p < 0.03 for length and frequency respectively), though greater for length. 
 Because the L IFG showed effects for both length and frequency we further wanted to investigate whether we can observe any signs of functional segregation within the IFG and in particular the pars opercularis, as had been observed in other studies (Molnar-Szakacs04, Chein02). For the two conditions, length and frequency, we observed two clusters within the L IFG, which were only partly overlapping (9 voxels out of 82 and 79 respectively for the two clusters;  Fig. 3 ). The distance between their center of mass was 9 mm, i.e. a factor of 1.5 greater than the smoothing kernel (6mm), with the cluster showing a greater effect of length following the anterior banks of the L IFS and being more lateral, posterior and dorsal to the cluster showing a greater effect of frequency. We will refer to the cluster identified during the length condition as dPOp (dorsal pars Opercularis) and the cluster identified for the frequency condition as vPOp (ventral pars Opercularis), because of their anatomical differences and in agreement with previous evidence. Both the dPOp and the vPOp exhibited effects of frequency and length, though the frequency effect for dPOp was just slightly below threshold (dPOp frequency: t(12) = 2.5, p < 0.06; vPOp length: t(12) = 3.2, p <0.02 corrected for two ROI). This difference already suggests that there might be a functional segregation between the pars Opercularis of the L IFG. To further examine whether there is a functional difference in the activation between the two clusters, we examined the region (dPOp vs. vPOp) by experimental condition (length vs. frequency) interaction ( Friederici et al. 2006 ). We performed a 2-sided paired t-test on the region specific differences between the length and frequency conditions and found a significant region-by-condition interaction (t(12) = 3.1, p < 0.01), indicating that there is a significant difference between the two clusters, with dPOp being more active for length effects rather than frequency, while in vPOp there seems to be no difference between the levels of activation for the two conditions. 
 
 
 
 
 Discussion 
 The present fMRI study was able to delineate the cortical network involved in a phonemic to articulatory translation that is necessary for the generation of articulatory codes. By directly contrasting targets with varying length we manipulated the load on the system of post-lexical articulatory-motor production and were able to specify the default network. This network comprised of large perisylvian activations in bilateral (although strongly left lateralized) mid and posterior Superior Temporal, Premotor, Supplementary Motor and posterior Frontal regions. This network is in agreement with current models on phonological and phonetic encoding ( Indefrey and W.J.M Levelt 2000 ;  Indefrey and W. J M Levelt 2004 ;  Hickok and Poeppel 2004 ;  Hickok and Poeppel 2007 ). 
 To further identify the roles of the different components of the network and in particular to resolve the conflict on the role of the left Inferior Frontal Gyrus we probed the network by manipulating target frequency. Based on our hypothesis, only regions that are directly involved in phonemic-to-articulatory translation would show an effect for frequency manipulation. Targets with high frequency components (whether we consider syllables or phonemes as the structural unit; for evidence in support of syllables see Levelt ( Levelt 1999 )) are processed faster than the ones with less frequent components (( Cholin, Willem J.M. Levelt, and Schiller 2006 ). This is taken as evidence to suggest that they are processed differently (possibly in the same region; ( Guenther, Ghosh, and Tourville 2006 )) and that high frequency clusters are pre-compiled and retrieved, while low frequency clusters need to be compiled online on a segment-to-segment basis (see the computational model DIVA for a proposed mechanism underlying the conversion; ( Guenther, Ghosh, and Tourville 2006 )). 
 In our experiment we identified four regions that showed frequency effect (higher activation for low vs. high frequency): the L SMA, the L PrCG and the IFG bilaterally. From previous studies on motor planning and production it is known that the SMA has a more generic role in motor planning and the preparation of movements and it is not strictly associated with linguistic functions though it is also part of linguistic motor planning ( Riecker et al. 2005 ). It has been shown that the rostral part of the SMA (pre-SMA) contains cells that code for an entire sequence to be produced, which in our case would correspond to a syllable. In a recent fMRI study, the pre-SMA was shown to be sensitive to sequence complexity effects both within and beyond the syllable boundaries ( Bohland and Guenther 2006 ). The present findings are in agreement with the presented hypotheses and the frequency effect observed in the L SMA could simply represent the higher system processing load that is associated with processing new and unfamiliar motor plans (low frequency) compared to familiar, more rehearsed and possibly precompiled ones (high frequency syllables). 
 The significant activation differences for low vs. high frequency pseudowords in the left Precentral Gyrus is also in agreement with our hypotheses. It is worth highlighting that only a small area in the dorsal PrCG was significantly active and that this area has been previously involved in studies examining sensory-motor mapping ( Hickok and Poeppel 2004 ). Hickok and Poeppel talked about a “dorsal stream” in speech processing, which is involved in mapping sound onto articulatory-based representations network. The regions that are part of this stream include a posterior inferior frontal area (including Broca’s area), a more dorsal premotor site and an area in the posterior parietal lobe, deep within the Sylvian fissure and at the boundary between the parietal and temporal lobes (also known as the Sylvian parieto-temporal junction or Spt; ( Hickok et al. 2003 ). Based on this account, the latter area, which lies within the boundaries of the Planum Temporale (PT), an area traditionally associated with acoustic and phonological processing, is therefore associated with speech production and is thought to be an interface for the sound-to-gesture transformation. In our study, this area showed significant effects for target length, but not frequency. In our task we cannot distinguish between the processes of generating a phonological representation for the presented target and generating a phonological representation for articulatory rehearsal, which could be separate ( Indefrey and W. J M Levelt 2004 ) or common based on the motor theory of speech. It is therefore not possible for us to say whether the activation in Spt is related to stimulus presentation, motor planning or both. However, the absence of significant frequency effects from this region highlights the fact that if this region is involved in sensory-motor mapping, then it’s role would be probably related to post-lexical phonological processing, such a syllabification and segmentation in preparation for generating the articulatory codes. Indeed, this claim would be in agreement with some older claims made by Indefrey, whereby a portion of the Superior Temporal Lobe was considered as a possible candidate region for syllabification. The other candidate was the left Inferior Frontal Gyrus. 
 In our study we also found significant activation in the L IFG. In particular, the posterior part of the L IFG, the pars Opercularis (roughly corresponding to area Brodmann Area 44; (K.  Amunts et al. 1999 )), has shown consistent effects for both length and frequency (four vs. two syllables and low vs. high frequency respectively). Based on our hypothesis, only regions that are part of the mechanism underlying phonemic-to-articulatory translation and the generation of articulatory scores would show an effect for frequency. We could therefore conclude that, in generating articulatory codes, the posterior part of Broca’s area is not part of the syllabification process (as has been proposed; see ( Indefrey and W.J.M Levelt 2000 ;  Indefrey and W. J M Levelt 2004 )), but it is rather directly involved in translating between phonological and articulatory forms. This claim is in agreement with the role of the L IFG in sensory-motor translation and it particularly involves the posterior portion of the IFG, the pars Opercularis, as has been proposed by Guenther et al. ( Guenther, Ghosh, and Tourville 2006 ). This part of the L IFG has a known role in sub-lexical processing ( Zatorre et al. 1996 ;  Burton, Small, and Blumstein 2000 ) and in particular processing requiring explicit segmentation compared to simple processing. Our current findings support the notion that activation of the L IFG during phonologically demanding tasks is not a result of the segmentation mechanism per se, but triggered articulatory recoding ( Hickok and Poeppel 2004 ). 
 Another dimension to the issue that is also supported by our current findings is that the pars Opercularis is functionally segregated and it is therefore taking part in both processes of segmentation or sensory-motor mapping. 
 The idea that Broca’s area is functionally segregated into its three anatomical partes (pars Opercularis, Triangularis and Orbitalis) is well-known and well-founded (( Bokde et al. 2001 ;  Chein et al. 2002 ;  Devlin et al. 2003 ;  Heim et al. 2007 ). Recently, however, there have also been claims about a functional segregation even within pars Opercularis (POp; ( Molnar-Szakacs et al. 2005 )). In a meta-analysis of imaging studies on imitation and action observation Molnar-Szackacs et al. observed that two distinct foci within the pars Opercularis, a dorsal (dPOp) and a ventral (vPOp) one, that serve different functions. The more dorsal shows “mirror neuron” properties and is significantly active during both action observation and imitation, while the more ventral shows only motor properties and is only active during imitation. 
 Our findings are in agreement with this segregation. We also found two clusters that are functionally segregated and one is located more dorsally in POp than the other. The more dorsal cluster is located around the area of the Inferior Frontal Sulcus and the premotor cortex and shows greater activation for length manipulation when compared to the vPOp, which is more strongly activated for low vs. high frequency stimuli. In our study, the dPOp is literally part of a wider activation in the L PrCG. Therefore, based on its proximity and connection to premotor areas and the IFS, as well as the fact that it is mostly active for the length condition, but not the frequency condition, we propose that the role of the dPO is not directly related to retrieving articulatory codes for phonemic representations, but rather implements processes general to sequencing discrete units as has been proposed by Gelfand and Bookheimer ( Gelfand and Bookheimer 2003 ). This assumption is based on the fact in a series of sequencing tasks involving hummed notes and strings of syllables the POp did not show an effect for stimulus type, but for task. This is in agreement with our findings and the fact that the dPOp shows an effect of length but not stimulus frequency. The vPOp on the other hand shows a significant effect of both length and frequency, which would be in agreement to a role as a “speech sound map” or “mental syllabary” that has been proposed by Guenther et al. ( Guenther, Ghosh, and Tourville 2006 ). 
 The research into the functional segregation of the Pars Opercularis is still in its preliminary steps. As imaging methods improve with high-field strength scanners and multi-array receiving coils it is expected that the spatial resolution in fMRI will also improve significantly to allow for more fine-grained differences to appear. In the present study we used a 16-channel coil and parallel imaging protocols (SENSE2) to allow us to get a better spatial resolution than standard fMRI studies by at least a factor of 3. The differences would be particularly visible in the z dimension, since we acquired considerable thin slices (2.0mm, with 0.3mm gap). We believe that this allowed us to identify local differences within the area of the L IFG that otherwise we would have missed because of low spatial resolution. Furthermore, because it is well-evidenced that the anatomy of the L IFG is extremely variable across subjects in this study we do not make any conclusive statements about their exact anatomical and cytoarchitectonical features, but we have defined the areas in gross anatomical terms such as ventral and dorsal, which are the tendencies that we have observed in our results. More research and higher spatial resolution would be needed to further specify the exact anatomical characteristics of this functional segregation. 
 Finally, we also wanted to comment on the fact that we did not find any significantly activated regions for the inverse contrast high vs. low frequency. Based on our hypothesis, we would expect that a significant activation for this contrast would reveal the location of the “mental syllabary” versus the network underlying articulatory code generation. However, based on the model proposed by Guenther et al. ( Guenther, Ghosh, and Tourville 2006 ), this not need be the case. According to his computational model (DIVA) the “speech sound map” (the equivalent of the mental syllabary) does not just contain pre-compiled frequent syllables, but also motor representation for phonemes, common words and phrases etc. The “speech sound map” is therefore involved in both processes, though the online compilation of articulatory codes would be computationally more demanding than the retrieval of precompiled gestural scores. Therefore, it is not surprising that we do not see effects for high vs. low frequency stimuli, since it would be the same network that is underlying the process. 
 To sum up, in this fMRI study we investigated the processes of phonological-to-articulatory translation and the role of the left Inferior Frontal Gyrus. Based on our findings, we conclude that the left IFG is not involved in phonological segmentation, but rather the translation between phonemic and articulatory representations. The Superior Temporal Gyrus and in particular the mid and posterior portion might be a better candidate for the role of phonological segmentation. We have also presented evidence in support of a functional segregation of the posterior portion of the L IFG, i.e. the pars Opercularis. This finding is in agreement with recent observations from the study of the “mirror neuron system” and adds another dimension to the study of the L IFG and the complexity of its function. 
 
 
 
 Figures and Table 
 
 Figure 1 
 
 
 
 Figure 2 
 
 
 
 Figure 3 
 
 
 
 Table 1 
 
 Brain Regions modulated by length and frequency 
 
 
 
 
 Contrast 
 Region 
 Coordinates 
 T(max) 
 No Voxels 
 
 
 
 
 
 x 
 
 
 y 
 
 
 z 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Four > Two 
 Left Precentral Gyrus 
 −56 
 −4 
 44 
 7.87 
 2097 
 
 
 Syllables 
 
 
 
 * Left Sylvian Parieto-temporal 
 −60 
 −12 
 4 
 6.76 
 
 
 
 
 junction 
 
 
 
 
 
 
 
 
 * Left Superior Temporal Gyrus 
 −54 
 8 
 0 
 6.00 
 
 
 
 
 * Left Inferior Frontal Gyrus 
 −60 
 4 
 20 
 4.63 
 
 
 
 
 Left Supplementary Motor Area 
 −4 
 10 
 68 
 7.21 
 388 
 
 
 
 Right Superior Temporal Gyrus 
 50 
 −22 
 8 
 5.45 
 393 
 
 
 
 Right Precentral Gyrus 
 50 
 −4 
 40 
 5.30 
 176 
 
 
 Low > High 
 Left Precentral Gyrus 
 −52 
 2 
 40 
 4.77 
 138 
 
 
 Frequency 
 
 
 
 Left Supplementary Motor Area 
 −4 
 14 
 58 
 4.51 
 122 
 
 
 
 Left Inferior Frontal Gyrus 
 −54 
 12 
 12 
 4.01 
 119 
 
 
 
 Right Inferior Frontal Gyrus 
 50 
 18 
 4 
 4.23 
 97 
 
 
 
 
 
 Note: Regions significantly activated in the random-effects group analysis (t(13) < 3.1, P < 0.05 FWE corrected for cluster-size). Displayed are the contrasts, the coordinates for the voxels of greatest activity within the activated clusters in MNI stereotaxic space, a description of the region, the T value and the number of significant voxels. In the case of very large clusters multiple peak voxels are reported. These are prefixed with a * and they are clustered together with the last non-prefixed entry in the table. 
 
 
 
 
 
 
 1 
 
 http://www.fil.ion.ucl.ac.uk/spm/software/spm5/ 
 
 
 
 
 
 
 
 
 Amunts 
 K 
 
 
 Schleicher 
 A 
 
 
 Burgel 
 U 
 
 
 Mohlberg 
 H 
 
 
 Uylings 
 HB 
 
 
 Zilles 
 K 
 
 
 1999 
 Broca’s region revisited: Cytoarchitecture and intersubject variability 
 Journal of Comparative Neurology 
 412 
 2 
 319 
 341 
 10441759 
 
 
 
 
 
 
 Bachoud-Lévi 
 A 
 
 
 Dupoux 
 E 
 
 
 Cohen 
 L 
 
 
 Mehler 
 J 
 
 
 1998 
 Where Is the Length Effect? A Cross-Linguistic Study of Speech Production 
 Journal of Memory and Language 
 39 
 3 
 331 
 346 
 
 
 
 
 
 
 Baddeley 
 A 
 
 
 2003 
 Working memory and language: an overview 
 J Commun Disord 
 36 
 3 
 189 
 208 
 12742667 
 
 
 
 
 
 
 Barch 
 DM 
 
 
 Sabb 
 FW 
 
 
 Carter 
 CS 
 
 
 Braver 
 TS 
 
 
 Noll 
 DC 
 
 
 Cohen 
 JD 
 
 
 1999 
 Overt verbal responding during fMRI scanning: empirical investigations of problems and potential solutions 
 Neuroimage 
 10 
 6 
 642 
 657 
 10600410 
 
 
 
 
 
 
 Birn 
 RM 
 
 
 Cox 
 RW 
 
 
 Bandettini 
 PA 
 
 
 2004 
 Experimental designs and processing strategies for fMRI studies involving overt verbal responses 
 Neuroimage 
 23 
 3 
 1046 
 1058 
 15528105 
 
 
 
 
 
 
 Bohland 
 JW 
 
 
 Guenther 
 FH 
 
 
 2006 
 An fMRI investigation of syllable sequence production 
 Neuroimage 
 32 
 2 
 821 
 841 
 16730195 
 
 
 
 
 
 
 Bokde 
 AL 
 
 
 Tagamets 
 MA 
 
 
 Friedman 
 RB 
 
 
 Horwitz 
 B 
 
 
 2001 
 Functional interactions of the inferior frontal cortex during the processing of words and word-like stimuli 
 Neuron 
 30 
 2 
 609 
 17 
 11395018 
 
 
 
 
 
 
 Browman 
 CP 
 
 
 Goldstein 
 L 
 
 
 1988 
 Some notes on syllable structure in articulatory phonology 
 Phonetica 
 45 
 2–4 
 140 
 155 
 3255974 
 
 
 
 
 
 
 Buracas 
 GT 
 
 
 Boynton 
 GM 
 
 
 2002 
 Efficient design of event-related fMRI experiments using M-sequences 
 Neuroimage 
 16 
 3 Pt 1 
 801 
 813 
 12169264 
 
 
 
 
 
 
 Burton 
 MW 
 
 
 Small 
 SL 
 
 
 Blumstein 
 SE 
 
 
 2000 
 The role of segmentation in phonological processing: An fMRI investigation 
 Journal of Cognitive Neuroscience 
 12 
 4 
 679 
 90 
 10936919 
 
 
 
 
 
 
 Chein 
 JM 
 
 
 Fissell 
 K 
 
 
 Jacobs 
 S 
 
 
 Fiez 
 JA 
 
 
 2002 
 Functional heterogeneity within Broca’s area during verbal working memory 
 Physiol Behav 
 77 
 4–5 
 635 
 9 
 12527011 
 
 
 
 
 
 
 Cholin 
 J 
 
 
 Levelt 
 WJ 
 
 
 Schiller 
 NO 
 
 
 2006 
 Effects of syllable frequency in speech production 
 Cognition 
 99 
 205 
 235 
 15939415 
 
 
 
 
 
 
 Demonet 
 JF 
 
 
 Fiez 
 JA 
 
 
 Paulesu 
 E 
 
 
 Petersen 
 SE 
 
 
 Zatorre 
 RJ 
 
 
 1996 
 PET Studies of Phonological Processing: A Critical Reply to Poeppel 
 Brain and Language 
 55 
 3 
 352 
 79 
 8954604 
 
 
 
 
 
 
 Devlin 
 JT 
 
 
 Matthews 
 PM 
 
 
 Rushworth 
 MFS 
 
 
 2003 
 Semantic processing in the left inferior prefrontal cortex: a combined functional magnetic resonance imaging and transcranial magnetic stimulation study 
 J Cogn Neurosci 
 15 
 1 
 71 
 84 
 12590844 
 
 
 
 
 
 
 Eickhoff 
 SB 
 
 
 Stephan 
 KE 
 
 
 Mohlberg 
 H 
 
 
 Grefkes 
 C 
 
 
 Fink 
 GR 
 
 
 Amunts 
 K 
 
 
 Zilles 
 K 
 
 
 2005 
 A new SPM toolbox for combining probabilistic cytoarchitectonic maps and functional imaging data 
 Neuroimage 
 25 
 4 
 1325 
 1335 
 15850749 
 
 
 
 
 
 
 Fiez 
 JA 
 
 
 Balota 
 DA 
 
 
 Raichle 
 ME 
 
 
 Petersen 
 SE 
 
 
 1999 
 Effects of lexicality, frequency, and spelling-to-sound consistency on the functional anatomy of reading 
 Neuron 
 24 
 1 
 205 
 218 
 10677038 
 
 
 
 
 
 
 Friederici 
 AD 
 
 
 Fiebach 
 CJ 
 
 
 Schlesewsky 
 M 
 
 
 Bornkessel 
 ID 
 
 
 Cramon 
 DYV 
 
 
 2006 
 Processing linguistic complexity and grammaticality in the left frontal cortex 
 Cereb Cortex 
 16 
 12 
 1709 
 1717 
 16400163 
 
 
 
 
 
 
 Frisch 
 SA 
 
 
 Large 
 NR 
 
 
 Pisoni 
 DB 
 
 
 2000 
 Perception of Wordlikeness: Effects of Segment Probabiltiy and Length on the processing of nonwords.f 
 Journal of Memory and Language 
 42 
 481 
 496 
 
 
 
 
 
 
 Friston 
 KJ 
 
 
 Fletcher 
 P 
 
 
 Josephs 
 O 
 
 
 Holmes 
 A 
 
 
 Rugg 
 MD 
 
 
 Turner 
 R 
 
 
 1998 
 Event-related fMRI: characterizing differential responses 
 Neuroimage 
 7 
 1 
 30 
 40 
 9500830 
 
 
 
 
 
 
 Galantucci 
 B 
 
 
 Fowler 
 CA 
 
 
 Turvey 
 MT 
 
 
 2006 
 The motor theory of speech perception reviewed 
 Psychon Bull Rev 
 13 
 3 
 361 
 377 
 17048719 
 
 
 
 
 
 
 Gelfand 
 JR 
 
 
 Bookheimer 
 SY 
 
 
 2003 
 Dissociating neural mechanisms of temporal sequencing and processing phonemes 
 Neuron 
 38 
 5 
 831 
 842 
 12797966 
 
 
 
 
 
 
 Goldrick 
 M 
 
 
 Rapp 
 B 
 
 
 2007 
 Lexical and post-lexical phonological representations in spoken production 
 Cognition 
 102 
 2 
 219 
 260 
 16483561 
 
 
 
 
 
 
 Graves 
 WW 
 
 
 Grabowski 
 TJ 
 
 
 Mehta 
 S 
 
 
 Gordon 
 JK 
 
 
 2007 
 A neural signature of phonological access: distinguishing the effects of word frequency from familiarity and length in overt picture naming 
 J Cogn Neurosci 
 19 
 4 
 617 
 631 
 17381253 
 
 
 
 
 
 
 Guenther 
 FH 
 
 
 Ghosh 
 SS 
 
 
 Tourville 
 JA 
 
 
 2006 
 Neural modeling and imaging of the cortical interactions underlying syllable production 
 Brain Lang 
 96 
 3 
 280 
 301 
 16040108 
 
 
 
 
 
 
 Hayasaka 
 S 
 
 
 Nichols 
 TE 
 
 
 2003 
 Validating cluster size inference: random field and permutation methods 
 Neuroimage 
 20 
 4 
 2343 
 2356 
 14683734 
 
 
 
 
 
 
 Heim 
 S 
 
 
 Eickhoff 
 SB 
 
 
 Ischebeck 
 AK 
 
 
 Friederici 
 AD 
 
 
 Stephan 
 KE 
 
 
 Amunts 
 K 
 
 
 2007 
 Effective connectivity of the left BA 44, BA 45, and inferior temporal gyrus during lexical and phonological decisions identified with DCM 
 Hum Brain Mapp [Internet] 
 Available from:  http://dx.doi.org/10.1002/hbm.20512 
 
 
 
 
 
 
 Hickok 
 G 
 
 
 Buchsbaum 
 B 
 
 
 Humphries 
 C 
 
 
 Muftuler 
 T 
 
 
 2003 
 Auditory-motor interaction revealed by fMRI: speech, music, and working memory in area Spt 
 J Cogn Neurosci 
 15 
 5 
 673 
 682 
 12965041 
 
 
 
 
 
 
 Hickok 
 G 
 
 
 Poeppel 
 D 
 
 
 2004 
 Dorsal and ventral streams: a framework for understanding aspects of the functional anatomy of language 
 Cognition 
 92 
 1–2 
 67 
 99 
 15037127 
 
 
 
 
 
 
 Hickok 
 G 
 
 
 Poeppel 
 D 
 
 
 2007 
 The cortical organization of speech processing 
 Nat Rev Neurosci 
 8 
 5 
 393 
 402 
 17431404 
 
 
 
 
 
 
 Iacoboni 
 M 
 
 
 2005 
 Understanding others: Imitation, language, empathy 
 Perspectives on imitation: from cognitive neuroscience to social science 
 1 
 Cambridge, MA 
 MIT Press 
 
 
 
 
 
 
 Indefrey 
 P 
 
 
 Levelt 
 WJM 
 
 
 2004 
 The spatial and temporal signatures of word production components 
 Cognition 
 92 
 1–2 
 101 
 144 
 15037128 
 
 
 
 
 
 
 Indefrey 
 P 
 
 
 Levelt 
 W 
 
 
 
 
 Gazzaniga 
 M 
 
 
 2000 
 The new cognitive neurosciences 
 Cambridge, MA 
 MIT Press 
 845 
 865 
 
 
 
 
 
 
 Jusczyk 
 P 
 
 
 Luce 
 P 
 
 
 Charles-Luce 
 J 
 
 
 1994 
 Infants’ sensitivity to phonotactic patterns in the native language 
 Journal of Memory and Language 
 33 
 630 
 645 
 
 
 
 
 
 
 Kellman 
 P 
 
 
 Gelderen 
 PV 
 
 
 Zwart 
 JAD 
 
 
 Duyn 
 JH 
 
 
 2003 
 Method for functional MRI mapping of nonlinear response 
 Neuroimage 
 19 
 1 
 190 
 199 
 12781738 
 
 
 
 
 
 
 Levelt 
 
 
 1999 
 Models of word production 
 Trends Cogn Sci 
 3 
 6 
 223 
 232 
 10354575 
 
 
 
 
 
 
 Liberman 
 AM 
 
 
 Mattingly 
 IG 
 
 
 1985 
 The motor theory of speech perception revised 
 Cognition 
 21 
 1 
 1 
 36 
 4075760 
 
 
 
 
 
 
 Mazaika 
 P 
 
 
 Whitfield-Gabrieli 
 S 
 
 
 Reiss 
 A 
 
 
 2007 
 Artifact Repair for fMRI Data from High Motion Clinical Subjects 
 Human Brain Mapping Conference 
 
 
 
 
 
 
 Molnar-Szakacs 
 I 
 
 
 Iacoboni 
 M 
 
 
 Koski 
 L 
 
 
 Mazziotta 
 JC 
 
 
 2005 
 Functional segregation within pars opercularis of the inferior frontal gyrus: evidence from fMRI studies of imitation and action observation 
 Cereb Cortex 
 15 
 7 
 986 
 994 
 15513929 
 
 
 
 
 
 
 Oakes 
 TR 
 
 
 Johnstone 
 T 
 
 
 Walsh 
 KSO 
 
 
 Greischar 
 LL 
 
 
 Alexander 
 AL 
 
 
 Fox 
 AS 
 
 
 Davidson 
 RJ 
 
 
 2005 
 Comparison of fMRI motion correction software tools 
 Neuroimage 
 28 
 3 
 529 
 543 
 16099178 
 
 
 
 
 
 
 Okada 
 K 
 
 
 Hickok 
 G 
 
 
 2006 
 Identification of lexical-phonological networks in the superior temporal sulcus using functional magnetic resonance imaging 
 Neuroreport 
 17 
 12 
 1293 
 1296 
 16951572 
 
 
 
 
 
 
 Poldrack 
 RA 
 
 
 Wagner 
 AD 
 
 
 Prull 
 MW 
 
 
 Desmond 
 JE 
 
 
 Glover 
 GH 
 
 
 Gabrieli 
 JD 
 
 
 1999 
 Functional specialization for semantic and phonological processing in the left inferior prefrontal cortex 
 Neuroimage 
 10 
 1 
 15 
 35 
 10385578 
 
 
 
 
 
 
 Riecker 
 A 
 
 
 Mathiak 
 K 
 
 
 Wildgruber 
 D 
 
 
 Erb 
 M 
 
 
 Hertrich 
 I 
 
 
 Grodd 
 W 
 
 
 Ackermann 
 H 
 
 
 2005 
 fMRI reveals two distinct cerebral networks subserving speech motor control 
 Neurology 
 64 
 4 
 700 
 6 
 15728295 
 
 
 
 
 
 
 Vitevitch 
 MS 
 
 
 Luce 
 PA 
 
 
 Charles-Luce 
 J 
 
 
 Kemmerer 
 D 
 
 
 1997 
 Phonotactics and syllable stress: implications for the processing of spoken nonsense words 
 Lang Speech 
 40 
 Pt 1 
 47 
 62 
 9230698 
 
 
 
 
 
 
 Vitevitch 
 MS 
 
 
 Luce 
 PA 
 
 
 Pisoni 
 DB 
 
 
 Auer 
 ET 
 
 
 1999 
 Phonotactics, neighborhood activation, and lexical access for spoken words 
 Brain Lang 
 68 
 1–2 
 306 
 311 
 10433774 
 
 
 
 
 
 
 Vitevitch 
 M 
 
 
 Luce 
 P 
 
 
 1998 
 When Words Compete: Levels of processing in perception of spoken words 
 Psychological Science 
 9 
 4 
 325 
 329 
 
 
 
 
 
 
 Vitevitch 
 MS 
 
 
 Luce 
 PA 
 
 
 2004 
 A web-based interface to calculate phonotactic probability for words and nonwords in English 
 Behav Res Methods Instrum Comput 
 36 
 3 
 481 
 487 
 15641436 
 
 
 
 
 
 
 Zatorre 
 RJ 
 
 
 Evans 
 AC 
 
 
 Meyer 
 E 
 
 
 Gjedde 
 A 
 
 
 1992 
 Lateralization of phonetic and pitch discrimination in speech processing 
 Science 
 256 
 5058 
 846 
 9 
 1589767 
 
 
 
 
 
 
 Zatorre 
 RJ 
 
 
 Meyer 
 E 
 
 
 Gjedde 
 A 
 
 
 Evans 
 AC 
 
 
 1996 
 PET studies of phonetic processing of speech: Review, replication, and reanalysis 
 Cerebral Cortex 
 6 
 1 
 21 
 30 
 8670635 
 
 
 
 
 
 
 Zwart 
 JAD 
 
 
 Gelderen 
 PV 
 
 
 Kellman 
 P 
 
 
 Duyn 
 JH 
 
 
 2002 
 Reduction of gradient acoustic noise in MRI using SENSE-EPI 
 Neuroimage 
 16 
 4 
 1151 
 1155 
 12202101 
 
 
 
 
 
 
 Zwart 
 JAD 
 
 
 Ledden 
 PJ 
 
 
 Gelderen 
 PV 
 
 
 Bodurka 
 J 
 
 
 Chu 
 R 
 
 
 Duyn 
 JH 
 
 
 2004 
 Signal-to-noise ratio and parallel imaging performance of a 16-channel receive-only brain coil array at 3.0 Tesla 
 Magn Reson Med 
 51 
 1 
 22 
 26 
 14705041 
 
 
 
 
