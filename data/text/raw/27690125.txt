
 properties manuscript? 
 
 
 7506220 
 1919 
 Brain Lang 
 Brain Lang 
 
 Brain and language 
 
 0093-934X 
 1090-2155 
 
 
 27690125 
 5179296 
 10.1016/j.bandl.2016.09.007 
 NIHMS819753 
 
 
 Article 
 
 
 
 Bilateral parietal contributions to spatial language 
 
 
 
 
 Conder 
 Julie 
 
 1 
 
 
 
 Fridriksson 
 Julius 
 
 2 
 
 
 
 Baylis 
 Gordon C. 
 
 3 
 
 
 
 Smith 
 Cameron M. 
 
 4 
 5 
 
 
 
 Boiteau 
 Timothy W. 
 
 4 
 5 
 
 
 
 Almor 
 Amit 
 
 4 
 5 
 6 
 
 
 1 McMaster University, Department of Psychology, Neuroscience & Behaviour 
 2 University of South Carolina, Department of Communication Sciences and Disorders 
 3 Western Kentucky University, Department of Psychological Sciences 
 4 Department of Psychology 
 5 Institute for Mind and Brain 
 6 Linguistics Program 
 
 Contact: Amit Almor, Psychology Department, Linguistics Program & Institute for Mind and Brain, University of South Carolina, 1512 Pendleton Street, Columbia, SC 29208,  almor@sc.edu , Office: (803)777-4302, Fax: (803)777-9558 
 
 
 28 
 9 
 2016 
 
 
 28 
 9 
 2016 
 
 
 1 
 2017 
 
 
 01 
 1 
 2018 
 
 164 
 16 
 24 
 
 
 This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law. 
 
 
 
 It is commonly held that language is largely lateralized to the left hemisphere in most individuals, whereas spatial processing is associated with right hemisphere regions. In recent years, a number of neuroimaging studies have yielded conflicting results regarding the role of language and spatial processing areas in processing language about space (e.g.,  Carpenter, Just, Keller, Eddy & Thulborn, 1999 ;  Damasio et al., 2001 ). In the present study, we used sparse scanning event-related functional magnetic resonance imaging (fMRI) to investigate the neural correlates of spatial language, that is; language used to communicate the spatial relationship of one object to another. During scanning, participants listened to sentences about object relationships that were either spatial or non-spatial in nature (color or size relationships). Sentences describing spatial relationships elicited more activation in the superior parietal lobule and precuneus  bilaterally  in comparison to sentences describing size or color relationships. Activation of the precuneus suggests that spatial sentences elicit spatial-mental imagery, while the activation of the SPL suggests sentences containing spatial language involve integration of two distinct sets of information – linguistic and spatial. 
 
 
 Spatial Language 
 Parietal Lobe 
 Precuneus 
 Laterality 
 fMRI 
 
 
 
 
 Introduction 
 Many aspects of language processing are localized to the left hemisphere in the majority of people, as originally suggested by Marc  Dax (1865)  and later by Paul Broca in 1865 ( Broca, P., 1865 ;  Manning & Thomas-Antérion, 2011 ). Conversely, spatial processing is primarily localized to the right hemisphere ( Witelson, 1976 ). These observations were originally established on the basis of patient studies showing consistent links between language impairments and left hemisphere damage, particularly in specific frontal and temporal regions, and between impaired spatial processing and right hemisphere damage (e.g., Dronkers, Redfern, & Knight, 1994;  Karnath, Berger, Küker, & Rorden, 2004 ). More recently, this distinction has been further corroborated by brain imaging studies using different techniques, such as positron emission tomography (PET), functional magnetic resonance imaging (fMRI), transcranial magnetic stimulation, and functional transcranial Doppler sonography (e.g.,  Duecker, Formisano, & Sack, 2013 ;  Gutierrez-Sigut, Payne, & MacSweeney, 2015 ;  Richardson, Fillmore, Rorden, Lapointe, & Fridriksson, 2012 ). 
 Although the neural circuits underlying the two types of processes are likely distinct, linguistic and spatial processing must interface to some degree, as in the case of “spatial language,” which allows language users to communicate about the location of objects ( Chatterjee, 2001 ). Although different languages encode spatial relations in slightly different ways, spatial language is generally characterized by a systematic schematization of space and the use of one region (the “ground”) to describe the location of another (the “figure”;  Talmy, 2000 ;  Levinson, 2003 ;  Bowerman, 1996 ). In many languages, this spatial language hinges on a small set of closed-class words ( Landau & Jackendoff, 1993 ). For example, in English, spatial descriptions involve a relatively small number of prepositions ( in ,  on , etc.) used to describe the location of a figure in terms of its spatial relation to a ground (e.g.,  the bird [figure] is in the tree [ground] .) The universal properties of the language of space suggests that this aspect is unique within language, but its relation to general spatial processing in the brain remains unclear. Does this type of language processing involve neural circuitry that is shared by more general nonlinguistic spatial processing? The research we report here aims to address this question by examining the neural basis of the language of space. Before describing our research in detail, we provide a short review of the existing literature. 
 
 Brain bases of spatial language 
 Landau and Jackendoff (1993)  proposed that the schematization found in spatial language reflects the properties of the underlying neural circuits. Building upon evidence for the existence of separate dorsal and ventral pathways in the visual system (e.g.,  Ungerleider & Mishkin, 1982 ;  Ungerleider & Haxby, 1994 ), Landau and Jackendoff theorized that processing spatial language engages the dorsal visual pathway, which is important for identifying the location of objects (the “where” system), whereas object descriptions and identification engage the ventral system, which is important for object recognition (the “what” system). In line with this prediction, a number of neuroimaging studies found evidence for the involvement of the parietal lobe in processing spatial language (e.g.,  Carpenter, Just, Kelley, Eddy, & Thulborn, 1999 ;  Damasio, Grabowski, Tranel, Ponto, Hichwa, & Damasio, 2001 ;  Emmorey et al., 2005 ;  Noordzij, Neggers, Ramsay, & Postma, 2008 ;  Wallentin et al., 2008 ).  Damasio and colleagues (2001)  showed that naming spatial relationships compared to object naming evoked activity in the left inferior parietal lobe. Interestingly, when the spatial relation task was compared to a control task involving normal or inverted faces, which also contains a spatial component, differences in activation were found only in left frontal and temporal regions, but not in any parietal regions. This further supports the role of the left parietal regions in spatial processing and spatial language. 
 A series of patient studies by Kemmerer and Tranel further supports the role of left parietal regions in spatial language ( Kemmerer and Tranel, 2003 ;  Tranel and Kemmerer, 2004 ).  Kemmerer and Tranel (2003)  found a double dissociation: damage to the left frontal operculum was associated with deficits in understanding action verbs, whereas damage to the left inferior and superior parietal regions was associated with deficits in understanding locative prepositions. In a follow-up study,  Tranel and Kemmerer (2004)  examined six patients who showed pervasive deficits in processing spatial language and found that these deficits were associated with damage to the posterior left front operculum, inferior left parietal operculum, and the underlying white matter. Together, these results provide further support for the involvement of left parietal and frontal regions as well as the connective path between them in spatial language processing. 
 While the evidence reviewed so far suggests that spatial language is left lateralized, other evidence might be taken to suggest bilateral involvement. An early study on language comprehension using fMRI found that comparing spatial descriptions (a linguistic task component) to spatial configurations of objects (a visuospatial task component) was associated with increased activity in the posterior left temporal gyrus but also in visuospatial parietal areas  bilaterally  ( Carpenter et al., 1999 ). However, given the nature of the picture comparison task, the bilateral parietal involvement may be more explicitly related to visuospatial  processing , as opposed to spatial  language  per se.  Wallentin et al. (2005)  similarly found bilateral frontal and parietal activity associated with the processing of sentences describing movement towards concrete spatial locations (e.g.,  into the labyrinth ), while movement towards abstract locations (e.g.,  into madness ) evoked more left-lateralized activity. Examining the BOLD activation associated with answering spatial vs. non-spatial recall questions about the figures in a previously viewed scene,  Wallentin, Roepstorff, Glover, and Burgess (2006)  found that recalling spatial information led to bilateral activation of the precuneus, and  Wallentin et al. (2008)  found a very similar finding when participants comprehended descriptions of scenes presented via headphones. Thus, while there is consistent evidence for lateralization of spatial processing to the right hemisphere and language processing to the left hemisphere, there is little consensus as to whether or not spatial language processing is predominantly uni- or bi-lateral. 
 While the language of space in spoken languages is largely schematic ( Landau & Jackendoff, 1993 ), sign languages, perhaps as a function of their use of the visuospatial medium, employ much richer spatial language that is capable of expressing spatial relations in great accuracy. Comparing the neural activation of individuals fluent in both English and American Sign Language (ASL) using PET,  Emmorey et al. (2005)  found significant bilateral activation of the parietal cortex during production of spatial language, regardless of whether this production was in English or ASL; however, greater activation of the right parietal cortex was associated with production in ASL. This greater activation may, in part, be due to the visual-to-motoric transformation of language that is necessary in ASL production ( Emmorey et al., 2005 ). However, this difference in parietal recruitment between the two languages may also reflect an asymmetry between the right and left parietal lobes, with the right parietal lobe possibly specializing in precise spatial coordinates and the left in categorical spatial relations ( Castelli, Glaser, & Butterworth, 2006 ;  Kemmerer & Tranel, 2000 ;  Kosslyn, Sokolov, & Chen, 1989 ). Notably, ASL has two alternative spatial constructions: classifier predicates, in which detailed spatial relationships can be communicated, and prepositions, a closed class of words similar to English prepositions in that they only express categorical spatial relations ( Emmorey et al., 2002 ). Neuroanatomically, these two constructions are quite distinct, with the classifier constructions employing bilateral parietal regions, and the ASL prepositions more left lateralized ( Emmorey et al., 2002 ). Thus, the inherently spatial medium used by sign language appears to allow for the usage of a precise coordinate system in the right parietal lobe for certain types of spatial descriptions, whereas spoken English spatial descriptions and ASL spatial prepositions recruit the left categorical system ( Emmorey et al., 2002 ,  2005 ). 
 In summary, although the question of whether spatial language processing is left lateralized or bilateral is of theoretical importance in that it can inform the understanding of hemispheric specialization, previous results are inconsistent. One goal of the present research is to test whether processing spoken English spatial description is bilateral or dominantly left lateralized. 
 
 
 Regions of the parietal lobe in spatial language 
 Although most studies of spatial language have implicated the parietal regions, there is little agreement about which specific parietal areas are involved. Implicated areas include the parietal lobule as a whole, the supramarginal gyrus, the intraparietal sulcus, the superior parietal lobule (SPL) and the precuneus (e.g.,  Carpenter et al., 1999 ;  Damasio et al., 2001 ;  Emmorey et al., 2002 ,  2005 ;  Kemmerer & Tranel, 2003 ;  Wallentin et al., 2005 ;  Wallentin et al., 2006 ;  Wallentin et al., 2008 ). In particular, the supramarginal gyrus (SMG) has been implicated in many studies, though only in the left hemisphere ( Damasio et al., 2001 ;  Kemmerer & Tranel, 2000 ;  Tranel & Kemmerer, 2004 ;  Emmorey et al., 2002 ,  2005 ).  Carpenter et al. (1999)  and  Emmorey et al. (2005)  also found activation of the right SMG and right precuneus.  Wallentin et al. (2005 ,  2006 ,  2008 ) also found bilateral activation of the precuneus across three very different types of spatial linguistic tasks. 
 There are a number of possible reasons for the inconsistencies seen across neuroimaging studies of spatial language. First, the stimuli used to elicit activation for spatial language have varied widely across studies, including: actual photographs of objects (e.g.,  Amorapanth, Widick, & Chatterjee, 2010 ;  Damasio et al., 2001 ,  Kemmerer & Tranel, 2003 ), line drawings of objects (e.g.,  Carpenter et al., 1999 ;  Damasio et al., 2001 ;  Kemmerer & Tranel, 2003 ;  Noordzij et al., 2008 ), computer-generated images (e.g.,  Wallentin et al., 2006 ), and linguistic stimuli (e.g.,  Noordzij et al., 2008 ;  Wallentin et al., 2008 ). The results from studies that have relied on pictorial stimuli are especially difficult to interpret because the parietal activation found in these studies may have been linked to a combination of visual and spatial process, instead of a spatiallinguistic process. To examine this possibility,  Noordzij et al. (2008)  used both verbal and mixed verbal-pictorial sets of stimuli and contrasted spatial to non-spatial sentences. They found that regardless of the context of the information (verbal-only or verbal-visuospatial), the left SMG was activated in response to locative prepositions. No activation was found in the right hemisphere or in other parts of the left hemisphere. However, because Noordzij et al. only report their results from contrasts that includes both the verbal and pictorial stimuli, and because they also included the hemodynamic activation elicited by the decision making part of their task, it is still unclear whether their results reflect the processing of spatial language, the visual stimuli, or the decision-making aspects of the task. Indeed, a general difficulty in comparing the results of existing spatial language studies is that they employed different tasks and the reported analyses often include activations associated with task performance together with the activation associated with the spatial processing under investigation. For example, frontal cortical activity may be a result of using explicit decision-making process in some conditions (e.g.,  Damasio et al., 2001 ). 
 Given the limitations of previous work, the present study aimed to carefully examine differences in brain activation between spatial and non-spatial language without the confounding effects of visual stimuli or the activation associated with the performance of a secondary task. We employed sparse scanning, an fMRI sequence in which the scanner is turned on intermittently, so as to allow the presentation of auditory stimuli without any scanner noise. In order to achieve a tight comparison between spatial and non-spatial language we contrasted the comprehension of spoken sentences that described spatial relations between objects using locative prepositions with sentences that described visual non-spatial relations between objects (size and color). To ensure participants were processing the sentences for comprehension, on some trials, participants had to make a judgment about whether a picture shown after a short delay matched the preceding sentence. Importantly, we did not include the data from these (overt response) trials in the analyses in order to isolate the brain activation associated with processing the sentences without any confounds from either visual processing or the judgment task. Our research specifically aimed to test whether processing spatial language is bilateral or left lateralized and ascertain which specific areas in the parietal lobe are involved. 
 
 
 
 Method 
 
 Participants 
 Seventeen participants (15 female, 2 male, age 18–25 years) with no history of neurological disorders or psychiatric illness participated in the study. All participants were native speakers of English, were right handed, and had normal or corrected-to-normal vision. Participants were screened to ensure their safety in the scanner. All participants gave informed consent as approved by the Institutional Review Board at the University of South Carolina. 
 
 
 Stimuli 
 24 spatial and 24 non-spatial sentences were constructed. Each sentence described the relationship of one geometric shape to another and lasted approximately 2 to 2.5 seconds. Non-spatial sentences included information about the brightness or size of one shape in relation to the other; spatial sentences contained information about the horizontal or vertical spatial relationship of one shape to the other (see  Table 1  for example sentences). The spatial condition included an equal numbers of left, right, above, and below (6 each, for a total of 24 sentences). Non-spatial comparisons had 6 each of light, dark, small and large, also for a total of 24 sentences. Sentences consisted of 6–8 words and the two conditions had an overall similar number of words,  t (23) = 1. 6,  p  = .12. Stimuli were digitally recorded with an audio interface in a sound booth. 
 
 
 fMRI task and procedure 
 Participants underwent a 6-minute T1-weighted scan and a 16-minute functional sparse scanning sequence. During the sparse scanning sequence, participants listened to 96 sentences from two conditions (non-spatial and spatial) such that each sentence was heard twice by each participant. The sentences was presented via noise-attenuating MRI-compatible headphones (Resonance Technology). The order of sentence presentation was randomized for each participant. Wait times presented before and after auditory stimuli were randomly jittered to increase power and adequately sample the hemodynamic response (see  Figure 1  for a schematic of an experimental trial). 
 After 20% of the sentence trials, a visual image consisting of two geometric shapes in a configuration that either matched or did not match the preceding sentence was presented for 2 seconds. There was an equal number of matching and non-matching trials in the experiment. Visual stimuli were projected using a back-projection mirror mounted on the head coil and a projection screen located at the end of the scanner. Visual stimuli were counterbalanced across all shapes (circles, squares, triangles), colors, sizes, and spatial configurations. Geometric shapes were presented in either black or grey for the “brighter or darker” condition and were either 2 cm or 5 cm in the “smaller or larger” condition (see  Figure 2  for example visual stimuli). Visual comparisons were designed to be easy so as to not influence the next trial. Inter-stimulus intervals averaged 7.4 seconds and were jittered between 3.2 and 9.16 seconds. Participants were not informed of when a visual image might appear. The participant was required to decide whether the visual image matched the preceding sentence with a button press. Button presses were recorded using an MRI-compatible glove. However, as these trials introduced activity (e.g. decision-making, motoric) not relevant to the primary research question, they were not included in the functional analysis. Accuracy performance on these trials was monitored. All stimuli and responses were presented and recorded using E-Prime presentation software (Psychology Software Tools Inc., Pittsburgh, PA). 
 
 
 MRI data acquisition 
 Scanning was performed using a 3T Siemens Trio MRI scanner equipped with a 12-channel headcoil (Munich, Germnay). The anatomical scans were a TFE (MPRAGE) sequence. This employs a TI of 900 ms, a delay of 2250 ms between TFE shots and a 90 degree flip angle, with a very short TE (4.5 ms). This sequence is capable of collecting a 1 mm isotropic volume (256×256×160 mm). For the purpose of fMRI data acquisition, a total of 322 echo-planar imaging (EPI) volumes were acquired in each session (36 axial slices, 3.2 mm thick, no slice gap). Other parameters for the functional scanning sequence were as follows: TR = 10 s (long TR was necessitated by the sparse scanning technique), TI = 2 s, TE = 30 ms, matrix = 64 × 64 voxels, flip angle 90°. Voxels were 3 mm 3 . 
 Sparse scanning was employed so that participants would be able to clearly hear the auditory stimulus without interference from scanner noise. In sparse scanning, the stimulus is presented during a pause in scanning, after which a whole head volume is collected. A TR of 10 seconds was chosen so that the modeled hemodynamic response delay of approximately 6 seconds was recorded following each auditory stimulus. Due to the random presentation of stimuli, a three-column custom timing event file was recorded during testing for each participant and was input at the lower-level analysis for each participant. The timing event file included: the timing of stimulus presentations, the length of each stimulus, and the weighting of each stimulus, which was set at a constant ‘1’ because our design did not include differential stimuli weighting. This design was then convolved with a double-gamma HRF function, a setting that combines two gamma functions: the first modeling the standard known gamma lag of the HRF function and a second, smaller gamma function attempting to model the undershoot following most spikes in hemodynamic responses. 
 
 
 fMRI data analysis 
 All preprocessing and statistical analyses were performed using FEAT (FMRI Expert Analysis Tool) Version 6.00, part of FSL (FMRIB’s Software Library,  www.fmrib.ox.ac.uk/fsl ). Registration to the high resolution structural images was carried out using FLIRT ( Jenkinson 2001 ,  2002 ). Registration from high resolution structural to standard Montreal Neurological Institute 152 1 mm space ( Jenkinson, Bannister, Brady, & Smith, 2002 ) was then further refined using FNIRT nonlinear registration ( Andersson 2007a ,  2007b ). Preprocessing of the fMRI data included motion correction using MCFLIRT ( Jenkinson 2002 ), non-brain removal using BET ( Smith 2002 ), spatial smoothing using a Gaussian kernel of FWHM 8.0mm, mean intensity normalization, and highpass temporal filtering (Gaussian-weighted least-squares straight line fitting, with sigma = 45.0s). For lower-level analyses, the cortical activation of each participant was modeled with separate regressors for the spatial language condition, non-spatial language condition, question trials with spatial language and yes answer, question trials with spatial language and no answer, question trials with non-spatial language and yes answer, and question trials with non-spatial language and no answer. The model also included the first (temporal) derivative of these regressors. Although the average motion estimated by MCLIRT for all participants was smaller than 3mm, we sought to further reduce motion artefacts by including in the model the six motion covariates generated by MCFLIRT for each participant. We then calculated two contrasts using only the spatial language and non-spatial language regressors: spatial > non-spatial and non-spatial > spatial. Z-statistic images were created for the two contrasts for each participant and high-level analysis was conducted by averaging across participants’ individual Z-maps. Cluster correction was used to address family-wise error using Z > 2.3 and p < .05 threshold criteria ( Worsley, 1992 ). 
 
 
 
 Results 
 
 Behavioral results 
 The accuracy on trials including visual stimuli was analyzed to ensure that participants were paying attention to the auditory stimuli. As participants did not know on which trials these visual targets would appear, low accuracy would indicate that the participant was not paying attention to the stimuli and/or did not understand the task. Data from one participant were excluded due to chance performance in the comprehension task (43.75% correct.) The accuracy of the remaining participants ranged from 68.75% to 100 % (mean = 91.80%, SD = 8.1), representing performance better than chance at a  p  < .1 level. This non-conservative criterion for above-chance performance was chosen so as to minimize data loss. Performance of the remaining 16 participants (14 female) on spatial items (mean = 89.71%, SD = 16.1) was not significantly different than performance on non-spatial items (mean = 93.38%, SD = 10),  t (15) = 0.77,  p  = 0.45. 
 
 
 fMRI results 
 The key data in this experiment concerned brain activation related to the two language conditions which we analyzed through the spatial > non-spatial and non-spatial > spatial contrasts. 
 
 Spatial > Non-spatial 
 This contrast revealed one significant cluster showing greater activation in the spatial than in the non-spatial condition. This cluster included bilateral regions including the SPL, Precuneus, and the parietal/occipital juncture (see  Figure 3  and  Table 2 ) with both hemispheres showing similar activation for this contrast. To further test whether this activation was truly bilateral we followed this whole-brain analysis with Region of Interest (ROI)-based lateralization analyses focusing on regions included in the cluster: the left and right SPL, Precuneus, and the Superior Occipital Gyrus. Following the general method used in  Wallentin et al. (2014)  for analyzing laterality effects, we used the Oxford Harvard Anatomical Atlas included with FSL in order to identify the SPL, Precuneus and the Lateral Occipital Cortex, superior division bilaterally, and then split these anatomical ROIs to their left and right parts. We then used FEATQUERY to extract the mean % signal change in these regions in the spatial and non-spatial language conditions relative to the fixation baseline in each participant, and then calculated laterality scores for each condition for each participant by subtracting the activation in the right from the activation in the left. Paired t-tests contrasting these laterality scores in the spatial language and the non-spatial language conditions found no difference in lateralization between the two conditions in either the SPL ( mean spatial  = .061,  mean non-spatial  = .051, t(15) < 1), Precuneus ( mean spatial  = .067,  mean non-spatial  = .079, t(15) = 1.74,  p  > .1), or the Superior Lateral Occipital Cortex ( mean spatial  = .070,  mean non-spatial  = .032, t(15) = 1.51,  p  > .1). This analysis revealed that the spatial vs. non-spatial contrast resulted in similar increased activation for spatial language within the left and right SPL, within left and right Precuneus, and within the left and right Superior Occipital Cortex. 
 
 
 Non-Spatial > Spatial 
 This contrast revealed two significant clusters showing greater activation in the non-spatial than in the spatial condition. Both clusters included left frontal regions. One cluster included inferior frontal regions and the other superior frontal regions (see  Table 2  and  Figure 3 ). 
 
 
 
 
 Discussion 
 Sentences describing spatial relationships elicited significantly more activation than sentences describing non-spatial visual relationships in the superior occipital lobe as well as in two parietal areas: the precuneus and the SPL. Importantly, these differences were observed in both hemispheres thus supporting the involvement of the parietal lobe in processing spatial language bilaterally during spoken language comprehension. Our careful comparison of spatial vs. non-spatial visual descriptions together with our use of auditory linguistic stimuli in a sparse scanning design that excluded explicit decision-making trials lends credence to interpreting these activations as indicating the specific processing of spatial language. We also found that non-spatial sentences elicited greater frontal activation than spatial sentences and that activation was left lateralized. We discuss each of these findings in turn. 
 Previous research on the neural bases of spatial language has been inconclusive with respect to lateralization with some studies reporting activation in only the left hemisphere (e.g.  Damasio et al., 2001 ;  Kemmerer & Tranel, 2003 ;  Tranel & Kemmerer, 2004 ) and others reporting bilateral activation (e.g.  Carpenter et al., 1999 ;  Wallentin et al., 2005 ;  Wallentin et al., 2006 ;  Wallentin et al., 2008 ). The question of whether there are hemispheric differences in processing spatial language is important because it bears on central claims related to hemispheric specialization. For example,  Emmorey and colleague’s (2005)  finding of bilateral activation in bilingual speakers using ASL to describe space as opposed to left lateralized activation when using English has been interpreted as supporting the right hemisphere’s greater involvement in processing spatial information, which is more critical for ASL than for English. Similarly,  Emmorey and colleague’s (2002)  finding of greater left activation when processing ASL prepositional spatial language than when processing ASL classifiers has been attributed to the right hemisphere’s specialization for processing detailed information vs. the left hemisphere specialization for processing schematic information. Our results, however, indicate that, in a tightly controlled comparison between spatial and non-spatial descriptions, the spatial descriptions result in more activation bilaterally. This indicates that despite their grammatical function and inherent schematic meaning, spoken English prepositions are processed by both hemispheres. Our results thus suggest that previous reports of hemispheric differences in processing spatial language could have resulted from measuring responses to visual stimuli (e.g.,  Tranel, & Kemmerer, 2004 ), task demands (see  Noordzij et al., 2008 ) or, in the case of the sign language studies, their inherently spatial medium (e.g.,  Emmorey et al., 2002 ;  2005 ). Similarly, the fact that  Noordzij, et al. (2008)  and Damasio ( Damasio, 2001 ) who found inferior rather than superior parietal regions associated with spatial vs non-spatial language likely also reflects the complexity of task and involvement of visual stimuli in these studies. Our study is unique in that we only analyzed response to spatial vs. non-spatial language in trials that required no response and involved no visual stimuli at all. 
 We now turn to discuss the specific regions activated in our study. Our finding of precuneus activation supports previous claims that this region is more strongly activated when processing spatial descriptions than when processing visual non-spatial descriptions ( Emmory et al., 2005 ;  Wallentin et al., 2008 ). Given the likely role of this region in mental imagery ( Bonda, Petrides, Frey, & Evans, 1995 ;  Knauff et al., 2003 ), our results are consistent with the notion that processing spatial language entails considerable mental imagery resources. Although it could be argued that our task forced participants to generate mental images in order to respond to the actual images, all of the stimuli in the present study involved mental imagery (e.g. visualizing a spatial relationship or a non-spatial relationship between two shapes). Critically, the trials involving imagery of spatial relationships elicited greater precuneus activation than those that did not, suggesting a greater role of the precuneus and mental imagery in processing spatial descriptions than in the processing of non-spatial visual descriptions. Furthermore, we were careful not to include data from trials in which participants were asked to respond, making it less likely that our data reflects a task specific response that is not representative of language more generally. Finally, the fact that greater activation in the spatial language conditions also extended to superior occipital regions further supports the interpretation of these activations as reflecting mental imagery. Our finding of greater precuneus activation are similar to those of  Emmorey and colleagues (2005 ,  2013)  with ASL users, and show that these findings were not just a reflection of the visual-spatial modality of ASL, but a more general reflection of spatial language processing in general. Additionally,  Wallentin et al. (2006 ,  2008 ) found bilateral precuneus activation in spatial recall tasks, taxing spatial working memory and imagery of spatial relations. The authors link their findings to imagery. 
 The other region our study found to be more strongly activated by spatial language than by non-spatial language was the SPL. The superior parietal cortex in general has been associated with the manipulation of information in working memory ( Koenigs, Barbey, Postle, & Grafman, 2009 ), processing of spatial relationships in both American and British Sign Language ( Emmorey et al., 2005 ;  MacSweeney et al., 2002 ), and spatial attention in general ( Corbetta, Miezin, Shulman, & Petersen, 1993 ). The SPL, in particular, has been associated with a number of functions related to spatial attention, such as shifting spatial attention ( Molenberghs, Mesulam, Peeters, & Vandenberghe, 2007 ), the communication of location and spatial classifiers in ASL ( Emmorey et al., 2002 ;  2005 ;  2013 ), maintaining an internal representation of body position ( Wolpert, Goodbody, & Husain, 1998 ), integrating audiovisual information ( Molholm et al., 2006 ), coordinating actions in space ( Segal & Petrides, 2012 ), completion of spatial mental tasks, such as mental mazes ( Jerde et al., 2008 ), keeping track of referents in discourse ( Almor et al., 2007 ), and the representation and processing of plural entities in language comprehension ( Boiteau, Bowers, Nair, & Almor, 2014 ). The varied functions of the SPL in spatial attentional processes are of particular interest to the present study, which was primarily a study of language, not of spatial attention. 
 As previously mentioned, studies of sign languages have revealed significant parietal activations including the SPL in constructions involving spatial information relative to signing nouns or object names ( Emmorey et al., 2002 ,  2005 ,  2013 ;  MacSweeney et al., 2002 ). One possible explanation of this finding relates to  Wolpert and colleagues’ (1998)  suggestion that the SPL plays a key role in maintaining awareness of the state of the body and keeping an internal representation of the body. Wolpert and colleagues specifically argued that the SPL has an integrative role with regard to multisensory kinesthetic information.  Molholm and colleagues (2006)  similarly argued that the SPL is involved in the spatial processing of the multisensory stimuli. The role of the SPL in kinesthetic integration and in maintaining body awareness may suggest that the role of the SPL in studies of sign language may be due to the use of the body in communication in sign language. Such awareness is clearly necessary when using sign language due to the highly visual spatial nature of the medium and the importance of the personal space of signers for making various linguistic distinctions. Despite making general sense, this explanation is insufficient because spatial constructions but not non-spatial constructions result in SPL activation in both ASL ( Emmorey et al., 2002 ;  2005 ;  2013 ) and BSL ( MacSweeney et al., 2002 ). This activation suggests that the SPL may be preferentially activated for the integration of linguistic and spatial information in sign languages beyond the activation suggested by the modality of sign languages themselves. Indeed, our own results suggest that the SPL has a unique role in spatial language that goes beyond the keeping track of body position and location (e.g.,  Emmorey et al., 2013 ;  MacSweeney et al., 2002 ) and sensorimotor information (e.g.  Molholm et al., 2006 ;  Wolpert et al., 1998 ) that is necessary when using sign language. 
 We instead believe that the involvement of SPL in processing spatial language reflects its role in maintaining and integrating multiple representations that are characterized by a configurational relation in which one representation is defined in terms of its configurational relation to another. In the case of spatial descriptions, this configuration expresses the location of one object (the figure) in terms of another (the ground) ( Landau & Jackendoff, 1993 ). This explanation is compatible with  Molenberghs and colleagues (2007)  who suggest that the SPL is involved in spatial attention to spatial configurations of stimuli, whereas inferior parietal regions were involved in attention to individual features of visual stimuli. 
 The involvement of the SPL has been demonstrated in a number of other language studies. For example,  Almor and colleagues (2007)  examined reference tracking when repeated references were established using repeated names vs. pronouns and found greater SPL activation for the repeated names. They suggested that this activation may be indicative of multiple discourse representations being created through the repetition of names and the subsequent effort required in order to track these multiple representations and integrate them into a single one ( Almor et al., 2007 ).  Boiteau and colleagues (2014)  found activation of the SPL for the maintenance and processing of multiple referents vs. a plural entity, again suggesting that the SPL plays a role in keeping track and integrating multiple linguistic representations. Together, the results of these and the current study are consistent with the idea that during language processing, the SPL serves the role of maintaining multiple representation that participate in a spatial or other structured configuration during language processing. 
 Finally, the non-spatial condition found two foci of activation in the left frontal cortex: inferior and superior. While we did not anticipate this finding, other studies have indeed reported similar effects. For example, the non-spatial vs. the spatial condition in  Wallentin et al. (2008)  turned up activation in BA 45, 47, 8, and 9. Indeed, these regions are widely reported to be involved in linguistic processing ( Dapretto & Bookheimer, 1999 ;  Broca, 1861 ;  Richardson et al., 2012 ;  Rogalsky, Matchin, & Hickok, 2008 ;  Wallentin et al. 2006 ). This finding may provide some clue as to how participants were performing the non-spatial version of the task: as opposed to generating and maintaining a mental image of the different figures, they were encoding them linguistically. Although linguistic processing and representation were required in the spatial condition as well, our imaging results suggest that these conditions engaged spatial and not just linguistic representations. 
 Future studies of the neural representations of spatial language should focus on better understanding the relative role of the precuneus and SPL in these processes. For instance, future studies should examine the difference between complex and simple spatial relationships and the difference in processing associated with comprehension of complex stimuli. Further, the role of the SPL in multisensory integration (e.g.  Molholm et al., 2006 ) may be related to integrative processes similar to those in the present study, thus suggesting a role of the SPL in integration in general, or SPL activations may be different for audiovisual integration as opposed to integration involving spatial information, as suggested by  Molenberghs and colleagues (2007) . Future studies should address this possibility and further elucidate the role of the SPL, given its consistent involvement in integration of linguistic information (e.g.  Almor et al., 2007 ;  Boiteau et al., 2014 ). 
 In conclusion, the present study shows that spatial information communicated through spoken language elicits bilateral superior occipital activation as well as of the precuneus and the SPL, two brain areas involved in spatial information processing. While the precuneus has been implicated in studies of ASL and mental imagery, the SPL has been implicated in a wide range of studies involving the integration of multisensory information (e.g.,  Molholm et al., 2006 ;  Wolpert et al., 1998 ), the coordination of neural systems for language and motor functions ( Rushworth et al., 2006 ;  Segal & Petrides, 2012 ), and in the shifting of attention between locations ( Molenberghs et al., 2007 ). With respect to spoken language comprehension, superior occipital regions and precuneus could support mental imagery evoked by spatial descriptions while the SPL may support the representation and processing of linguistically described spatial relationships. 
 
 
 
 This research was supported in part by a fellowship from the Natural Sciences and Engineering Research Council of Canada (NSERC, #90476158) to the first author, NIH grants R21AG030445 and R01DC009571, NSF award BCS0822617, and by the McCausland Center for Neuroimaging at the University of South Carolina. The authors wish to express their gratitude to the undergraduate and graduate students who participated in the study, and to Al Montgomery for the use of his voice in auditory stimuli. 
 
 
 
 This is a PDF file of an unedited manuscript that has been accepted for publication. As a service to our customers we are providing this early version of the manuscript. The manuscript will undergo copyediting, typesetting, and review of the resulting proof before it is published in its final citable form. Please note that during the production process errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain. 
 
 
 
 
 
 
 
 Almor 
 A 
 
 
 Smith 
 DV 
 
 
 Bonilha 
 L 
 
 
 Fridriksson 
 J 
 
 
 Rorden 
 C 
 
 
 2007 
 What is in a name? Spatial brain circuits are used to track discourse references 
 Neuroreport 
 18 
 1215 
 1219 
 17632270 
 
 
 
 
 
 
 Amorapanth 
 PX 
 
 
 Widick 
 P 
 
 
 Chatterjee 
 A 
 
 
 2010 
 The neural basis for spatial relations 
 Journal of Cognitive Neuroscience 
 22 
 8 
 1739 
 1753 
 19642889 
 
 
 
 
 
 
 Andersson 
 JLR 
 
 
 Jenkinson 
 M 
 
 
 Smith 
 SM 
 
 
 2007a 
 Non-linear optimisation 
 FMRIB technical report TR07JA1 
 
 www.fmrib.ox.ac.uk/analysis/techrep 
 
 
 
 
 
 
 
 Andersson 
 JLR 
 
 
 Jenkinson 
 M 
 
 
 Smith 
 SM 
 
 
 2007b 
 Non-linear registration, aka Spatial normalisation 
 FMRIB technical report TR07JA2 
 
 www.fmrib.ox.ac.uk/analysis/techrep 
 
 
 
 
 
 
 
 Beckmann 
 C 
 
 
 Jenkinson 
 M 
 
 
 Smith 
 SM 
 
 
 2003 
 General multi-level linear modelling for group analysis in FMRI 
 NeuroImage 
 20 
 1052 
 1063 
 14568475 
 
 
 
 
 
 
 Boiteau 
 TW 
 
 
 Bowers 
 E 
 
 
 Nair 
 V 
 
 
 Almor 
 A 
 
 
 2014 
 The neural representation of plural discourse entities 
 Brain and Language 
 137 
 130 
 141 
 25218099 
 
 
 
 
 
 
 Bonda 
 E 
 
 
 Petrides 
 M 
 
 
 Frey 
 S 
 
 
 Evans 
 A 
 
 
 1995 
 Neural correlates of mental transformations of the body-in-space 
 Proceedings of the National Academy of Sciences USA 
 11180 
 11184 
 
 
 
 
 
 
 Bowerman 
 M 
 
 
 1996 
 Learning how to structure space for language: A cross linguistic perspective 
 
 
 Bloom 
 P 
 
 
 Language and Space 
 385 
 436 
 Cambridge, MA 
 MIT Press 
 
 
 
 
 
 
 Broca 
 P 
 
 
 1861 
 Remarques sur le siége de la faculté du langage articulé, suives d’une observation d’aphémie (perte de la parole) (Remarks on the seat of the faculty of articulated language, followed by an observation on aphemia {loss of speech}) 
 Bulletins de la Société d’Anthropologie de Paris 
 6 
 330 
 357 
 
 
 
 
 
 
 Broca 
 P 
 
 
 1865 
 Sur le siège de la faculté du langage articulé 
 Bulletins De La Société D’anthropologie De Paris 
 6 
 1 
 377 
 393 
 
 http://doi.org/10.3406/bmsap.1865.9495 
 
 
 
 
 
 
 
 Carpenter 
 PA 
 
 
 Just 
 MA 
 
 
 Keller 
 TA 
 
 
 Eddy 
 WF 
 
 
 Thulborn 
 KR 
 
 
 1999 
 Time course of fMRI-activation in language and spatial networks during sentence comprehension 
 NeuroImage 
 10 
 216 
 224 
 10417254 
 
 
 
 
 
 
 Castelli 
 F 
 
 
 Glaser 
 DE 
 
 
 Butterworth 
 B 
 
 
 2006 
 Discrete and analogue quantity processing in the parietal lobe: A functional MRI study 
 Proceedings of the National Academy of Sciences 
 103 
 21 
 4693 
 4698 
 
 
 
 
 
 
 Cavanna 
 AE 
 
 
 Trimble 
 MR 
 
 
 2006 
 The precuneus: a review of its functional anatomy and neural correlates 
 Brain 
 129 
 564 
 583 
 16399806 
 
 
 
 
 
 
 Chatterjee 
 A 
 
 
 2001 
 Language and space: some interactions 
 Trends in Cognitive Sciences 
 5 
 55 
 61 
 11166635 
 
 
 
 
 
 
 Corbetta 
 M 
 
 
 Miezin 
 FM 
 
 
 Shulman 
 GL 
 
 
 Petersen 
 SE 
 
 
 1993 
 A PET study of visuospatial attention 
 Journal of Neuroscience 
 13 
 3 
 1202 
 1226 
 8441008 
 
 
 
 
 
 
 Damasio 
 H 
 
 
 Grabowski 
 TJ 
 
 
 Tranel 
 D 
 
 
 Ponto 
 LLB 
 
 
 Hichwa 
 RD 
 
 
 Damasio 
 AR 
 
 
 2001 
 Neural correlates of naming actions and of naming spatial relations 
 NeuroImage 
 13 
 1053 
 1064 
 11352611 
 
 
 
 
 
 
 Dapretto 
 M 
 
 
 Bookheimer 
 SY 
 
 
 1999 
 Form and content: dissociating syntax and semantics in sentence comprehension 
 Neuron 
 24 
 2 
 427 
 32 
 10571235 
 
 
 
 
 
 
 Dax 
 M 
 
 
 1865 
 Lésions de la moitié gauche de l’encéphale coincident avec l’oubli des signes de la pensée 
 Gazette Hebdomadaire de Médicine et de Chirurgie (Paris) 
 2 
 259 
 260 
 
 
 
 
 
 
 Dronkers 
 NF 
 
 
 Redfern 
 BB 
 
 
 Knight 
 RT 
 
 
 1999 
 The neural architecture of language disorders 
 
 
 Gazzaniga 
 M 
 
 
 The new cognitive neurosciences 
 Cambridge, MA 
 MIT Press 
 
 
 
 
 
 
 Duecker 
 F 
 
 
 Formisano 
 E 
 
 
 Sack 
 AT 
 
 
 2013 
 Hemispheric differences in the voluntary control of spatial attention: Direct evidence for a right-hemispheric dominance within frontal cortex 
 Journal of Cognitive Neuroscience 
 25 
 8 
 1332 
 1342 
 23574586 
 
 
 
 
 
 
 Emmorey 
 K 
 
 
 Damasio 
 H 
 
 
 McCullough 
 S 
 
 
 Grabowski 
 T 
 
 
 Ponto 
 LLB 
 
 
 Hichwa 
 RD 
 
 
 
 2002 
 Neural systems underlying spatial language in American sign language 
 NeuroImage 
 17 
 812 
 824 
 12377156 
 
 
 
 
 
 
 Emmorey 
 K 
 
 
 Grabowski 
 T 
 
 
 McCullough 
 S 
 
 
 Ponto 
 LLB 
 
 
 Hichwa 
 RD 
 
 
 Damasio 
 H 
 
 
 2005 
 The neural correlates of spatial language in English and American Sign Language: a PET study with hearing bilinguals 
 NeuroImage 
 24 
 832 
 840 
 15652318 
 
 
 
 
 
 
 Emmorey 
 K 
 
 
 McCullough 
 S 
 
 
 Mehta 
 S 
 
 
 Ponto 
 LLB 
 
 
 Grabowski 
 TJ 
 
 
 2013 
 The biology of linguistic expression impacts neural correlates for spatial language 
 Journal of Cognitive Neuroscience 
 25 
 4 
 517 
 533 
 23249348 
 
 
 
 
 
 
 Gutierrez-Sigut 
 E 
 
 
 Payne 
 H 
 
 
 MacSweeney 
 M 
 
 
 2015 
 Investigating language lateralization during phonological and semantic fluency tasks using functional transcranial Doppler sonography 
 Laterality 
 20 
 1 
 49 
 68 
 24875468 
 
 
 
 
 
 
 Jenkinson 
 M 
 
 
 Bannister 
 P 
 
 
 Brady 
 M 
 
 
 Smith 
 S 
 
 
 2002 
 Improved optimization for the robust and accurate linear registration and motion correction of brain images 
 Neuroimage 
 825 
 841 
 12377157 
 
 
 
 
 
 
 Jenkinson 
 M 
 
 
 Smith 
 SM 
 
 
 2001 
 A global optimisation method for robust affine registration of brain images 
 Medical Image Analysis 
 5 
 2 
 143 
 156 
 11516708 
 
 
 
 
 
 
 Jerde 
 TA 
 
 
 Lewis 
 SM 
 
 
 Goerke 
 U 
 
 
 Gourtzelidis 
 P 
 
 
 Tzagarakis 
 C 
 
 
 Lynch 
 J 
 
 
 Georgopoulos 
 AP 
 
 
 2008 
 Ultra-high field parallel imaging of the superior parietal lobule during mental maze solving 
 Experimental Brain Research 
 187 
 551 
 561 
 18305932 
 
 
 
 
 
 
 Karnath 
 H 
 
 
 Berger 
 MF 
 
 
 Küker 
 W 
 
 
 Rorden 
 C 
 
 
 2004 
 The anatomy of spatial neglect based on voxelwise statistical analysis: a study of 140 patients 
 Cerebral Cortex 
 14 
 1164 
 1172 
 15142954 
 
 
 
 
 
 
 Kemmerer 
 D 
 
 
 Tranel 
 D 
 
 
 2000 
 A double dissociation between linguistic and perceptual representations of spatial relationships 
 Cognitive Neuropsychology 
 17 
 393 
 414 
 20945188 
 
 
 
 
 
 
 Kemmerer 
 D 
 
 
 Tranel 
 D 
 
 
 2003 
 A double dissociation between the meanings of action verbs and locative prepositions 
 Neurocase 
 9 
 421 
 435 
 14972757 
 
 
 
 
 
 
 Knauff 
 M 
 
 
 Fangmeier 
 T 
 
 
 Ruff 
 CC 
 
 
 Johnson-Laird 
 PN 
 
 
 2003 
 Reasoning, models, and images: behavioral measures and cortical activity 
 Journal of Cognitive Neuroscience 
 15 
 559 
 573 
 12803967 
 
 
 
 
 
 
 Koenigs 
 M 
 
 
 Barbey 
 AK 
 
 
 Postle 
 BR 
 
 
 Grafman 
 J 
 
 
 2009 
 Superior parietal cortex is critical for the manipulation of information in working memory 
 Journal of Neuroscience 
 29 
 47 
 14980 
 14986 
 19940193 
 
 
 
 
 
 
 Kosslyn 
 SM 
 
 
 Ganis 
 G 
 
 
 Thompson 
 WL 
 
 
 2003 
 Mental imagery: Against the nihilistic hypothesis 
 Trends in Cognitive Sciences 
 7 
 109 
 111 
 12639690 
 
 
 
 
 
 
 Kosslyn 
 SM 
 
 
 Sokolov 
 MA 
 
 
 Chen 
 JC 
 
 
 1989 
 The lateralization of BRAIN: A computational theory and model of visual hemispheric specialization 
 
 
 Klahr 
 D 
 
 
 Kotovsky 
 K 
 
 
 Complex information processing: The impact of Herbert Simon 
 Hillsdale, NJ 
 Erlbaum 
 
 
 
 
 
 
 Landau 
 B 
 
 
 Jackendoff 
 R 
 
 
 1993 
 “What” and “where” in spatial cognition 
 Behavioral and Brain Sciences 
 16 
 217 
 265 
 
 
 
 
 
 
 Levinson 
 SC 
 
 
 2003 
 Spatial language 
 
 
 Nadel 
 L 
 
 
 Encyclopedia of Cognitive Science 
 131 
 137 
 London 
 Nature Publishing Group 
 
 
 
 
 
 
 MacSweeney 
 M 
 
 
 Woll 
 B 
 
 
 Campbell 
 R 
 
 
 McGuire 
 PK 
 
 
 David 
 AS 
 
 
 Williams 
 SCR 
 
 
 Brammer 
 MJ 
 
 
 2002 
 Neural systems underlying British Sign Language and audiovisual English processing in native users 
 Brain 
 125 
 1583 
 1593 
 12077007 
 
 
 
 
 
 
 Manning 
 L 
 
 
 Thomas-Antérion 
 C 
 
 
 2011 
 Marc Dax and the discovery of the lateralization of language in the left cerebral hemisphere 
 Rev Neurol (Paris) 
 167 
 12 
 868 
 72 
 21640366 
 
 
 
 
 
 
 Molenberghs 
 P 
 
 
 Mesulam 
 MM 
 
 
 Peeters 
 R 
 
 
 Vandenberghe 
 RRC 
 
 
 2007 
 Remapping attentional priorities: Differential contribution of superior parietal lobule and intraparietal sulcus 
 Cerebral Cortex 
 17 
 2703 
 2712 
 17264251 
 
 
 
 
 
 
 Molholm 
 S 
 
 
 Sehatpour 
 P 
 
 
 Mehta 
 AD 
 
 
 Shpaner 
 M 
 
 
 Gomez-Ramirez 
 M 
 
 
 Ortigue 
 S 
 
 
 Foxe 
 JJ 
 
 
 2006 
 Audio-visual multisensory integration in superior parietal lobule revealed by human intracranial recordings 
 Journal of Neurophysiology 
 96 
 721 
 729 
 16687619 
 
 
 
 
 
 
 Noordzij 
 ML 
 
 
 Neggers 
 SFW 
 
 
 Ramsay 
 NF 
 
 
 Postma 
 A 
 
 
 2008 
 Neural correlates of locative prepositions 
 Neuropsychologia 
 46 
 1576 
 1580 
 18249423 
 
 
 
 
 
 
 Parsons 
 LM 
 
 
 Fox 
 PT 
 
 
 Downs 
 JH 
 
 
 Glass 
 T 
 
 
 Hirsch 
 TB 
 
 
 Martin 
 CC 
 
 
 
 1995 
 Use of implicit motor imagery for visual shape discrimination as revealed by PET 
 Nature 
 375 
 54 
 58 
 7723842 
 
 
 
 
 
 
 Richardson 
 JD 
 
 
 Fillmore 
 P 
 
 
 Rorden 
 C 
 
 
 Lapointe 
 LL 
 
 
 Fridriksson 
 J 
 
 
 2012 
 Reestablishing Broca’s initial findings 
 Brain and Language 
 123 
 2 
 125 
 30 
 23058844 
 
 
 
 
 
 
 Rogalsky 
 C 
 
 
 Matchin 
 W 
 
 
 Hickok 
 G 
 
 
 2008 
 Broca’s area, sentence comprehension, and working memory: an fMRI study 
 Frontiers in Human Neuroscience 
 2 
 14 
 10.3389/neuro.09.014.2008 
 
 
 
 
 
 
 Rushworth 
 MF 
 
 
 Behrens 
 TE 
 
 
 Johansen-Berg 
 H 
 
 
 2006 
 Connection patterns distinguish 3 regions of human parietal cortex 
 Cerebral Cortex 
 16 
 1418 
 1430 
 16306320 
 
 
 
 
 
 
 Smith 
 SM 
 
 
 2002 
 Fast robust automated brain extraction 
 Human Brain Mapping 
 17 
 3 
 143 
 155 
 12391568 
 
 
 
 
 
 
 Segal 
 E 
 
 
 Petrides 
 M 
 
 
 2012 
 The anterior superior parietal lobule and its interactions with language and motor areas during writing 
 European Journal of Neuroscience 
 35 
 309 
 322 
 22188383 
 
 
 
 
 
 
 Talmy 
 L 
 
 
 2000 
 How language structures space 
 Toward a Cognitive Semantics: Volume 1 (Concept Structuring Systems) 
 177 
 254 
 Cambridge, MA 
 MIT Press 
 
 
 
 
 
 
 Tranel 
 D 
 
 
 Kemmerer 
 D 
 
 
 2004 
 Neuroanatomical correlates of locative prepositions 
 Cognitive Neuropsychology 
 7 
 719 
 749 
 
 
 
 
 
 
 Ungerleider 
 LG 
 
 
 Haxby 
 JV 
 
 
 1994 
 ‘What’ and ‘where’ in the human brain 
 Current Opinion in Neurobiology 
 4 
 2 
 157 
 165 
 8038571 
 
 
 
 
 
 
 Ungerleider 
 LG 
 
 
 Mishkin 
 M 
 
 
 1982 
 Two cortical visual systems 
 
 
 Ingle 
 DJ 
 
 
 Goodale 
 MA 
 
 
 Mansfield 
 RJW 
 
 
 Analysis of Visual Behavior 
 549 
 586 
 Cambridge, MA 
 MIT Press 
 
 
 
 
 
 
 Wallentin 
 M 
 
 
 Østergaard 
 S 
 
 
 Lund 
 TE 
 
 
 Østergaard 
 L 
 
 
 Roepstorff 
 A 
 
 
 2005 
 Concrete spatial language: see what I mean? 
 Brain and Language 
 92 
 221 
 233 
 15721955 
 
 
 
 
 
 
 Wallentin 
 M 
 
 
 Michaelsen 
 JLD 
 
 
 Rynne 
 I 
 
 
 Nielsen 
 RH 
 
 
 2014 
 Lateralized task shift effects in Broca’s and Wernicke’s regions and in Visual Word Form Area are selective for conceptual content and reflects trial history 
 Neuroimage 
 101 
 276 
 288 
 25047449 
 
 
 
 
 
 
 Wallentin 
 M 
 
 
 Roepstorff 
 A 
 
 
 Glover 
 R 
 
 
 Burgess 
 N 
 
 
 2006 
 Parallel memory systems for talking about location and age in precuneus, caudate and Broca’s region 
 Neuroimage 
 32 
 1850 
 1864 
 16828565 
 
 
 
 
 
 
 Wallentin 
 M 
 
 
 Weed 
 E 
 
 
 Østergaard 
 L 
 
 
 Mouridsen 
 K 
 
 
 Roepstorff 
 A 
 
 
 2008 
 Accessing the mental space - Spatial working memory processes for language and vision overlap in precuneus 
 Human Brain Mapping 
 29 
 524 
 532 
 17525981 
 
 
 
 
 
 
 Witelson 
 SF 
 
 
 1976 
 Abnormal right hemisphere specialization in developmental dyslexia 
 
 
 Knights 
 RM 
 
 
 Bakker 
 DF 
 
 
 Neuropsychology of learning disorders: Theoretical approaches 
 Baltimore 
 University Park Press 
 
 
 
 
 
 
 Wolpert 
 DM 
 
 
 Goodbody 
 SJ 
 
 
 Husain 
 M 
 
 
 1998 
 Maintaining internal representations: The role of the human superior parietal lobe 
 Nature Neuroscience 
 1 
 6 
 529 
 533 
 10196553 
 
 
 
 
 
 
 Woolrich 
 MW 
 
 
 Behrens 
 TEJ 
 
 
 Beckmann 
 CF 
 
 
 Jenkinson 
 M 
 
 
 Smith 
 SM 
 
 
 2004 
 Multi-level linear modelling for FMRI group analysis using Bayesian inference 
 NeuroImage 
 21 
 1732 
 1747 
 15050594 
 
 
 
 
 
 
 Woolrich 
 MW 
 
 
 Ripley 
 BD 
 
 
 Brady 
 JM 
 
 
 Smith 
 SM 
 
 
 2001 
 Temporal autocorrelation in univariate linear modelling of FMRI data 
 NeuroImage 
 14 
 1370 
 1386 
 11707093 
 
 
 
 
 
 
 Worsley 
 KJ 
 
 
 2001 
 Statistical analysis of activation images 
 Functional MRI: An Introduction to Methods 
 
 
 Jezzard 
 P 
 
 
 Matthews 
 PM 
 
 
 Smith 
 SM 
 
 
 251 
 270 
 Oxford University Press 
 Oxford 
 
 
 
 
 
 
 Worsley 
 KJ 
 
 
 Evans 
 AC 
 
 
 Marrett 
 S 
 
 
 Neelin 
 P 
 
 
 1992 
 A three-dimensional statistical analysis for CBF activation studies in human brain 
 Journal of Cerebral Blood Flow and Metabolism 
 12 
 900 
 918 
 1400644 
 
 
 
 
 
 
 Zhang 
 S 
 
 
 Li 
 CS 
 
 
 2012 
 Functional connectivity mapping of the human precuneus by resting state fMRI 
 NeuroImage 
 59 
 4 
 3548 
 3562 
 22116037 
 
 
 
 
 
 
 Figure 1 
 
 Schematic of experiment trial 
 The participant is asked to focus on the fixation point while they listen to sentences presented through headphones. The duration of the sentences ranged from 2 to 2.5 seconds. A visual stimulus appeared after a minority of trials. The total trial time was 10 seconds. 
 
 
 
 
 Figure 2 
 
 Example visual stimuli 
 Six combinations were possible: spatial + match, spatial + non-match; non-spatial size match or non-match, and non-spatial color match or non-match). 
 
 
 
 
 Figure 3 
 
 The results of the spatial > non-spatial (red) and nonspatial > spatial (green) contrasts. Color overlays show the Z values in the significant clusters. 
 
 
 
 
 TABLE 1 
 
 Examples of spatial and non-spatial stimuli. 
 
 
 
 
 Type of Stimuli 
 Example 
 
 
 
 
 Spatial 
 “The square is to the left of the circle.” 
 
 
 
 “The triangle is below the square.” 
 
 
 Non-spatial 
 “The square is lighter than the circle.” 
 
 
 Brightness comparison 
 “The triangle is darker than the circle.” 
 
 
 Non-spatial 
 “The square is larger than the circle.” 
 
 
 Size comparison 
 “The triangle is smaller than the square.” 
 
 
 
 
 
 TABLE 2 
 
 Local maxima of significant clusters 
 Coordinates of local maxima, corresponding Z-scores, Broadman Areas and Regions (derived with Talairach Client version 2.4.3 following transformation from MNI coordinates by icbm2tal using BrainMap GingerALE 2.3.6) 
 
 
 
 
 Cluster Index 
 Z-score 
 MNI Coordinates 
 BA 
 Region 
 
 
 x 
 y 
 z 
 
 
 
 
 
 
 
 
 
 Spatial > Non-spatial 
 
 
 1 
 4.40 
 25 
 −59 
 56 
 7 
 Right Precuneus 
 
 
 1 
 4.25 
 22 
 −56 
 58 
 7 
 Right Precuneus 
 
 
 1 
 3.77 
 39 
 −80 
 37 
 19 
 Right Superior Occipital Gyrus 
 
 
 1 
 3.77 
 −3 
 −64 
 57 
 7 
 Left Precuneus 
 
 
 1 
 3.75 
 −30 
 −56 
 59 
 7 
 Left Superior Parietal Lobule 
 
 
 1 
 3.71 
 39 
 −83 
 34 
 19 
 Right Superior Occipital Gyrus 
 
 
 
 
 
 
 
 
 
 
 
 Non-spatial > Spatial 
 
 
 1 
 3.65 
 −46 
 33 
 −15 
 47 
 Left Inferior Frontal Gyrus 
 
 
 1 
 3.63 
 −44 
 33 
 −16 
 47 
 Left Inferior Frontal Gyrus 
 
 
 1 
 3.55 
 −39 
 54 
 −2 
 10 
 Left Middle Frontal Gyrus 
 
 
 1 
 3.41 
 −39 
 42 
 −15 
 47 
 Left Middle Frontal Gyrus 
 
 
 1 
 3.4 
 −37 
 56 
 −9 
 10 
 Left Middle Frontal Gyrus 
 
 
 1 
 3.37 
 −35 
 43 
 −16 
 11 
 Left Middle Frontal Gyrus 
 
 
 2 
 3.63 
 −19 
 29 
 55 
 6 
 Left Superior Frontal Gyrus 
 
 
 2 
 3.59 
 −14 
 41 
 54 
 6 
 Left Superior Frontal Gyrus 
 
 
 2 
 3.57 
 −13 
 27 
 57 
 6 
 Left Superior Frontal Gyrus 
 
 
 2 
 3.47 
 −45 
 19 
 49 
 6 
 Left Middle Frontal Gyrus 
 
 
 2 
 3.4 
 −10 
 44 
 52 
 8 
 Left Superior Frontal Gyrus 
 
 
 2 
 3.33 
 −15 
 44 
 50 
 8 
 Left Superior Frontal Gyrus 
 
 
 
 
 
 
 Highlights 
 
 
 
 Sentences describing spatial relationships elicit greater activation in the superior parietal lobule and precuneus  bilaterally  in comparison to sentences describing size or color relationships. 
 
 
 Activation of the precuneus suggests that spatial sentences elicit spatial-mental imagery. 
 
 
 Activation of the SPL suggests sentences containing spatial language involve integration of two distinct sets of information – linguistic and spatial. 
 
 
 
 
