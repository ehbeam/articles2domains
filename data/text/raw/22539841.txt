
 properties manuscript? 
 
 
 8102140 
 5035 
 J Neurosci 
 J. Neurosci. 
 
 The Journal of Neuroscience 
 
 0270-6474 
 1529-2401 
 
 
 22539841 
 3368505 
 10.1523/JNEUROSCI.6294-11.2012 
 NIHMS373629 
 
 
 Article 
 
 
 
 The effect of object state-changes on event processing: Do objects compete with themselves? 
 
 
 
 
 Hindy 
 Nicholas C. 
 
 a 
 * 
 
 
 
 Altmann 
 Gerry T.M. 
 
 b 
 
 
 
 Kalenik 
 Emily 
 
 a 
 
 
 
 Thompson-Schill 
 Sharon L. 
 
 a 
 
 
 a Department of Psychology, University of Pennsylvania, Philadelphia, PA 19104 
 b Department of Psychology, University of York, Heslington, York YO10 5DD, UK 
 
 * Corresponding author Address: Department of Psychology, University of Pennsylvania, 3720 Walnut Street, Philadelphia, PA 19104, Telephone: 603-661-4222, Fax: 215-898-1982,  hindy@psych.upenn.edu 
 
 
 10 
 5 
 2012 
 
 
 25 
 4 
 2012 
 
 
 25 
 10 
 2012 
 
 32 
 17 
 5795 
 5803 
 
 
 This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law. 
 
 
 
 When an object is described as changing state during an event, do the representations of those states compete? The distinct states they represent cannot co-exist at any one moment in time, yet each representation must be retrievable at the cost of suppressing the other possible object states. We used functional magnetic resonance imaging of human participants to test whether such competition does occur, and whether this competition between object states recruits brain areas sensitive to other forms of conflict. In Experiment 1, the same object was changed either substantially or minimally by one of two actions. In Experiment 2, the same action either substantially or minimally changed one of two objects. On a subject-specific basis, we identified voxels most responsive to conflict in a Stroop color-word interference task. Voxels in left posterior ventrolateral prefrontal cortex most responsive to Stroop conflict were also responsive to our object state-change manipulation, and were not responsive to the imageability of the described action. In contrast, voxels in left middle frontal gyrus responsive to Stroop conflict were not responsive even to language, and voxels in left middle temporal gyrus that were responsive to language and imageability were not responsive to object state-change. Results suggest that, when representing object state-change, multiple incompatible representations of an object compete, and the greater the difference between the initial state and the end state of an object, the greater the conflict. 
 
 
 
 National Eye Institute : NEI 
 R01 EY021717 || EY 
 
 
 National Institute on Deafness and Other Communication Disorders : NIDCD 
 R01 DC009209 || DC 
 
 
 
 
 
 Introduction 
 Event comprehension requires the ability to keep track of multiple representations of an object as it is altered in state or location. Recent work on language-mediated eye-movements suggests that the mental representation of a described object is dissociable from the perceived object in a concurrently presented visual scene, and suggests further that multiple representations of (all or parts of) the  same  object in different states may compete and interfere with one another during event processing ( Altmann and Kamide, 2009 ). 
 On reading “ The squirrel will crack the acorn ,” we must represent that the acorn existed in distinct states: cracked and intact. If an immediately succeeding sentence reads “ And then, it will lick the acorn ,” the cracked state must be retrieved; if, instead, that sentence reads “ But first, it will lick the acorn ,” the intact state must be retrieved. Now consider replacing “ The squirrel will crack the acorn ” with “ The squirrel will sniff the acorn .” Regardless of the “but first” or “and then,” there is no conflict regarding the nature of the acorn’s representation to be retrieved. We hypothesize that reading about the cracked acorn will recruit brain regions usually associated with conflict resolution, whereas reading about the sniffed acorn will not. 
 Here, we test the proposal that selecting from amongst distinct states of the same object will selectively recruit prefrontal cortex regions sensitive to semantic conflict, and that this increased activation will overlap on a subject-specific basis with conflict-dependent activation in a standard interference task. Event comprehension trials for each experiment varied in the degree to which a described object was changed in state. In Experiment 1, the same object was changed either substantially or minimally by one of two actions (“crack” or “sniff”). In Experiment 2, the same action (“stomp on”) either substantially or minimally changed one of two objects (an egg or a penny). Conflict-dependent fMRI data collected during a Stroop color-word interference task was used to create subject-specific regions of interest (ROIs) in left posterior ventrolateral prefrontal cortex (pVLPFC), a brain area responsive to semantic conflict ( Thompson-Schill et al., 2005 ). We additionally examined activation in two other ROIs: 1) voxels in left middle frontal gyrus (MFG) that were responsive to Stroop conflict but unresponsive to sentence comprehension; 2) voxels in left middle temporal gyrus (MTG) responsive to sentence comprehension but unresponsive to Stroop conflict. 
 In each experiment, the rated degree to which an object changed in state during an event, but not the rated imageability of the described action, parametrically predicted the amplitude of the BOLD response in left pVLPFC voxels most responsive to Stroop conflict. In contrast, object state-change did not predict activation in either left MFG or left MTG; in left MTG we instead observed an effect of action imageability. Across complementary manipulations of action (Expt. 1) and object (Expt. 2), the consistent linear effect of object state-change on conflict-responsive areas of left pVLPFC indicates that multiple states of an object do compete during event processing when the object is changed from its original state. 
 
 
 Materials and Methods 
 
 Subjects 
 Sixteen right-handed native English speakers (9 female), aged 18–28 years, participated in Experiment 1, and a separate sample of 16 right-handed native English speakers (8 female), aged 19–33 years, participated in Experiment 2. Two additional subjects from Experiment 2 were excluded from data analysis and replaced due to unusually poor performance on the event comprehension task; one subject correctly identified fewer than half the catch trials; the other subject had a false-alarm rate that was 10 times the average of all Experiment 2 subjects. All fMRI subjects were paid $20 per hour and were recruited from within the University of Pennsylvania community. Subjects gave informed consent as approved by the University of Pennsylvania Institutional Review Board. Additionally, 522 University of Pennsylvania undergraduate students participated for course credit in an online task used for stimulus norming (273 subjects in Experiment 1; 249 subjects in Experiment 2). All subjects spoke English as a first language. 
 
 
 Event stimuli 
 Event comprehension items for each experiment consisted of two sentences describing a person or an animal acting upon a single object. Across conditions in each experiment, the object acted upon was either minimally or substantially changed in the first-sentence event. In Experiment 1, we varied the first-sentence action to induce the state-change manipulation; the object acted upon was identical for both “substantial state-change” and “minimal state-change” conditions (e.g., “ The squirrel will crack/sniff the acorn ”). In Experiment 2, we held the action constant across conditions, and varied the object to induce the state-change manipulation (e.g., “ The girl will stomp on the penny/egg ”). By separately varying the described action and the described object across Experiments 1 and 2, we avoid changes in pVLPFC activation being due to changes in the verb alone (Expt. 1) or the object alone (Expt. 2); that is, we test whether object state-change drives conflict-dependent pVLPFC activation independent of variations in either action or in object.  Table 1  shows example items from each experiment, along with the object state-change and action imageability ratings corresponding to those items. 
 The first-sentence verb for each item in Experiment 1 was matched across conditions on lexical ambiguity, measured as the number of distinct meanings ( t (238) = 0.75,  p =  .45) ( Burke, 2009 ), and on frequency of use ( t (238) = 1.00,  p =  .32) ( Brysbaert and New, 2009 ). The object referred to in each item in Experiment 2 was similarly matched across conditions on both lexical ambiguity ( t (198) = 0.30,  p =  .77), and frequency ( t (198) = −0.89,  p =  .37). The action described in the second sentence was identical across conditions in both experiments, and always minimally affected the object. In Experiment 1, the temporal phrase at the beginning of each second sentence was either “but first” or “and then.” We included this manipulation to test the additional hypothesis that the “crack…but first” cases would engender increased activity compared to the “crack…and then” cases because of the need to switch the focus from the newly changed state to the previous (unchanged) state. However, we observed the same pattern of neural activity for both the “and then” and “but first” conditions in Experiment 1 1 . In Experiment 2, we therefore kept temporal context constant across items by always beginning the second sentence with “and then.” For both experiments, subjects were exposed to all stimuli and all conditions in a fully factorial repeated measures design, but never saw more than one version of each stimulus. 
 
 
 Event ratings 
 Object state-change and action imageability ratings were collected through online surveys for the first and second sentence of each item in each experiment. Each survey subject rated only one alternative sentence of each item. For object state-change ratings, subjects rated “the degree to which the depicted object will be at all different after the action occurs that it had been before the action occurred.” Subjects rated each item on a 7-point scale ranging from “just the same” to “completely changed.” For action imageability, subjects rated “how much a sentence brings to mind a clear mental image of a particular action.” Subjects rated each item on a 7-point scale ranging from “not imageable at all” to “extremely imageable.” 
 Object state-change and action imageability ratings for the first-sentence events included data from 85 subjects for Experiment 1, and 101 subjects for Experiment 2. The first-sentence event in the “minimal state-change” condition received an average object state-change rating of 1.97 ( SD  = 0.57) in Experiment 1, and 2.78 ( SD  = 0.79) in Experiment 2. The first-sentence event in the “substantial state-change” condition received an average object state-change rating of 4.64 ( SD  = 0.84) in Experiment 1, and 4.96 ( SD  = 0.74) in Experiment 2. Object state-change ratings varied broadly within the “minimal state-change” and “substantial state-change” conditions ( Figure 1 ); the overall difference in object state-change between conditions was reliable in each experiment ( p ’s < .001). The average first-sentence action imageability rating for the “minimal state-change” condition was 4.89 ( SD  = 0.64) in Experiment 1, and 5.57 ( SD  = 0.42) in Experiment 2. For the “substantial state-change” condition, the average first-sentence action imageability rating was 5.46 ( SD  = 0.41) in Experiment 1, and 5.59 ( SD  = 0.47) in Experiment 2. The difference in action imageability between conditions was reliable in Experiment 1 ( p <  .001), but was not reliable for Experiment 2 ( p  = .18). For both experiments, object state-change correlated with neither frequency nor lexical ambiguity (see above;  p ’s > .4). 
 Object state-change and action imageability ratings for the second-sentence events included data from 95 subjects for Experiment 1, and 98 subjects for Experiment 2. The second-sentence events of all items in both experiments were designed to involve minimal object state-change. To confirm that there were no differences between conditions, we used a separate online survey to collect object state-change and action imageability ratings for these events. In Experiment 1, the second sentence of each item was identical across conditions, and had an average object state-change rating of 1.90 ( SD  = 0.47), and an average action imageability rating of 4.52 ( SD  = 0.69). For the second sentence in Experiment 2, which had a different object in the “minimal” and “substantial” state-change conditions, the average object state-change rating was 1.69 ( SD  = 0.44) for “minimal state-change” items and 1.74 ( SD  = 0.49) for “substantial state-change” items, while the average action imageability rating was 4.23 ( SD  = 0.83) for “minimal state-change” items, and 4.13 ( SD  = 0.84) for “substantial state-change” items. Experiment 2 items did not reliably differ across conditions in either the object state-change or the action imageability of the second-sentence event ( p ’s > .3). 
 For each experiment, we additionally collected ratings for the likelihood that the second sentence of each item would follow the first sentence of that item (if that first sentence had been read, for example, in a magazine or newspaper). We used separate online surveys to collect data from 93 subjects for Experiment 1 (which included 4 conditions), and 50 subjects for Experiment 2 (which included 2 conditions). The average likelihood rating across “minimal state-change” event sequences was 4.06 ( SD  = 0.78) in Experiment 1, and 4.12 ( SD  = 0.90) in Experiment 2. The average likelihood rating for “substantial state-change” event sequences was 4.08 ( SD  = 0.78) in Experiment 1, and 4.28 ( SD  = 0.95) in Experiment 2. There was no statistical difference between state-change conditions of either experiment in the rated likelihood of the event sequences ( p ’s > .2). 
 
 
 Event comprehension task 
 The event comprehension task in each fMRI experiment was separated into five runs, with an equal number of trials of each condition in each run. Experiment 1 included 120 experimental trials split across four conditions. Experiment 2 included 100 experimental trials split across two conditions. Additionally, subjects in each experiment read 15 “catch trials” in which the second-sentence event of the trial was implausible given the first-sentence event (e.g., “The mother will eat the sandwich. And then, she will serve the sandwich.”). The trial structure was identical in the two experiments. Each trial lasted six seconds, during which the first sentence was presented for three seconds, followed by the second sentence for three seconds. Subjects pressed the two outer buttons of a keypad when the second-sentence event was implausible given the first-sentence event. Trials were separated by 3 to 15 seconds of jittered fixation, optimized for statistical power using the OptSeq algorithm ( http://surfer.nmr.mgh.harvard.edu/optseq/ ). Stimuli were presented using E-Prime (Psychology Software Tools). 
 
 
 Stroop color-word interference task 
 After the event comprehension task, subjects in each experiment performed a 10-minute button-press Stroop color identification task, based on previously described procedures ( Milham et al., 2001 ;  January et al., 2009 ). The response box for this task was restricted to three buttons: yellow, green, and blue. Stimuli included four trial types: response-eligible conflict, response-ineligible conflict, and two groups of neutral trials. Subjects were presented with a single word for each trial, and instructed to press the button corresponding to the typeface color of each word. Conflict trials could be either response-eligible or response-ineligible. For response-eligible conflict trials, the color term matched one of the subject’s possible responses (i.e., yellow, green, or blue), but always mismatched the typeface color. For response-ineligible conflict trials, the color term (orange, brown, or red) mismatched the typeface color, and also was not a possible response. Separate sets of non-color neutral trials (e.g., farmer, stage, tax) were intermixed with either response-eligible conflict trials or response-ineligible conflict trials. Both response-eligible and response-ineligible conflict trial types have previously been demonstrated to induce conflict at non-response levels, while response-eligible conflict trials additionally induce conflict at the level of motor response ( Milham et al., 2001 ). To optimize power for identifying subject-specific conflict-responsive subregions of left pVLPFC and left MFG, we considered only the main effect of conflict trials versus neutral trials. 
 
 
 Imaging procedure 
 Structural and functional data were collected on a 3-T Siemens Trio system and an eight-channel array head coil. Structural data included axial T1-weighted localizer images with 160 slices and 1 mm isotropic voxels (TR = 1620 ms, TE = 3.87 ms, TI = 950 ms). Functional data included echo-planar fMRI performed in 44 axial slices and 3 mm isotropic voxels (TR = 3000 ms, TE = 30 ms). Twelve seconds preceded data acquisition in each functional run to approach steady-state magnetization. 
 
 
 Data analysis 
 Image preprocessing and statistical analyses were performed using AFNI ( Cox, 1996 ). Functional data were sinc interpolated to correct for slice timing, and aligned to the mean of all functional images, using a six parameter iterated least squares procedure. The functional data were then registered with each subject’s high-resolution anatomical data set, and normalized to a standard template in Talairach space. Finally, functional data were smoothed with an 8 mm FWHM Gaussian kernel, and scaled to percent signal change. Each two-sentence trial was modeled as a six-second boxcar function convolved with a canonical hemodynamic response function, with an additional covariate in the subject-wise parametric analysis to model the degree of object state-change (or action imageability) of the item for each trial. Beta coefficients were estimated using a modified general linear model that included a restricted maximum likelihood estimation of the temporal auto-correlation structure, with a polynomial baseline fit, and the motion parameters and global signal as covariates of no interest. 
 Our analyses are focused on three ROIs, one (pVLPFC) that is our primary region of interest and two (left MFG and left MTG) that serve as controls for our purposes. Stroop-conflict ROIs in both left pVLPFC and left MFG were functionally defined separately for each subject using data obtained during the Stroop color-word interference task. Additionally, each Stroop-conflict ROI was anatomically constrained based on probabilistic anatomical atlases ( Eickhoff et al., 2005 ) transformed into Talairach space. Left pVLPFC was defined as the combination of pars triangularis (Brodmann area 45), pars opercularis (Brodmann area 44), and the anterior half of the inferior frontal sulcus. Across subjects from both experiments, the anatomical definition of left pVLPFC included an average of 784 voxels ( SD  = 35). Left MFG included portions of Brodmann areas 6, 9, 10, and 46. Across subjects from both experiments, the anatomical definition of left MFG included an average of 962 voxels ( SD  = 40). Across subjects from both experiments, the anatomical definition of left MTG included an average of 644 voxels ( SD  = 33). Within these broad anatomical boundaries, each Stroop-conflict ROI comprised the 50 voxels with the highest  t -statistics in a within-subject contrast of conflict trials versus neutral trials in the Stroop color-word interference task, while the sentence-comprehension ROI comprised the 50 left MTG voxels with the highest t-statistics in a within-subject contrast of contrast of all event comprehension trials (averaged across conditions) versus baseline. Although analyses are reported for ROIs of 50 voxels, the same statistical patterns were consistently observed across a broad range of ROI sizes. All statistical tests for each ROI were evaluated at the two-tailed .05 level of significance. Finally, we assessed the object state-change effect in each voxel across the whole brain, corrected for multiple comparisons, which we report at the end of the Results. 
 
 
 
 Results 
 
 Stroop color-word interference task 
 Across Experiments 1 and 2, subjects correctly answered 98% of all trials. The average response time was 706 ms for conflict trials and 656 ms for neutral trials ( t (31) = 6.60,  p  < .001). In a group-level contrast that included all subjects from both experiments, the most reliable cluster of voxels with an activation difference between conflict trials and neutral trials was centered between the inferior frontal gyrus (pars triangularis) and the inferior frontal sulcus of left pVLPFC ( Figure 2A ). Additional clusters of increased activation for conflict trials relative to neutral trials were observed in left MFG and left intraparietal sulcus. 
 
 
 Stroop-conflict ROI in left pVLPFC 
 To determine voxels most responsive to conflict on an individual subject level, we identified for each subject the 50 left pVLPFC voxels with the highest  t -statistics in a contrast of conflict trials versus neutral trials in the Stroop interference task. The location of the top 50 conflict-responsive voxels varied widely across subjects, with slightly more cross-subject overlap in the most posterior area of left pVLPFC, at the junction of pars triangularis, pars opercularis, and the inferior frontal sulcus ( Figure 2B ). Within each subject-specific Stroop-conflict ROI in left pVLPFC, we examined the effect of object state-change on the amplitude of the BOLD signal. 
 
 
 Experiment 1 event comprehension (object fixed, action varied) 
 Subjects correctly identified 97% of catch trials in the Experiment 1 event comprehension task, and committed false alarms (i.e., classifying a non-catch trial as implausible) on fewer than 2% of experimental trials. There was a slightly but reliably greater number of false alarms for the substantial state-change trials (2%) than for the minimal state-change trials (1%;  t (15) = 2.46,  p =  .03). Due to the small numbers involved, this difference was also tested in a chi-square test, and was also found to be significant (χ-square = 9.62,  p  = .002). False alarm trials, along with catch trials, were coded separately for all fMRI analyses. 
 The average signal change across all sentence conditions was reliably above baseline in the left pVLPFC Stroop-conflict ROI ( t (15) = 8.59,  p  < .001), indicating that this ROI was generally responsive during sentence comprehension. Because action imageability ratings were correlated with object state-change ( r  = .50), we removed variance predicted by the action imageability ratings before comparing the “substantial state-change” and “minimal state-change” conditions, though including action imageability as a covariate did not influence the reliability of any effects. A significant main effect for object state-change emerged within the left pVLPFC Stroop-conflict ROI ( t (15) = 2.50,  p =  .02) ( Figure 3A ), but there was no effect for temporal order (“and then” versus “but first”) and no interaction ( p ’s > .4). Next, we used the data from ratings of object state-change and action imageability to examine the relationship between these stimulus dimensions and signal change within the left pVLPFC Stroop-conflict ROI. Analyses separately tested the reliability of object state-change and action imageability effects across subjects and across items. Because we did not find an effect of the temporal context of the second sentence (either “but first” or “and then”), we averaged across these temporal conditions in each Experiment 1 parametric analysis that used the object state-change or action imageability ratings. 
 In a subject-wise parametric analysis, we measured the extent to which, for each subject, the BOLD signal amplitude within the left pVLPFC Stroop-conflict ROI varied in proportion to either object state-change or action imageability. Data were separately modeled for each subject, using one covariate to model each trial presentation, and a second covariate to model the degree of object state-change (or action imageability) of the item for each trial. Estimation of these beta coefficients converged with results from the categorical analyses above, as object state-change stimulus ratings reliably predicted left pVLPFC signal amplitude ( t (15) = 3.44,  p =  .004). In contrast, action imageability ratings did not reliably predict left pVLPFC signal amplitude ( t (15) = −0.27,  p =  .79). Moreover, across a broad range of ROI sizes, object state-change reliably predicted signal within the left pVLPFC Stroop-conflict ROI, while action imageability did not reliably predict activation ( Figure 3B ). Interestingly, while object state-change consistently predicted left pVLPFC signal amplitude, both across subjects and across ROI sizes, there was much greater variance across subjects in the degree to which the action imageability ratings predicted signal. This may reflect individual experiential differences across subjects. To further visualize this dissociation, we binned the items into quartiles according to either the object state-change or the action imageability ratings of the stimuli ( Figure 3C ). 
 In an item-wise analysis, we measured the extent to which, for each item averaged across subjects, BOLD signal amplitude within the left pVLPFC Stroop-conflict ROI could be predicted by the stimulus ratings. Data were separately modeled for each trial, and then individual beta coefficients were binned by item across subjects. Because each of the 120 items included 2 state-change versions (i.e., “substantial state-change” and “minimal state-change”), and because each subject read only one version of each item, there were 238 degrees of freedom in the Experiment 1 item analysis, and the average percent signal change of each item was composed of data from 8 of the 16 subjects. Object state-change ratings correlated with percent signal change in the left pVLPFC Stroop-conflict ROI ( r (238) = .15,  p  = .02), while action imageability ratings did not predict signal ( r (238) = .01,  p  = .82;  Figure 3D ). 
 
 
 Experiment 2 event comprehension (object varied, action fixed) 
 Subjects correctly identified 92% of catch trials in the Experiment 2 event comprehension task, and committed false alarms on 2% of experimental trials, with an equal number of false alarms for the substantial state-change and minimal state-change conditions ( t (15) = 1.21,  p =  .25; χ-square = 1.87,  p  = .17). As in Experiment 1, false alarm trials were coded separately, along with catch trials, for all fMRI analyses. 
 All Experiment 1 effects of object state-change on activation in the left pVLPFC Stroop-conflict ROI replicated in Experiment 2. As in Experiment 1, the average percent signal change across conditions was reliably different from baseline ( t (15) = 6.65,  p  < .001). With action imageability covaried out, there was a reliable categorical effect of the “substantial state-change” condition versus the “minimal state-change” condition ( t (15) = 3.03,  p =  .008;  Figure 4A ). In the subject-wise parametric analysis, object state-change reliably predicted ROI activation ( t (15) = 2.98,  p =  .009), while action imageability did not ( t (15) = −0.37,  p =  .71). As in Experiment 1, this pattern was reliable across a broad range of ROI sizes, with greater variance across subjects in the action imageability parameter estimate than in the object state-change parameter estimate ( Figure 4B ). In the item-wise analysis, object state-change ratings reliably predicted percent signal change in the left pVLPFC Stroop-conflict ROI ( r (198) = .24,  p  < .001), while action imageablity did not predict signal change ( r (198) = .00,  p  = .98;  Figure 4D ). 
 Though the same verb was used across conditions in the first sentence of each Experiment 2 item, individual verbs may have multiple action connotations. To control for the potential variability of action connotation, a large subset of the Experiment 2 stimuli (60 of the 100 total items) were matched as nearly as possible on the specific action connotation of the first-sentence verb. In the item-level analysis, the pattern of results in the left pVLPFC Stroop-conflict ROI for this subset of the stimuli was identical to that of the full Experiment 2 stimulus set of 100 items for object state-change ( r (58) = .27,  p  < .001), and for action imageability ( r (58) = .00,  p  =. 99). 
 
 
 Comparisons across ROIs 
 As is evident in  Figure 2A , the group-level analysis of the Stroop color-word interference task revealed a separate cluster of conflict-responsive voxels outside of left pVLPFC, in left MFG. Likewise, brain areas other than left pVLPFC, including left MTG, were generally active during sentence reading. We analyzed data from the left MTG region in particular, because of its putative involvement in semantic memory (cf.  Martin, 2007 ). To examine task-related effects in conflict-responsive MFG regions and language-responsive MTG regions, we identified for each subject the 50 left MFG voxels with the highest  t -statistics in a contrast of conflict trials versus neutral trials in the Stroop task, and the 50 left MTG voxels with the highest  t -statistics in a contrast of all event comprehension trials (averaged across conditions) versus baseline ( Figure 5A ). As was the case in left pVLPFC, the location of the top 50 conflict-responsive voxels in left MFG, and the top 50 language-responsive voxels in left MTG, varied widely across subjects ( Figure 5A ). 
 Unlike the pVLPFC region described earlier, these two control regions responded to only one of our two functional localizers: The Stroop-conflict ROI in left MFG was not on average responsive during sentence reading, while the sentence-comprehension ROI in left MTG was not responsive to Stroop conflict. The average left MFG signal change across all sentential conditions was not reliably different from baseline in either Experiment 1 ( t (15) = −0.02,  p =  .98) or Experiment 2 ( t (15) = −1.10,  p =  .29). Likewise, left MTG signal change was not reliably different between Stroop conflict trials and neutral trials in either Experiment 1 ( t (15) = 0.55,  p =  .59) or Experiment 2 ( t (15) = −1.29,  p =  .22). Within these subject-specific ROIs, we repeated for each experiment the subject-wise and item-wise analyses described above for object state-change and action imageability. 
 For each experiment, we used anANOVA to test for the interaction between region (pVLPFC, MFG, and MTG) and the degree to which the object state-change ratings predicted BOLD response amplitude. Object state-change beta coefficients differed significantly across ROIs for both Experiment 1 ( F (2,30) = 3.98,  p  = .03), and Experiment 2 ( F (2,30) = 3.74,  p  = .04). Planned comparisons further revealed that object state-change did not reliably predict signal amplitude in either the left MFG Stroop-conflict ROI ( Figure 5B ) or the left MTG sentence-comprehension ROI ( Figure 5C ). For Experiment 1, beta coefficients for object state-change were reliably different between left MTG and left pVLPFC ROIs ( t (15) = 3.43,  p =  .004), while the difference between left MFG and left pVLPFC beta coefficients did not reach significance ( t (15) = 1.17,  p =  .26). For Experiment 2, object state-change beta coefficients in both left MTG ( t (15) = 2.36,  p =  .03) and left MFG ( t (15) = 2.44,  p =  .03) were reliably different from pVLPFC. Object state-change beta coefficients were not reliably different between left MTG and left MFG in either experiment ( p ’s > .1). 
 We conducted a similar set of analyses in order to examine interactions between region and imageability. The action imageability beta coefficients did not reliably differ across ROIs for either Experiment 1 ( F (2,30) = 1.97,  p  = .16), or Experiment 2 ( F (2,30) = 1.31,  p  = .28). Experiment 1 planned comparisons, however, revealed a negative correlation between action imageability ratings and left MTG response amplitude ( t (15) = −2.2,  p  = .04), while the difference between action imageability beta coefficients in left MTG and left pVLPFC was marginally reliable ( t (15) = 1.77,  p  = .10). In Experiment 2, in which the variance of the action imageability ratings was more constrained ( σ2  = 0.37 for Experiment 1;  σ2  = 0.18 for Experiment 2), MTG beta coefficients for action imageability did not reliably differ from either baseline or from any other ROI ( p ’s > .1). 
 
 
 Whole-brain conjunction analysis of Experiments 1 and 2 
 To compare the influence of object state-change on neural activity across the two experiments, we first co-varied out activation predicted by the action imageability ratings for each experiment, and then measured the extent to which activation of each voxel was predicted by the object state-change ratings (correcting for multiple comparisons). Both experiments showed extensive change-related activity in left pVLPFC ( Figure 6A ;  Table 2 ). Additionally, there was an interaction between Experiment and the object state-change effect in the right inferior parietal lobule, an area specifically implicated in studies of gesture recognition and body schema, in which action understanding is independent of objects ( Hermsdörfer et al., 2001 ;  Chaminade et al., 2005 ). Right supramarginal gyrus was significantly more responsive to object state-change in Experiment 1, in which the described action varied across “substantial state-change” and “minimal state-change” conditions, than in Experiment 2, in which the described action was identical across conditions ( Figure 6B ). 
 
 
 
 Discussion 
 Tracking objects across events requires maintaining multiple representations of the same object in different states. We demonstrate that this component of event cognition elicits a neural response in left pVLPFC that overlaps with increased activation for conflict trials in a Stroop color-word interference task. Through analysis of rated stimulus norms, we further observe that the degree to which an object is changed during an event parametrically predicts the BOLD response amplitude in left pVLPFC voxels most sensitive to Stroop conflict; the rated imageability of the action does not. In Experiment 1, the described object was identical for the “substantial state-change” and “minimal state-change” conditions; the state-change manipulation was thus driven by the described action. In Experiment 2, the described action was identical across conditions; the state-change manipulation was driven instead by the affordances of the described object. 
 Convergence across experiments demonstrates the generalizability of the effects of object state-change on semantic conflict. By varying the number of voxels included in the left pVLPFC Stroop-conflict ROI, we demonstrate that this effect is robust within subjects across a wide range of ROI sizes. Moreover, the reliable item-wise correlations between object state-change ratings and BOLD response amplitude in the left pVLPFC Stroop-conflict ROI suggests that the effects generalize across a diverse stimulus population of actions, objects, and events, and highlights the utility of item analysis of fMRI data ( Bedny et al., 2007 ). 
 In each experiment we observe a dissociation among three sets of voxels: 1) voxels in left pVLPFC that are sensitive to Stroop conflict and are activated above baseline during sentence comprehension; 2) voxels in left MFG that are sensitive to Stroop conflict but are  not  activated above baseline during sentence comprehension; and 3) voxels in left MTG that are  not  sensitive to Stroop conflict but are activated above baseline during sentence comprehension. In each experiment, object state-change ratings parametrically predicted BOLD amplitude in the left pVLPFC Stroop-conflict ROI, while action imageability ratings did not. This functional dissociation within the left pVLPFC Stroop-conflict ROI is in stark contrast to patterns of results in both left MFG and left MTG. 
 In the left MFG Stroop-conflict ROI, which was responsive to Stroop conflict but not to sentence reading, neither object state-change nor action imageability reliably predicted BOLD amplitude. While left MFG has been shown to be responsive to Stroop conflict beyond the level of motor response ( Milham et al., 2001 ), it is generally not associated with  semantic  conflict ( Binder et al., 2009 ), and dissociates from left pVLPFC with respect to item-specific memory interference, as evidenced by neuroimaging ( D’Esposito et al., 1999 ), patient lesion ( Thompson-Schill et al., 2002 ), and transcranial magnetic stimulation (Feredoes and Postle, 2010) studies. Instead, posterior-most areas of left MFG, where we observe the greatest cross-subject overlap of this ROI, may be specifically involved in maintaining  task  representations ( Derrfuss et al., 2005 ). 
 In the left MTG sentence-comprehension ROI, which was not responsive to Stroop conflict but was responsive during sentence reading, object state-change did not predict BOLD amplitude in either experiment. However, in Experiment 1, the rated imageability of the described action negatively correlated with MTG signal. Because event comprehension places a stronger demand on semantic retrieval processes when it is more difficult to bring to mind a clear mental image of the described action, the negative correlation of action imageability ratings with left MTG activation is concordant with studies of left MTG responsiveness to difficulty manipulations in semantic retrieval tasks (e.g.,  Whitney et al., 2011 ). The absence of an action imageability effect in Experiment 2 is predicted by reduced variance of the action imageability ratings (the described action was fixed across state-change conditions). The modulation of left pVLPFC and left MTG by object state-change and action imageability respectively, replicates previous dissociations between these regions (e.g.,  Thompson-Schill et al., 1999 ;  Bedny et al., 2008 ), indicating functionally distinct contributions of these regions to event comprehension. 
 In contrast to left MTG and left MFG, left pVLPFC is consistently shown to be central in resolving competition amongst incompatible semantic representations ( Thompson-Schill et al., 2005 ). Neuroimaging, patient lesion, and transcranial magnetic stimulation studies demonstrate that left pVLPFC is activated during and is necessary for overriding misinterpretations of syntactically ambiguous sentences ( January et al., 2009 ), selecting context-appropriate meanings of ambiguous words ( Metzler, 2001 ;  Hindy et al., 2009 ), completing sentences that have multiple alternative responses ( Robinson et al., 1998 ;  Robinson et al., 2005 ), generating verbs with many semantic competitors ( Thompson-Schill et al., 1997 ), and resolving working memory interference in item recognition ( Feredoes et al., 2006 ). 
 Stepping back from the ROIs, and examining activation across the entire brain, we see that voxels sensitive to the object state-change manipulation overlapped across experiments in left pVLPFC. In contrast, areas of the inferior parietal lobe that were sensitive to the state-change manipulation in Experiment 1 were not sensitive to this manipulation in Experiment 2. Because the described action varied across conditions in Experiment 1, but was fixed across conditions in Experiment 2, this dissociation is consistent with literature that associates these inferior parietal lobe areas with action representation independent of the objects acted upon ( Glover, 2004 ). 
 Stepping back further, and considering the theoretical implications of these data, correlations between rated degree of object state-change and BOLD response in the left pVLPFC Stroop-conflict ROI may at first seem consistent with an account that the more an object is changed in state during the first sentence of a trial, the more information must be inferred to derive the context-appropriate representation of the same object in the second sentence. This would predict, however, an interaction with temporal context in Experiment 1, because in the ‘and then’ case, the state computed at the end of the first sentence is identical to that referred to at the end of the second (but would be different in the ‘but first’ case). There was, however, no such interaction. Additionally, Experiment 2 participants only ever read “ and then”  versions of the stimuli, encouraging maintenance of only the changed instantiation, yet we still observed evidence of conflict. Alternatively, one might suppose that the more an object is changed in state, the more information must be kept in memory. This would not predict any interaction with temporal context. However, the left pVLPFC has elsewhere been shown to be associated with resolving interference in working memory  independently  of working memory itself ( Thompson-Schill et al., 2002 ). Thus, the location in which we observe sensitivity to object state-change, as well as the functional specificity of the ROI to Stroop conflict, suggests that our data do not reflect memory load. 
 We conjecture instead that multiple instantiations of the same object (whether of the object representation in its entirety, or of components of the object representation) must be represented when the object is described as changing in state, and that there is interference between these instantiations. This could include interference between the sensorimotor instantiations of the different affordances associated with distinct object states, mediated by the event representations within which multiple object instantiations are distinguished (cf.  Zwaan and Radvinsky, 1998 ). Because objects were generally changed from a canonical state to a marked state, the strength of the initially activated object representation may modulate the extent to which this initial representation remains active even after the contextually appropriate object representation has been computed. And while language and memory research ( Bower, 2000 ;  Van Dyke and McElree, 2006 ) has shown evidence of  similarity -based interference between actively maintained object representations, we find that the more dissimilar the ‘before’ and ‘after’ instantiations of an object, the greater the interference. This difference between distinct  objects  (similarity-based interference) and distinct  instantiations  of a single object (dissimilarity-based interference) may have its roots in the fact that the distinct instantiations of an object across event-time (i.e., the ‘before’ and ‘after’) are mutually exclusive—they cannot co-exist. Distinct  objects , on the other hand, can co-exist no matter how similar; the greater the overlap between the objects’ representations, the greater the interference, but differences between the objects do not have consequences for co-existence and are not inhibitory. When we need to categorize distinct representations as instantiations of a single object, left pVLPFC may act as a top-down modulatory signal to bias candidate representations—and the neural patterns that instantiate them—toward the context-appropriate representation of the object, performing a similar interference resolution process as described for other forms of ambiguity resolution ( Thompson-Schill and Botvinick, 2006 ). 
 Our ability to comprehend, represent, recall, and narrate events is a quintessentially human ability. Yet the representation of multiple instantiations of the same object across “event time” (i.e., before, during, and after the event occurs), and how these may compete with one another, is a topic that has not received attention in cognitive psychology. Taken together, data reported here suggest that the need to represent the same object in different states comes at a competitive  cost.  The work reported here is a step toward identifying these representational mechanisms, and speaks to future cognitive models of object and event representation, allowing more detailed exploration of the representations over which the human cognitive system operates. 
 
 
 
 This research was funded by an NIH award to STS (ROI DC009209), ESRC awards to GA (RES-063-27-0138 and RES-062-23-2749), and an NSF graduate research fellowship to NCH. We are grateful to Kara Cohen for help with stimulus development, and to Xin Kang for help with stimulus norming. 
 
 
 
 1 
 In a whole-brain analysis, the Experiment 1 contrast of temporal context (i.e., “but first” vs. “and then”) did not reveal any reliable clusters of increased activation anywhere in the brain. However, though not reliable after correcting for multiple comparisons, the largest cluster of increased activation for conditions that required temporal re-sequencing was in left posterior superior temporal sulcus, an area often linked to speech processing as well as to theory of mind (cf.  Hein and Knight, 2008 ). 
 
 
 
 
 
 
 
 Altmann 
 GT 
 
 
 Kamide 
 Y 
 
 
 2009 
 Discourse-mediation of the mapping between language and the visual world: Eye movements and mental representation 
 Cognition 
 111 
 55 
 71 
 19193366 
 
 
 
 
 
 
 Amunts 
 K 
 
 
 Schleicher 
 A 
 
 
 Bürgel 
 U 
 
 
 Mohlberg 
 H 
 
 
 Uylings 
 HB 
 
 
 Zilles 
 K 
 
 
 1999 
 Broca’s region revisited: cytoarchitecture and intersubject variability 
 The Journal of Comparative Neurology 
 412 
 319 
 341 
 10441759 
 
 
 
 
 
 
 Bedny 
 M 
 
 
 Aguirre 
 GK 
 
 
 Thompson-Schill 
 SL 
 
 
 2007 
 Item analysis in functional magnetic resonance imaging 
 Neuroimage 
 35 
 1093 
 1102 
 17346988 
 
 
 
 
 
 
 Bedny 
 M 
 
 
 McGill 
 M 
 
 
 Thompson-Schill 
 SL 
 
 
 2008 
 Semantic adaptation and competition during word comprehension 
 Cerebral Cortex 
 18 
 2574 
 2585 
 18308708 
 
 
 
 
 
 
 Binder 
 JR 
 
 
 Desai 
 RH 
 
 
 Graves 
 WW 
 
 
 Conant 
 LL 
 
 
 2009 
 Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies 
 Cerebral Cortex 
 19 
 2767 
 2796 
 19329570 
 
 
 
 
 
 
 Bower 
 GH 
 
 
 2000 
 A brief history of memory research 
 The Oxford Handbook of Memory 
 3 
 32 
 
 
 
 
 
 
 Brysbaert 
 M 
 
 
 New 
 B 
 
 
 2009 
 Moving beyond Kučera and Francis: A critical evaluation of current word frequency norms and the introduction of a new and improved word frequency measure for American English 
 Behavior Research Methods 
 41 
 977 
 990 
 19897807 
 
 
 
 
 
 
 Burke 
 RJ 
 
 
 2009 
 Roger’s Reference: The Complete Homonym/Homophone Dictionary 
 7 
 Educational Multimedia Publishing 
 
 
 
 
 
 
 Chaminade 
 T 
 
 
 Meltzoff 
 AN 
 
 
 Decety 
 J 
 
 
 2005 
 An fMRI study of imitation: Action representation and body schema 
 Neuropsychologia 
 43 
 115 
 127 
 15488911 
 
 
 
 
 
 
 Cox 
 RW 
 
 
 1996 
 AFNI: software for analysis and visualization of functional magnetic resonance neuroimages 
 Computers and Biomedical Research 
 29 
 162 
 173 
 8812068 
 
 
 
 
 
 
 Derrfuss 
 J 
 
 
 Brass 
 M 
 
 
 Neumann 
 J 
 
 
 Von Cramon 
 DY 
 
 
 2005 
 Involvement of the inferior frontal junction in cognitive control: Meta-analyses of switching and Stroop studies 
 Human Brain Mapping 
 25 
 22 
 34 
 15846824 
 
 
 
 
 
 
 D’Esposito 
 M 
 
 
 Postle 
 BR 
 
 
 Ballard 
 D 
 
 
 Lease 
 J 
 
 
 1999 
 Maintenance versus manipulation of information held in working memory: An event-related fMRI study 
 Brain and Cognition 
 41 
 66 
 86 
 10536086 
 
 
 
 
 
 
 Eickhoff 
 SB 
 
 
 Stephan 
 KE 
 
 
 Mohlberg 
 H 
 
 
 Grefkes 
 C 
 
 
 Fink 
 GR 
 
 
 Amunts 
 K 
 
 
 Zilles 
 K 
 
 
 2005 
 A new SPM toolbox for combining probabilistic cytoarchitectonic maps and functional imaging data 
 Neuroimage 
 25 
 1325 
 1335 
 15850749 
 
 
 
 
 
 
 Feredoes 
 E 
 
 
 Tononi 
 G 
 
 
 Postle 
 BR 
 
 
 2006 
 Direct evidence for a prefrontal contribution to the control of proactive interference in verbal working memory 
 Proceedings of the National Academy of Sciences 
 103 
 19530 
 19534 
 
 
 
 
 
 
 Glover 
 S 
 
 
 2004 
 Separate visual representations in the planning and control of action 
 Behavioral and Brain Sciences 
 27 
 3 
 24 
 15481943 
 
 
 
 
 
 
 Hein 
 G 
 
 
 Knight 
 RT 
 
 
 2008 
 Superior temporal sulcus-it’s my area: Or is it? 
 Journal of Cognitive Neuroscience 
 20 
 2125 
 2136 
 18457502 
 
 
 
 
 
 
 Hermsdörfer 
 J 
 
 
 Goldenberg 
 G 
 
 
 Wachsmuth 
 C 
 
 
 Conrad 
 B 
 
 
 Ceballos-Baumann 
 A 
 
 
 Bartenstein 
 P 
 
 
 Schwaiger 
 M 
 
 
 Boecker 
 H 
 
 
 2001 
 Cortical correlates of gesture processing: clues to the cerebral mechanisms underlying apraxia during the imitation of meaningless gestures 
 Neuroimage 
 14 
 149 
 161 
 11525324 
 
 
 
 
 
 
 Hindy 
 NC 
 
 
 Hamilton 
 R 
 
 
 Houghtling 
 AS 
 
 
 Coslett 
 H 
 
 
 Thompson-Schill 
 SL 
 
 
 2009 
 Computer-mouse tracking reveals TMS disruptions of prefrontal function during semantic retrieval 
 Journal of Neurophysiology 
 102 
 3405 
 19812291 
 
 
 
 
 
 
 January 
 D 
 
 
 Trueswell 
 JC 
 
 
 Thompson-Schill 
 SL 
 
 
 2009 
 Co-localization of Stroop and syntactic ambiguity resolution in Broca’s area: Implications for the neural basis of sentence processing 
 Journal of Cognitive Neuroscience 
 21 
 2434 
 2444 
 19199402 
 
 
 
 
 
 
 Jonides 
 J 
 
 
 Smith 
 EE 
 
 
 Marshuetz 
 C 
 
 
 Koeppe 
 RA 
 
 
 Reuter-Lorenz 
 PA 
 
 
 1998 
 Inhibition in verbal working memory revealed by brain activation 
 Proceedings of the National Academy of Sciences 
 95 
 8410 
 
 
 
 
 
 
 Martin 
 A 
 
 
 2007 
 The representation of object concepts in the brain 
 Annual Review of Psychology 
 58 
 25 
 45 
 
 
 
 
 
 
 Metzler 
 C 
 
 
 2001 
 Effects of left frontal lesions on the selection of context-appropriate meanings 
 Neuropsychology 
 15 
 315 
 328 
 11499987 
 
 
 
 
 
 
 Milham 
 MP 
 
 
 Banich 
 MT 
 
 
 Webb 
 A 
 
 
 Barad 
 V 
 
 
 Cohen 
 NJ 
 
 
 Wszalek 
 T 
 
 
 Kramer 
 AF 
 
 
 2001 
 The relative involvement of anterior cingulate and prefrontal cortex in attentional control depends on nature of conflict 
 Cognitive Brain Research 
 12 
 467 
 473 
 11689307 
 
 
 
 
 
 
 Novick 
 JM 
 
 
 Trueswell 
 JC 
 
 
 Thompson-Schill 
 SL 
 
 
 2005 
 Cognitive control and parsing: Reexamining the role of Broca’s area in sentence comprehension 
 Cognitive, Affective, & Behavioral Neuroscience 
 5 
 263 
 
 
 
 
 
 
 Robinson 
 G 
 
 
 Blair 
 J 
 
 
 Cipolotti 
 L 
 
 
 1998 
 Dynamic aphasia: An inability to select between competing verbal responses? 
 Brain 
 121 
 77 
 9549489 
 
 
 
 
 
 
 Robinson 
 G 
 
 
 Shallice 
 T 
 
 
 Cipolotti 
 L 
 
 
 2005 
 A failure of high level verbal response selection in progressive dynamic aphasia 
 Cognitive Neuropsychology 
 22 
 661 
 694 
 21038272 
 
 
 
 
 
 
 Thompson-Schill 
 SL 
 
 
 Bedny 
 M 
 
 
 Goldberg 
 RF 
 
 
 2005 
 The frontal lobes and the regulation of mental activity 
 Current Opinion in Neurobiology 
 15 
 219 
 224 
 15831406 
 
 
 
 
 
 
 Thompson-Schill 
 SL 
 
 
 Botvinick 
 MM 
 
 
 2006 
 Resolving conflict: A response to Martin and Cheng (2006) 
 Psychonomic Bulletin & Review 
 13 
 402 
 408 
 17048722 
 
 
 
 
 
 
 Thompson-Schill 
 SL 
 
 
 D’Esposito 
 M 
 
 
 Aguirre 
 GK 
 
 
 Farah 
 MJ 
 
 
 1997 
 Role of left inferior prefrontal cortex in retrieval of semantic knowledge: A reevaluation 
 Proceedings of the National Academy Sciences 
 94 
 14792 
 14797 
 
 
 
 
 
 
 Thompson-Schill 
 SL 
 
 
 D’Esposito 
 M 
 
 
 Kan 
 IP 
 
 
 1999 
 Effects of Repetition and Competition on activity in left prefrontal cortex during word generation 
 Neuron 
 23 
 513 
 522 
 10433263 
 
 
 
 
 
 
 Thompson-Schill 
 SL 
 
 
 Jonides 
 J 
 
 
 Marshuetz 
 C 
 
 
 Smith 
 EE 
 
 
 D’Esposito 
 M 
 
 
 Kan 
 IP 
 
 
 Knight 
 RT 
 
 
 Swick 
 D 
 
 
 2002 
 Effects of frontal lobe damage on interference effects in working memory 
 Cognitive, Affective, & Behavioral Neuroscience 
 2 
 109 
 120 
 
 
 
 
 
 
 Van Dyke 
 JA 
 
 
 McElree 
 B 
 
 
 2006 
 Retrieval interference in sentence comprehension 
 Journal of Memory & Language 
 55 
 157 
 166 
 18209744 
 
 
 
 
 
 
 Whitney 
 C 
 
 
 Kirk 
 M 
 
 
 O’Sullivan 
 J 
 
 
 Lambon Ralph 
 MA 
 
 
 Jefferies 
 E 
 
 
 2011 
 The neural organization of semantic control: TMS evidence for a distributed network in left inferior frontal and posterior middle temporal gyrus 
 Cerebral Cortex 
 21 
 1066 
 20851853 
 
 
 
 
 
 
 Zwaan 
 RA 
 
 
 Radvansky 
 GA 
 
 
 1998 
 Situation models in language comprehension and memory 
 Psychological Bulletin 
 123 
 162 
 185 
 9522683 
 
 
 
 
 
 
 Figure 1 
 
 Object state-change ratings for the first sentence of each item in the event comprehension task. (A) Experiment 1 items, including each item’s “minimal state-change” condition and “substantial state-change” condition, ranked by object state-change. (B) Experiment 2 items ranked by object state-change. 
 
 
 
 
 Figure 2 
 
 Stroop-conflict ROI in left pVLPFC. (A) Whole-brain group-level contrast of conflict trials versus neutral trials in the Stroop color-word interference task, thresholded at a corrected alpha of  p  < .01, and displayed on a partially inflated Talairach surface; left pVLPFC is outlined in white. (B) Probabilistic overlap map of the subject-specific Stroop-conflict ROIs in left pVLPFC. Each subject-specific ROI included the 50 left pVLPFC with the highest within-subject  t -statistics for the Stroop contrast. The left pVLPFC voxel with the greatest overlap across subjects included 7 of the 32 total subjects from both Experiment 1 and Experiment 2. 
 
 
 
 
 Figure 3 
 
 Experiment 1 left pVLPFC Stroop-conflict ROI analysis. (A) Percent signal change plots from a categorical analysis of the “minimal state-change” and “substantial state-change” conditions. (B) Beta coefficients across a broad range of ROI sizes from a subject-wise parametric analysis of voxel activation predicted by object state-change and action imageability stimulus ratings. A vertical line indicates the 50-voxel threshold for each subject’s left pVLPFC Stroop-conflict ROI. Error bars indicate ± 1 standard error of the mean. (C) Binned quartile visualization of the subject-wise parametric analysis. (D) Item analysis of stimulus ratings and voxel activation. Item-specific activation, averaged across subjects, in the left pVLPFC Stroop-conflict ROI is plotted against the object state-change and action imageability stimulus ratings. 
 
 
 
 
 Figure 4 
 
 Experiment 2 left pVLPFC Stroop-conflict ROI analysis. (A) Categorical analysis. (B) Subject-wise parametric analysis beta coefficients across a broad range of ROI sizes. (C) Binned quartile visualizations of the subject-wise parametric analysis. (D) Item analysis of stimulus ratings and voxel activation. 
 
 
 
 
 Figure 5 
 
 Left MFG and left MTG ROI analysis for Experiments 1 and 2. (A) Probabilistic overlap maps of the subject-specific Stroop-conflict ROI in left MFG and the subject-specific sentence-comprehension ROI in left MTG. (B) Subject-wise parametric analysis beta coefficients across a broad range of Stroop-conflict ROI sizes for each experiment in left MFG. (C) Subject-wise beta coefficients across a broad range of sentence-comprehension ROI sizes for each experiment in left MTG. 
 
 
 
 
 Figure 6 
 
 Whole-brain conjunction analysis of Experiments 1 and 2. (A) Overlap of Experiment 1 and Experiment 2 voxels reliably predicted by the object state-change ratings, after removing variance predicted by the action imageability ratings. (B) Between-experiment differences in object state-change responsive voxels. Each contrast is thresholded at  p  < .05, corrected for multiple comparisons. 
 
 
 
 
 Table 1 
 
 Example stimuli from each experiment. 
 
 
 
 
 EXPERIMENT 1 
 (object fixed, action varied) 
 
 
 
 
 
 
 
 
 
 State-Change Condition 
 
 object state-change 
 action imageability 
 
 
 
 
 minimal 
 The squirrel will sniff the acorn. And then/But first, it will lick the acorn. 
 1.87 
 5.00 
 
 
 substantial 
 The squirrel will crack the acorn. And then/But first, it will lick the acorn. 
 5.17 
 5.68 
 
 
 minimal 
 The chef will weigh the onion. And then/But first, she will smell the onion. 
 1.51 
 5.26 
 
 
 substantial 
 The chef will chop the onion. And then/But first, she will smell the onion. 
 5.79 
 6.00 
 
 
 minimal 
 The musician will play the piano. And then/But first, he will rave about the piano. 
 2.47 
 5.89 
 
 
 substantial 
 The musician will tune the piano. And then/But first, he will rave about the piano. 
 4.34 
 5.13 
 
 
 
 EXPERIMENT 2 
 
 (object varied, action fixed) 
 
 
 
 
 
 
 
 
 
 minimal 
 The girl will stomp on the penny. And then, she will look down at the penny. 
 1.74 
 5.55 
 
 
 substantial 
 The girl will stomp on the egg. And then, she will look down at the egg. 
 6.20 
 6.28 
 
 
 minimal 
 The girl will blow on the dice. And then, she will smile about the dice. 
 1.72 
 5.87 
 
 
 substantial 
 The girl will blow on the dandelion. And then, she will smile about the dandelion. 
 5.29 
 6.19 
 
 
 minimal 
 The karate instructor will kick the foam pad. And then, he will hold up the pad. 
 2.66 
 6.07 
 
 
 substantial 
 The karate instructor will kick the wooden board. And then, he will hold up the board. 
 5.12 
 5.98 
 
 
 
 
 
 Object state-change and action imageability for each sentence of each item was rated on a 7-point scale. fMRI participants read each item in only one condition. The object state-change and action imageability ratings in the rightmost columns are specific to the first sentence of each item shown. 
 
 
 
 
 Table 2 
 
 Whole-brain analysis for Experiments 1 and 2. 
 
 
 
 
 Experiment 1 (object fixed, action varied)
 
 
 
 
 # vox 
 
 
 peak t 
 
 
 x 
 
 
 y 
 
 
 z 
 
 
 Brain region 
 
 
 
 
 
 182 
 6.7 
 43.5 
 −10.5 
 11.5 
 L. pVLPFC (p. opercularis) 
 
 
 143 
 7.42 
 −46.5 
 55.5 
 47.5 
 R. supramarginal gyrus 
 
 
 109 
 5.91 
 40.5 
 −25.5 
 29.5 
 L. pVLPFC (inferior frontal sulcus) 
 
 
 105 
 5.53 
 40.5 
 43.5 
 35.5 
 L. supramarginal gyrus 
 
 
 74 
 4.45 
 1.5 
 −19.5 
 41.5 
 L. DMPFC 
 
 
 57 
 4.91 
 −28.5 
 −19.5 
 2.5 
 R. insula 
 
 
 
 
 
 
 Experiment 2 (object varied, action fixed)
 
 
 
 
 # vox 
 
 
 peak t 
 
 
 x 
 
 
 y 
 
 
 z 
 
 
 Brain region 
 
 
 
 
 
 188 
 6.13 
 52.5 
 −28.5 
 2.5 
 L. pVLPFC (p. triangularis) 
 
 
 139 
 5.67 
 10.5 
 4.5 
 20.5 
 L. caudate nucleus 
 
 
 136 
 5.81 
 4.5 
 −34.5 
 32.5 
 L. DMPFC 
 
 
 52 
 4.05 
 40.5 
 −40.5 
 11.5 
 L. pVLPFC (p. triangularis) 
 
 
 
 
 
 
 Experiment 1 > Experiment 2
 
 
 
 
 # vox 
 
 
 peak t 
 
 
 x 
 
 
 y 
 
 
 z 
 
 
 Brain region 
 
 
 
 
 
 79 
 4.31 
 −46.5 
 43.5 
 41.5 
 R. supramarginal gyrus 
 
 
 
 
 
 Clusters of voxels reliably predicted by the object state-change ratings, after removing variance predicted by the action imageability ratings out. Each contrast is thresholded at  p  < .05, corrected for multiple comparisons. There were no statistically reliable voxel clusters with Experiment 2 > Experiment 1. Talairach coordinates and anatomical labels indicate the location of the peak voxel of each cluster. DMPFC = dorsomedial prefrontal cortex. 
 
 
 
 
