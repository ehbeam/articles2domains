
 properties manuscript? 
 
 
 0020713 
 6083 
 Neuropsychologia 
 Neuropsychologia 
 
 Neuropsychologia 
 
 0028-3932 
 1873-3514 
 
 
 22750118 
 3423083 
 10.1016/j.neuropsychologia.2012.06.016 
 NIHMS390198 
 
 
 Article 
 
 
 
 The response of face-selective cortex with single face parts and part combinations 
 
 
 
 
 Dachille 
 Lindsay R. 
 
 
 
 
 Gold 
 Jason M. 
 
 
 
 
 James 
 Thomas W. 
 
 
 Department of Psychological and Brain Sciences, Indiana University 
 
 
 Corresponding author: TWJ, 1101 E Tenth St. Bloomington, IN 47405,  thwjames@indiana.edu , 812-856-0841 
 
 
 20 
 7 
 2012 
 
 
 26 
 6 
 2012 
 
 
 8 
 2012 
 
 
 01 
 8 
 2013 
 
 50 
 10 
 2454 
 2459 
 
 
 This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law. 
 
 
 
 A critical issue in object recognition research is how the parts of an object are analyzed by the visual system and combined into a perceptual whole. However, most of the previous research has examined how changes to object parts influence recognition of the whole, rather than recognition of the parts themselves. This is particularly true of the research on face recognition, and especially with questions related to the neural substrates. Here, we investigated patterns of BOLD fMRI brain activation with internal face parts (features) presented singly and in different combinations. A preference for single features over combinations was found in the occipital face area (OFA) as well as a preference for the two-eyes combination stimulus over other combination stimulus types. The fusiform face area (FFA) and lateral occipital cortex (LO) showed no preferences among the single feature and combination stimulus types. The results are consistent with a growing view that the OFA represents processes involved in early, feature-based analysis. 
 
 
 object recognition 
 face recognition 
 fmri 
 occipital face area 
 feature-based processing 
 
 
 
 The processes involved in object recognition, and especially in face recognition, are often dichotomized into part/feature-based and holistic/configural ( Farah, Wilson, Drain, & Tanaka, 1998 ;  Maurer, Le Grand, & Mondloch, 2002 ;  McKone & Yovel, 2009 ;  Rossion, 2008 ). Although there has been a considerable amount of research investigating the behavioral and neural markers of holistic/configural processing and also of feature changes on holistic/configural processing, there has been relatively little research investigating markers of single part-based processing. Studies that restrict viewing to isolated features converge with eye-movement studies to suggest that face recognition relies largely on the eye/eyebrow regions, followed by the mouth regions, followed by the nose regions ( Blais, Jack, Scheepers, Fiset, & Caldara, 2008 ; Caldara, Zhou, & Miellet;  Haig, 1986 ;  James, Huh, & Kim, 2010 ;  Yarbus, 1967 ). Studies using response classification or reverse correlation techniques converge with the other methods to suggest that face recognition relies mostly on eye/eyebrow regions, followed by mouth regions ( Schyns, Bonnar, & Gosselin, 2002 ;  Sekuler, Gaspar, Gold, & Bennett, 2004 ). Finally, ideal observer techniques converge with the other methods to show that eye/eyebrow regions carry the most information for face recognition, followed by the mouth regions, followed by the nose regions ( Gold, Bennett, & Sekuler, 1999 ;  Gold, Mundy, & Tjan, in press ). Thus, the results of these behavioral studies suggest that, despite the fact that faces may tend to be analyzed using highly configural/holistic strategies, there are parts of the face that are more informative than others and that are analyzed preferentially. 
 There are only a few studies that have investigated the neural substrates involved in processing these informative parts of a face, but they suggest several important points about the patterns of brain activation found in regions of face- and object-selective cortex. First, there is some evidence that the activation in the FFA, which to some is taken as the hallmark of whole face processing ( Kanwisher & Yovel, 2006 ), is just as sensitive to partial images of faces as it is to whole face images ( James, et al., 2010 ;  Tong, Nakayama, Moscovitch, Weinrib, & Kanwisher, 2000 ). Second, fragments of faces that are high in “diagnosticity” produce greater levels of activation in the FFA, occipital face area (OFA), and lateral occipital cortex (LO), than fragments that are low in diagnosticity ( Lerner, Epshtein, Ullman, & Malach, 2008 ;  Nestor, Vettel, & Tarr, 2008 ). Third, despite the fact that the FFA has been shown to be equally sensitive to whole and partial faces, the FFA has been shown to play a greater role in processing whole faces than the OFA and the OFA plays a greater role in the processing face parts than the FFA ( Betts & Wilson, 2010 ;  Nichols, Betts, & Wilson, 2010 ), suggesting that the processing of wholes and parts may not be all-or-none. Most recently, a series of studies using TMS to disrupt processing in the OFA has found evidence that it is highly involved in the processing of face parts ( Pitcher, Charles, Devlin, Walsh, & Duchaine, 2009 ; Pitcher, Duchaine, Walsh, Yovel, & Kanwisher;  Pitcher, Walsh, & Duchaine, 2011 ;  Pitcher, Walsh, Yovel, & Duchaine, 2007 ). These results have led to the hypothesis that the OFA may represent a site of early-stage face-part processing that feeds into the FFA, which represents a site of late-stage whole face processing ( Pitcher, et al., 2011 ). 
 The goal of the present study was to extend research on the neural substrates of feature-based processing of faces. fMRI was used to measure BOLD activation with single internal face features and different combinations of those features. We hypothesized that the OFA would respond strongly with face features and would show a gradient of sensitivity across different face features, with highest sensitivity for eye features and lowest sensitivity for nose features. Based on the idea that the FFA represents a later stage of processing that may involve the integration of features, we hypothesized that the FFA would show more activation with combination stimuli than with single features. Alternatively, the FFA may respond weakly and equivalently across the stimulus types, because they all lack a whole-face context. 
 
 Materials and Methods 
 
 Subjects 
 Fourteen healthy adults (7 male, ages 21–32) participated for payment. Two subjects were excluded from the fMRI analysis due to motion artifacts in the functional imaging data. All subjects signed informed consent forms, and the Indiana University Institutional Review Board approved the study. 
 
 
 Stimuli 
 Twelve face images (6 male, 6 female) were created with FaceGen 3.2 ( www.facegen.com ) and are shown in the top of  Figure 1 . Parameters in FaceGen were selected such that all faces were between the ages of 20–30, symmetric, and equally attractive. Faces were rendered as 256 × 256 pixel grayscale images. Different sized apertures were used for the eye/eyebrow, nose, and mouth features, but across face images, the size and position of the apertures was kept constant. The final set of single feature stimuli included left eye/eyebrow, right eye/eyebrow, nose, and mouth. Multi-feature combination stimuli were created by combining two, three, or four single features, always taken from the same face, and always positioned in the correct spatial location. The combinations used were the two eyes (2-feature), eyes and mouth (3-feature), and eyes, nose, and mouth (4-feature). It is worthwhile noting that in these seven single feature and combination feature stimulus types, no face outline was used. Examples of the stimuli in  Figure 1  are shown embedded in the same level of noise used during scanning (see procedures below). The top row is shown at the mean contrast level used during scanning. The bottom row is shown at a much higher contrast level for illustration purposes. 
 
 
 Scanning Session Procedures 
 Subjects underwent a pre-scan practice procedure in a MRI simulator located in the Indiana University Imaging Research Facility to familiarize the subjects with the MRI environment, familiarize the subjects with the task, and to help limit any perceptual learning during the subsequent scanning session. 
 Subjects lay supine in the scanner bore with their head secured in the head coil by foam padding. Subjects viewed stimuli through a mirror that was mounted above the head coil. This allowed the subjects to see the stimuli on a rear-projection screen (40.2 × 30.3 cm) placed behind the subject in the bore. Stimuli were projected onto the screen with a Mitsubishi LCD projector (model XL30U). The viewing distance from the mirror to the eyelid was 11.5 cm, and the distance from the screen to the mirror was 79 cm, giving a total viewing distance of 90.5 cm. When projected in this manner, the size of the entire 256 × 256 pixel stimulus image subtended approximately 6 degrees of visual angle. 
 Each scanning session consisted of one localizer run and seven experimental runs. The localizer run was included to independently, functionally localize object- and face-selective brain regions, specifically the OFA, FFA, and LO for region of interest (ROI) analyses. During the functional localizer run, full contrast, noise-free, grayscale images of familiar objects (e.g., chair, toaster), faces (different from those used in the experimental runs), and phase-scrambled images (derived from the object and face stimuli) were presented in a blocked design while participants fixated the center of the screen. Six stimuli per block were presented for 1.5 s each with an inter-stimulus interval (ISI) of 500 ms, producing a block time of 12 s. Blocks were presented in 48 s cycles of noise – objects – noise – faces. There were 8 cycles in the single run and the run began and ended with 12 s of rest, making the total run length 6 minutes and 48 seconds. 
 During experimental runs, each of the seven stimulus types was presented at each of three separate contrast levels in a full-factorial 3×7 design. The contrast levels were determined individually for each subject. This was done to bring behavioral performance below ceiling, to reduce variability across subjects, and to assess the influence of stimulus quality on brain activation. For each subject, the exact contrast levels used were determined from the data collected during the pre-scan practice session. The low contrast for each subject was the level that produced 75% accuracy with the eyes-nose-mouth stimulus during practice trials and the high contrast was the level that produced 75% with the mouth stimulus during practice trials. The middle contrast was a level midway between the low and high levels on a log contrast scale. Contrast is reported as the square root of contrast energy (RMS contrast) and signal-to-noise ratio (SNR) is reported as the ratio of signal contrast energy and noise contrast energy. 
 The stimuli were presented in a blocked design while participants performed a one-back matching task. Six stimuli per block were all selected from the same stimulus type. Stimuli in a block of trials were selected from one stimulus type and presented at one contrast level (i.e., trials in a block were taken from the same cell in the 3×7 full-factorial design). Stimuli and were embedded in Guassian noise of constant variance (RMS contrast = 0.1) that was re-sampled each trial. Stimuli were presented for 1 s each with an ISI of 2 s, producing a total block length of 18 s. Stimulus blocks were separated by fixation blocks 12 s in length. Matlab R2008a ( www.mathworks.com ) combined with the Psychophysics Toolbox ( www.psychtoolbox.org ;  Brainard, 1997 ;  Pelli, 1997 ) was used to create the stimuli, adjust the signal-to-noise levels, present the stimuli during the scanning session, and collect the behavioral responses. Each experimental run contained 15 stimulus blocks and 16 fixation blocks, for a total run length of 7 minutes and 42 seconds. Across the 7 runs, there were a total of 105 stimulus blocks, equally divided among the 7 stimulus types, resulting in 15 blocks per stimulus type. 
 
 
 Imaging Parameters and Analysis 
 Imaging data were acquired with a Siemens Magnetom TRIO 3-T whole-body MRI. During data collection, an upgrade was performed to TIM TRIO such that 6 of 14 subjects were collected after the upgrade. In the following text, the post-upgrade imaging parameters are reported in parentheses. The main change post-upgrade was an increase in the in-plane resolution of the functional images, but prior to analysis all images were re-sampled to the same 3 mm 3  resolution. Images were collected using an eight-channel (32-channel) phased-array head coil. The field of view was 220 × 220 mm, with an in-plane resolution of 64 × 64 pixels (128 × 128 pixels) and 33 (35) axial slices of 3.4 mm thickness per volume. These parameters produced voxels that were 3.4 × 3.4 × 3.4 mm (1.7 × 1.7 × 3.4 mm). Functional images were collected using a gradient echo EPI sequence: TE = 25 ms (24 ms), TR = 2,000 ms, flip angle = 70° for BOLD imaging. Parallel imaging was used after the upgrade with a PAT factor of 2. High-resolution T1-weighted anatomical volumes were acquired using a Turbo-flash 3-D sequence: TI = 1,100 ms (900 ms), TE = 2.92 ms (2.67 ms), TR = 2300 ms (1800 ms) flip angle = 12° (9°), with 160 (192) sagittal slices of 1 mm thickness, a field of view of 224 × 256 mm, and an isometric voxel size of 1 mm 3 . 
 Imaging data were analyzed using BrainVoyager ™  QX 2.2. Individual anatomical volumes were transformed into a common stereotactic space based on the reference of the Talairach atlas using an eight-parameter affine transformation. All functional volumes were re-aligned to the functional volume collected closest in time to the anatomical volume using an intensity-based motion-correction algorithm. Functional volumes also underwent slice scan-time correction, 3-D spatial Gaussian filtering (FWHM 6 mm), and linear trend removal. Functional volumes were co-registered to the anatomical volume using an intensity-based matching algorithm and normalized to the common stereotactic space using an eight-parameter affine transformation. During normalization, functional data were re-sampled to 3 mm 3  isometric voxels. Whole-brain statistical parametric maps were calculated using a general linear model with predictors based on the timing protocol of the blocked stimulus presentation, convolved with a two-gamma hemodynamic response function. Defining the cluster for each ROI was done by starting with the voxel with the maximum statistical value and including other voxels within a cube that extended 15 mm in each direction. After determining the voxels included in each ROI cluster, beta weights for each subject were extracted from the ROIs using the ANCOVA table tool in BrainVoyager’s volume of interest module. Statistical hypothesis testing was performed on the extracted beta weights using repeat measures ANOVAs in SPSS. In the figures where graphs show error bars, those error bars represent 95% confidence intervals, calculated using the within-subjects mean squared error from the highest order interaction term. 
 
 
 
 Results 
 The pre-scan practice trials were used to determine individual low, medium, and high contrast levels for each subject to be used during scanning. The mean low RMS contrast level across subjects was 0.0631 (SNR = 0.4393) with a range of 0.035 to 0.110. The mean high RMS contrast level across subjects was 0.0343 (SNR = 0.1236) with a range of 0.022 to 0.055. In an initial analysis, two ANOVAs were performed, one on accuracy and another on BOLD signal change. Both included contrast level as a factor. As expected for the stimulus type by contrast level ANOVA on behavioral accuracy, contrast level showed a significant main effect ( F (2,26)  = 6.51,  p  =.005), but did not show a significant interaction with stimulus type. In the stimulus type by contrast level by brain region by hemisphere ANOVA on BOLD signal change, contrast level did not show a main effect and also did not interact with any of the other factors. It is possible that the contrast levels were not disparate enough to produce significant BOLD signal change effects. However, because changing contrast level produced significant behavioral effects and consistent with previous work, it may be more likely that changes in contrast level have little influence on BOLD signal change in the regions investigated ( Avidan, et al., 2002 ;  Grill-Spector & Malach, 2004 ). Regardless, the subsequent analyses focused on examining effects of the stimulus type factor and were conducted on data collapsed across contrast level. 
 For the data acquired during scanning, trials for which subjects gave no response were very few, but were excluded from the analyses of behavioral data.  Figure 2  shows accuracy for all stimulus types. A one-way ANOVAs showed a significant effect of stimulus type ( F (6,78)  = 9.69,  p  <.001). Post-hoc, paired t-tests revealed that accuracy for the nose stimulus was significantly worse than all other stimulus types (all  t (13)  > 4.21,  p  <.001). In fact, accuracy with the nose stimulus was not significantly greater than chance. Excluding the nose, though, there were no other significant differences among the single feature stimulus types. There were also no significant differences among the combination stimulus types. Accuracy with the eyes-nose-mouth stimulus was better than with any of the single feature stimuli and also the combination two-eyes stimulus (all  t (13)  > 2.56,  p  <.025). 
 Functional imaging runs that showed estimated motion “spikes” of greater than 1 mm or motion “drifts” of greater than 2 mm were excluded. If more than 2 of 7 runs were excluded, then that subject was dropped from the analysis entirely. For Experiment 1, two subjects were removed, leaving 12 subjects for the remaining analyses. 
 A priori ROIs were localized using the data from the independent functional localizer run. The ROIs were determined from a group-average whole-brain fixed-effects GLM thresholded using the false discovery rate method (q =.05). The locations of the OFA and FFA were determined by contrasting the face and object conditions and the location of the LO was determined by contrasting the object and noise conditions. The locations of the ROIs are shown in  Figure 3  and the Talairach coordinates are shown in  Table 1 . Beta weights representing BOLD signal change were extracted from the ROIs for each subject. A region by hemisphere by stimulus type (3 × 2 × 7) ANOVA with BOLD percent signal change as the dependent variable revealed a significant three-way interaction ( F (12,132)  = 2.87,  p  = 0.002). 
 Based on previous work suggesting that eye/eyebrow regions are used most, followed by mouth regions, followed by nose regions, the main hypothesis was that the OFA would show greater activation with two eyes than with single eyes, with single eyes than with single mouths, and with single mouths than with single noses. Although the specific hypothesis was not born out, the pattern of results was still consistent with the more general hypothesis that the OFA is more involved in feature-based processing. A hemisphere by stimulus type (2 × 7) ANOVA with BOLD percent signal change in the OFA as the dependent variable revealed significant main effects stimulus type and of hemisphere ( F (12,132)  = 2.87,  p  = 0.002), but no interaction between the two. As such, post hoc tests across stimulus types were performed on the average across hemispheres.  Figure 4  shows the results for all stimulus types from the left and right OFA as well as the average across hemispheres. In the OFA, activation was highest with the nose, mouth, right eye, and two eyes stimuli, which did not differ significantly from each other. Activation with the mouth, right eye, and two eyes stimulus types was significantly greater than activation with the eyes-mouth and eyes-nose-mouth stimulus types (both  t (11)  > 2.28,  p  <.05). Activation with the left eye stimulus type was significantly lower than with the other three single feature stimulus types (all  t (11)  > 2.95,  p  <.015). Activation with the eyes-mouth stimulus type was significantly greater than activation with the eyes-nose-mouth stimulus type (all  t (11)  > 2.95,  p  <.015). 
 Another hypothesis was that the FFA would show greater activation with combination stimuli than with single feature stimuli. However, there were no significant differences in activation among stimulus types in either the left or right FFA ( Figure 5 ). There were also no differences among stimulus types in either the left or right LO. 
 
 
 Discussion 
 To our knowledge, this is the first study investigating the response properties of face-selective cortex with single face features and combinations of those features. Recent views consider the OFA to be highly involved in processing faces parts ( Betts & Wilson, 2010 ;  Liu, Harris, & Kanwisher, 2009 ;  Nichols, et al., 2010 ;  Pitcher, et al., 2011 ). Behavioral work suggests that eye/eyebrow features are of primary importance, followed by mouth features ( Blais, et al., 2008 ; Caldara, et al.;  Gold, et al., 1999 ;  Gold, et al., in press ;  Haig, 1986 ;  James, et al., 2010 ;  Schyns, et al., 2002 ;  Sekuler, et al., 2004 ;  Yarbus, 1967 ). Based on this previous work, we hypothesized that the OFA would show a preference for single features over combinations and a preference for eye features over other types. The current results partially support this hypothesis, but also clarify and extend it. Activation in the OFA showed a preference for single features over combinations of more than two features and among feature combination stimuli, showed a preference for the two eyes combined. These results reinforce the view that the OFA plays a role in processing face parts and suggest a possible neural basis for the reliance on eye/eyebrow features in face recognition. 
 One interesting and unexpected aspect of the data was the large difference in BOLD activation in both the left and right OFA between the single left eye and right eye features. There is some precedent in the literature for asymmetric contribution of the left and right eye features to face recognition ( Schyns, et al., 2002 ). In that study, response classification methods were used to determine which face features were relied on the most for recognition. Across their various tasks, the eye on the left side of the image (right eye of the person in the image) contributed more to recognition than the eye on the right side of the image and this was especially true during gender categorization tasks. In the current experiment, the stimulus types were labeled based on the left and right side of the person in the image. Thus, it is intriguing to speculate that the lower reliance upon the left eye (right side of image) in some studies of face recognition may reflect weak activation to those left eye features in the OFA. 
 In the OFA, activation with the two-eyes stimulus was not different from activation with the single right eye stimulus and there was a monotonic decrease in activation as features were mouth and then nose features were combined with the two eyes. It is interesting to consider this pattern of activation in the framework of summation of signals from feature detectors. If the population of neurons in the OFA contains “feature detector” neurons with preferences for single right eye, nose, or mouth features, then presenting the single right eye, single nose, and single mouth stimuli should produce significant activation, which is what was observed. However, presenting the two-eyes, the eyes-mouth, or the eyes-nose-mouth combination stimulus would be expected to produce at least the same activation as the strongest single feature stimulus. This may be the case with the two-eyes stimulus, which shows the same activation as the right-eye stimulus, which is the greater of the left- and right-eye activations. Alternatively, one could argue that a combination stimulus should produce more activation than any of the single feature stimuli from which it was composed, because the BOLD signal should “sum” across the different feature detector neurons. It is clear, however, that simple summation does not explain any of the activation patterns with combination stimuli in the OFA. More research is needed to explain why the presence of multiple features in a stimulus produces inhibition of activation, rather than summation in the OFA. 
 Most theories of FFA function suggest that it is specialized for “holistic/configural” processing of faces ( Kanwisher & Yovel, 2006 ;  McKone, Kanwisher, & Duchaine, 2006 ;  Rhodes, Byatt, Michie, & Puce, 2004 ;  Rossion, 2008 ). However, the definition of “holistic/configural” processing itself is debated and especially the role of face parts in “holistic/configural” processing ( McKone & Yovel, 2009 ;  Rivest, Moscovitch, & Black, 2009 ;  Rossion, 2008 ). Some theories contend that discrete face parts are the foundational building blocks from which “holistic/configural” representations are integrated ( McKone & Yovel, 2009 ). Other theories contend that part/feature-based processing and “holistic/configural” processing are distinct and separate systems ( Rossion, 2008 ). We hypothesized that integration of face parts would produce a pattern of activation where combination stimuli produced more activation than the single feature stimuli from which it was composed. The results, however, showed no evidence for this pattern of activation in the left or right FFA. Despite the fact that the FFA is highly sensitive to whole faces, it showed no differentiation between different combinations of face features, even the eyes-nose-mouth combination, which appeared quite face-like. This result suggests that the FFA is not likely to represent a mid-point between the processing of single features and whole faces, but does not rule out the hypothesis that the FFA may integrate low-level features directly into a whole. 
 The current study used stimuli presented in noise and with low contrast that was individually chosen for each subject. This method allowed for an assessment of above-floor and below-ceiling levels of performance and also reduced variability between subjects. Most fMRI studies of face recognition use pristine stimuli; therefore, the use of degraded stimuli may limit the comparisons between the current study and other studies. A few studies have used low contrast stimuli to study object recognition, but not in combination with noise, which also limits comparability. Nevertheless, the result found here -- that changes in contrast level produced little effect in high-level visual brain regions -- is consistent with the previous literature (for review, see  Grill-Spector & Malach, 2004 ). 
 In sum, differences in activation with single face features and combinations of features dissociated the role of regions of the face- and object-selective cortical network. The FFA and LO showed no preference across stimuli with different numbers of face features. The OFA, on the other hand, showed a preference for single face features and for eye features especially. This finding is consistent with previous work suggesting that the OFA may be recruited during the earliest stages of face processing, before a “holistic/configural” face representation is formed ( Pitcher, et al., 2011 ). 
 
 
 
 The research was supported in part by the Faculty Research Support Program administered through the IU Office of the Vice President of Research, in part by the Indiana METACyt Initiative of Indiana University; in part through a major grant from the Lilly Endowment, Inc.; and in part by National Institute of Health grant EY019265 to J.M.G. We thank Karin Harman James for insights given on every aspect of the project and Thea Atwood and Rebecca Ward for assistance with data collection. 
 
 
 
 This is a PDF file of an unedited manuscript that has been accepted for publication. As a service to our customers we are providing this early version of the manuscript. The manuscript will undergo copyediting, typesetting, and review of the resulting proof before it is published in its final citable form. Please note that during the production process errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain. 
 
 
 
 
 
 
 
 Avidan 
 G 
 
 
 Harel 
 M 
 
 
 Hendler 
 T 
 
 
 Ben-Bashat 
 D 
 
 
 Zohary 
 E 
 
 
 Malach 
 R 
 
 
 2002 
 Contrast sensitivity in human visual areas and its relationship to object recognition 
 Journal of Neurophysiology 
 87 
 6 
 3102 
 3116 
 12037211 
 
 
 
 
 
 
 Betts 
 LR 
 
 
 Wilson 
 HR 
 
 
 2010 
 Heterogeneous structure in face-selective human occipito-temporal cortex 
 Journal of Cognitive Neuroscience 
 22 
 10 
 2276 
 2288 
 19803682 
 
 
 
 
 
 
 Blais 
 C 
 
 
 Jack 
 RE 
 
 
 Scheepers 
 C 
 
 
 Fiset 
 D 
 
 
 Caldara 
 R 
 
 
 2008 
 Culture shapes how we look at faces 
 PLoS ONE 
 3 
 8 
 e3022 
 18714387 
 
 
 
 
 
 
 Brainard 
 DH 
 
 
 1997 
 The Psychophysics Toolbox 
 Spat Vis 
 10 
 4 
 433 
 436 
 9176952 
 
 
 
 
 
 
 Caldara 
 R 
 
 
 Zhou 
 X 
 
 
 Miellet 
 S 
 
 
 2010 
 Putting culture under the ‘spotlight’ reveals universal information use for face recognition 
 PLoS ONE 
 5 
 3 
 e9708 
 20305776 
 
 
 
 
 
 
 Farah 
 MJ 
 
 
 Wilson 
 KD 
 
 
 Drain 
 M 
 
 
 Tanaka 
 JW 
 
 
 1998 
 What is “special” about face perception? 
 Psychological Review 
 105 
 3 
 482 
 498 
 9697428 
 
 
 
 
 
 
 Gold 
 J 
 
 
 Bennett 
 PJ 
 
 
 Sekuler 
 AB 
 
 
 1999 
 Identification of band-pass filtered letters and faces by human and ideal observers 
 Vision Research 
 39 
 21 
 3537 
 3560 
 10746125 
 
 
 
 
 
 
 Gold 
 JM 
 
 
 Mundy 
 PJ 
 
 
 Tjan 
 BS 
 
 
 in press 
 The perception of a face is no more than the sum of its parts 
 Psychological Science 
 
 
 
 
 
 
 Grill-Spector 
 K 
 
 
 Malach 
 R 
 
 
 2004 
 The human visual cortex 
 Annual Review of Neuroscience 
 27 
 649 
 677 
 
 
 
 
 
 
 Haig 
 ND 
 
 
 1986 
 Exploring recognition with interchanged facial features 
 Perception 
 15 
 235 
 247 
 3797198 
 
 
 
 
 
 
 James 
 TW 
 
 
 Huh 
 E 
 
 
 Kim 
 S 
 
 
 2010 
 Temporal and spatial integration of face, object, and scene features in occipito-temporal cortex 
 Brain and Cognition 
 74 
 2 
 112 
 122 
 20727652 
 
 
 
 
 
 
 Kanwisher 
 N 
 
 
 Yovel 
 G 
 
 
 2006 
 The fusiform face area: a cortical region specialized for the perception of faces 
 Philosophical transactions of the royal society B 
 361 
 2109 
 2128 
 
 
 
 
 
 
 Lerner 
 Y 
 
 
 Epshtein 
 B 
 
 
 Ullman 
 S 
 
 
 Malach 
 R 
 
 
 2008 
 Class information predicts activation by object fragments in human object areas 
 Journal of Cognitive Neuroscience 
 20 
 7 
 1189 
 1206 
 18284342 
 
 
 
 
 
 
 Liu 
 J 
 
 
 Harris 
 A 
 
 
 Kanwisher 
 N 
 
 
 2009 
 Perception of face parts and face configurations: an FMRI study 
 Journal of Cognitive Neuroscience 
 22 
 1 
 203 
 211 
 19302006 
 
 
 
 
 
 
 Maurer 
 D 
 
 
 Le Grand 
 R 
 
 
 Mondloch 
 CJ 
 
 
 2002 
 The many faces of configural processing 
 Trends in Cognitive Sciences 
 5 
 6 
 255 
 260 
 12039607 
 
 
 
 
 
 
 McKone 
 E 
 
 
 Kanwisher 
 N 
 
 
 Duchaine 
 BC 
 
 
 2006 
 Can generic expertise explain special processing for faces? 
 Trends in Cognitive Sciences 
 11 
 1 
 8 
 15 
 17129746 
 
 
 
 
 
 
 McKone 
 E 
 
 
 Yovel 
 G 
 
 
 2009 
 Why does picture-plane inversion sometimes dissociate perception of features and spacing in faces, and sometimes not? Toward a new theory of holistic processing 
 Psychon Bull Rev 
 16 
 5 
 778 
 797 
 19815781 
 
 
 
 
 
 
 Nestor 
 A 
 
 
 Vettel 
 JM 
 
 
 Tarr 
 MJ 
 
 
 2008 
 Task-specific codes for face recognition: how they shape the neural representation of features for detection and individuation 
 PLoS ONE 
 3 
 12 
 e3978 
 19112516 
 
 
 
 
 
 
 Nichols 
 DF 
 
 
 Betts 
 LR 
 
 
 Wilson 
 HR 
 
 
 2010 
 Decoding of faces and face components in face-sensitive human visual cortex 
 Front Psychol 
 1 
 28 
 21833198 
 
 
 
 
 
 
 Pelli 
 DG 
 
 
 1997 
 The VideoToolbox software for visual psychophysics: transforming numbers into movies 
 Spat Vis 
 10 
 4 
 437 
 442 
 9176953 
 
 
 
 
 
 
 Pitcher 
 D 
 
 
 Charles 
 L 
 
 
 Devlin 
 JT 
 
 
 Walsh 
 V 
 
 
 Duchaine 
 B 
 
 
 2009 
 Triple dissociation of faces, bodies, and objects in extrastriate cortex 
 Current Biology 
 19 
 4 
 319 
 324 
 19200723 
 
 
 
 
 
 
 Pitcher 
 D 
 
 
 Duchaine 
 B 
 
 
 Walsh 
 V 
 
 
 Yovel 
 G 
 
 
 Kanwisher 
 N 
 
 
 The role of lateral occipital face and object areas in the face inversion effect 
 Neuropsychologia 
 
 
 
 
 
 
 Pitcher 
 D 
 
 
 Walsh 
 V 
 
 
 Duchaine 
 B 
 
 
 2011 
 The role of the occipital face area in the cortical face perception network 
 Experimental Brain Research 
 209 
 4 
 481 
 493 
 
 
 
 
 
 
 Pitcher 
 D 
 
 
 Walsh 
 V 
 
 
 Yovel 
 G 
 
 
 Duchaine 
 B 
 
 
 2007 
 TMS evidence for the involvement of the right occipital face area in early face processing 
 Current Biology 
 17 
 18 
 1568 
 1573 
 17764942 
 
 
 
 
 
 
 Rhodes 
 G 
 
 
 Byatt 
 G 
 
 
 Michie 
 PT 
 
 
 Puce 
 A 
 
 
 2004 
 Is the fusiform face area specialized for faces, individuation, or expert individuation? 
 Journal of Cognitive Neuroscience 
 16 
 2 
 189 
 203 
 15068591 
 
 
 
 
 
 
 Rivest 
 J 
 
 
 Moscovitch 
 M 
 
 
 Black 
 S 
 
 
 2009 
 A comparative case study of face recognition: the contribution of configural and part-based recognition systems, and their interaction 
 Neuropsychologia 
 47 
 13 
 2798 
 2811 
 19524599 
 
 
 
 
 
 
 Rossion 
 B 
 
 
 2008 
 Picture-plane inversion leads to qualitative changes of face perception 
 Acta Psychologica 
 128 
 2 
 274 
 289 
 18396260 
 
 
 
 
 
 
 Schyns 
 PG 
 
 
 Bonnar 
 L 
 
 
 Gosselin 
 F 
 
 
 2002 
 Show me the features! Understanding recognition from the use of visual information 
 Psychological Science 
 13 
 5 
 402 
 409 
 12219805 
 
 
 
 
 
 
 Sekuler 
 AB 
 
 
 Gaspar 
 CM 
 
 
 Gold 
 JM 
 
 
 Bennett 
 PJ 
 
 
 2004 
 Inversion leads to quantitative, not qualitative, changes in face processing 
 Current Biology 
 14 
 5 
 391 
 396 
 15028214 
 
 
 
 
 
 
 Tong 
 F 
 
 
 Nakayama 
 K 
 
 
 Moscovitch 
 M 
 
 
 Weinrib 
 O 
 
 
 Kanwisher 
 N 
 
 
 2000 
 Response properties of the human fusiform face area 
 Cognitive Neuropsychology 
 17 
 1–3 
 257 
 280 
 20945183 
 
 
 
 
 
 
 Yarbus 
 AL 
 
 
 1967 
 Eye movements and vision 
 New York 
 Plenum Press 
 
 
 
 
 
 
 Figure 1 
 
 Single feature and combination stimuli. The top row shows the twelve different faces from which the stimuli were drawn. In the bottom two rows, from left to right, the stimuli are single features of nose, mouth, left eye, and right eye; and combinations of two-eyes, eyes-mouth, and eyes-nose-mouth. Stimuli in the second from bottom row are shown at a contrast level equal to the mean threshold contrast across subjects for the eyes-nose-mouth stimulus, which was the highest contrast level used in the scanner. Stimuli in the bottom row are shown at 10 times that contrast level too make the stimuli easier for the reader to view. 
 
 
 
 
 Figure 2 
 
 Accuracy as a function of stimulus type. 2E-M = eyes-mouth, 2E-N-M = eyes-nose-mouth. Error bars are 95% confidence intervals. 
 
 
 
 
 Figure 3 
 
 Locations of object- and face-selective regions of interest. The object – noise contrast is shown with a threshold of  t =16. The face – object contrasts is shown with the FDR threshold (q=.05; voxel-wise t=3.51). Z-values are from the Talairach reference. FFA = fusiform face area, LO = lateral occipital area, OFA = occipital face area. 
 
 
 
 
 Figure 4 
 
 BOLD signal change as a function of stimulus type for the left and right OFA and for the average across hemispheres. Significant differences (p<.05) between selected stimulus types are shown with an *. 2E-M = eyes-mouth, 2E-N-M = eyes-nose-mouth. Error bars are 95% confidence intervals. 
 
 
 
 
 Figure 5 
 
 BOLD signal change as a function of stimulus type and hemisphere for the FFA and LO. 2E-M = eyes-mouth, 2E-N-M = eyes-nose-mouth. Error bars are 95% confidence intervals. 
 
 
 
 
 Table 1 
 
 Talairach coordinates for regions of interest. 
 
 
 
 
 Region 
 X 
 Y 
 Z 
 
 
 
 
 l-FFA 
 −40 
 −46 
 −17 
 
 
 r-FFA 
 +38 
 −44 
 −15 
 
 
 l-LO 
 −38 
 −75 
 −3 
 
 
 r-LO 
 +35 
 −74 
 −4 
 
 
 l-OFA 
 −36 
 −76 
 −12 
 
 
 r-OFA 
 +26 
 −82 
 −12 
 
 
 
 
 
 
 Highlights 
 
 
 
 BOLD activation in the OFA was greater with single feature stimuli than with feature combination stimuli 
 
 
 BOLD activation in the OFA was lowest for the 3- and 4-feature stimulus types 
 
 
 BOLD activation in the FFA and LO did not differ across stimulus types 
 
 
 
 
