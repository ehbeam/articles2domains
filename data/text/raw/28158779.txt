properties open_access? Soc Cogn Affect Neurosci Soc Cogn Affect Neurosci scan Social Cognitive and Affective Neuroscience 1749-5016 1749-5024 Oxford University Press 28158779 5460045 10.1093/scan/nsx011 nsx011 Original Articles Maintaining the feelings of others in working memory is associated with activation of the left anterior insula and left frontal-parietal control network Smith Ryan <email>rsmith@psychiatry.arizona.edu</email> Lane Richard D. Alkozei Anna Bao Jennifer Smith Courtney Sanova Anna Nettles Matthew Killgore William D. S. Department of Psychiatry, University of Arizona, Tucson, AZ 85724-5002, USA Correspondence should be addressed to Ryan Smith, Department of Psychiatry, University of Arizona, 1501 N., Campbell Ave., PO Box 245002, Room 7304B, Tucson, AZ 85724-5002, USA. E-mail:  rsmith@psychiatry.arizona.edu 5 2017 01 2 2017 01 2 2017  PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>.  12 5 848 860 27 9 2016 5 1 2017 23 1 2017 © The Author (2017). Published by Oxford University Press. 2017 This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License ( http://creativecommons.org/licenses/by-nc/4.0/ ), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com Abstract The maintenance of social/emotional information in working memory (SWM/EWM) has recently been the topic of multiple neuroimaging studies. However, some studies find that SWM/EWM involves a medial frontal-parietal network while others instead find lateral frontal-parietal activations similar to studies of verbal and visuospatial WM. In this study, we asked 26 healthy volunteers to complete an EWM task designed to examine whether different cognitive strategies— maintaining emotional images, words, or feelings— might account for these discrepant results. We also examined whether differences in EWM performance were related to general intelligence (IQ), emotional intelligence (EI), and emotional awareness (EA). We found that maintaining emotional feelings, even when accounting for neural activation attributable to maintaining emotional images/words, still activated a left lateral frontal-parietal network (including the anterior insula and posterior dorsomedial frontal cortex). We also found that individual differences in the ability to maintain feelings were positively associated with IQ and EA, but not with EI. These results suggest that maintaining the feelings of others (at least when perceived exteroceptively) involves similar frontal-parietal control networks to exteroceptive WM, and that it is similarly linked to IQ, but that it also may be an important component of EA. working memory emotion emotional working memory social cognition prefrontal cortex insula Introduction Working memory (WM) can be defined as the temporary maintenance/manipulation of information for use in guiding goal-directed decision-making and action selection ( Levy and Goldman-Rakic, 2000 ;  Baddeley, 2007 ;  Sreenivasan  et al. , 2014 ). Higher WM capacity predicts measures of academic success and fluid intelligence and appears important for successful problem-solving ( Conway  et al. , 2003 ). Neuroscientific studies have also clarified that WM involves interactions between (1) lateral frontal-parietal (lFP) control networks (including regions of lateral prefrontal cortex, lateral parietal cortex, posterior dorsomedial prefrontal cortex, and anterior insula) and (2) cortical regions that represent the information being maintained ( Petrides, 2000 ;  Glahn  et al. , 2002 ;  Veltman  et al. , 2003 ;  Ranganath and D’Esposito, 2005 ;  D’Esposito, 2007 ;  Rottschy  et al. , 2012 ;  Nee  et al. , 2013 ;  Sreenivasan  et al. , 2014 ;). There further appears to be considerable overlap between WM and selective attention functions in the brain; specifically, both functions appear to involve top-down modulation processes that amplify task-relevant representations and suppress task-irrelevant representations ( Kane and Engle, 2002 ;  McCabe  et al. , 2010 ;  Gazzaley and Nobre, 2012 ). Individual differences in the effectiveness of these top-down modulation processes are also thought to explain the correlation between WM capacity and intelligence mentioned above ( Engle, 2002 ;  Kane and Engle, 2003 ;  McVay and Kane, 2012 ). Current models of the neural basis of WM are domain-general in that they suggest the same lFP network structures will be engaged irrespective of the sensory modality of the information being maintained/manipulated ( Duncan and Owen, 2000 ;  Koechlin  et al. , 2003 ;  Barbey  et al. , 2013 ). To date, however, the studies supporting these models have largely focused on WM for exteroceptive sensory information (e.g. visual, auditory, etc.); very few studies have examined WM for interoceptive/emotional information ( Waugh  et al. , 2014 ;  Xin and Lei, 2015 ). The ability to maintain the emotional responses of self and others in mind [“emotional working memory” (EWM)] could be of potential importance for many aspects of emotion regulation and social problem solving. Previous behavioral work—using an EWM paradigm requiring maintenance of the intensity of one’s own emotional responses—has provided evidence of differential interference effects between visual WM and EWM ( Mikels  et al. , 2008 ), suggesting that EWM may be at least partially dissociable from other WM systems. A recent neuroimaging study ( Waugh  et al. , 2014 ) using this same paradigm also found that EWM was significantly associated with anterior medial prefrontal activation, in addition to the lFP activation typically found in exteroceptive WM studies. This builds on previous findings showing that medial prefrontal activation is linked to attentional focus on one’s own emotions ( Lane  et al. , 1997 ;  Gusnard  et al. , 2001 ;  Ochsner  et al. , 2004 ;  Smith  et al. , 2014 ). Relatedly, another body of work on “social working memory” (SWM) has also contrasted exteroceptive WM with the ability to maintain/manipulate information about the mental states/traits of others, which includes—but is not limited to—information about emotions ( Meyer and Lieberman, 2012 ;  Meyer  et al. , 2012 ;  Meyer  et al. , 2015 ;  Xin and Lei, 2015 ). Specifically, using an SWM task involving the maintenance/manipulation of the psychological traits of others, two studies have now shown that a similar network of medial prefrontal/parietal (i.e. posterior cingulate/precuneus) regions increases in activation with increasing SWM load, and that lFP regions are also co-activated under these conditions ( Meyer  et al. , 2012 ,  2015 ). In contrast to the medial frontal-parietal (mFP) network activation observed in the above studies, a different SWM paradigm— using an n-back task involving emotions seen in facial images—recently found a contradictory pattern of neural responses ( Xin and Lei, 2015 ). Specifically, this study observed that greater lFP activation, coupled with greater mFP  inhibition , was instead associated with maintaining the emotions of others in mind. The authors of this study proposed that the unexpected response pattern they observed may suggest that SWM should be separated into “internally focused” and “externally focused” subtypes (as also proposed in  Lieberman, 2007 ). Thus, while maintaining “internal” information (like the mental traits of others) may require activation of the mFP network, they suggest that maintaining the emotions of others seen in faces (as in their n-back paradigm) may be a more “external” aspect of SWM and therefore activate the lFP network instead. However, at present it remains unclear if this explanation is correct, or whether some other difference between these EWM/SWM tasks can account for the differential participation of mFP and lFP networks. One important issue that has received little attention, and that is of central importance to understanding EWM in particular, is that there are multiple cognitive strategies one might use to hold the emotions of others in mind. When maintaining emotions seen in faces (as in  Xin and Lei, 2015 ), for example, it seems there are at least three such strategies: (1) one could hold the visual image of the emotional face in mind, (2) one could label the face with an emotion word (e.g. “sad”) and then hold that word in mind or (3) one could imagine the emotional feeling itself and hold that feeling in mind. 1  Importantly, the first two strategies would be expected to activate the lFP networks associated with exteroceptive WM; only the third strategy would be expected to involve maintaining truly “internal” information requiring mFP network activation (i.e. according to the suggestion of  Xin & Lei, 2015 ). In the present study, we therefore sought to help further clarify the neural basis of EWM/SWM by using a socio-emotional working memory paradigm that directly contrasts these three strategies one might use for holding the emotions of others in mind. We hypothesized that, when compared to maintaining emotion words or maintaining emotional facial images, maintaining emotional feelings in WM (WM-f) would be uniquely associated with mFP network activation. This was based on the idea that only the WM-f strategy would involve maintaining representations of “internal“ (i.e. interoceptive/introspective) content. To validate our measure of WM-f, we also tested the a priori hypothesis that individual differences in WM-f ability would be associated with higher scores on a previously validated performance measure of emotional awareness (EA) ( Lane  et al. , 1990 ). This was based on our reasoning that, because EA is measured by scoring verbal reports of the anticipated feelings of self and others in hypothetical emotion-provoking contexts, generating such verbal reports plausibly requires that an individual is able to imagine the feelings of others and maintain/manipulate representations of these feelings in WM. As a secondary aim of the study, we also explored the relationship between WM-f and measures of general intelligence (IQ) and emotional intelligence (EI). This was because, despite the fact that exteroceptive WM has been strongly linked with IQ ( Conway  et al. , 2003 ), it remains unexplored whether WM-f shares this relationship with IQ, or whether it is more closely related to current measures of EI instead. Based on the conceptual distinction between EI and IQ ( Mayer  et al. , 2001 ), and the results of previous studies ( Webb  et al. , 2013 ), we only expected small-to-moderate correlations between EI and IQ; however, given that WM-f represents a specific application of cognitive control processes to emotional feelings, and that such control processes have typically been linked to IQ ( Conway  et al. , 2003 ), it was unclear which of these two constructs would be more strongly associated with WM-f. 2  Therefore, we also carried out exploratory analyses to provide some preliminary answers to this question. Materials and methods Participants Twenty-six healthy adults (13 female; mean age  =  23.12  ±  4.03) were recruited from the general population via flyers and internet advertisements to participate in the present study. Participants did not have any history of psychiatric or neurological disorders (assessed via a phone screen questionnaire based on criteria within the Diagnostic and Statistical Manual for Mental Disorders, 4th edition; DSM-IV-TR) and all provided written informed consent prior to participation. The research protocol of the present study was also reviewed and approved by the Institutional Review Board of the University of Arizona. Socio-emotional working memory task Upon completing the informed consent, participants were presented with written instructions (on a laptop computer) for how to perform the WM task (See  Figure 1 ). These instructions stated that “on each trial you will sequentially be shown either one, two, or three faces” and “you will also hear a word spoken at the time of the presentation of each face. “The instructions then informed the participants that the faces would display different emotional expressions and that the words they heard would also refer to emotions, but that a given emotion word they heard would not match the emotion expressed by the face shown at the same time. Next, participants read that “after the presentation of these faces and words, there will be a pause (where only a black screen is shown), during which time you will be asked to hold something in memory” and that after the pause a new face would appear on the screen, followed by the words “same” and “different.” They were told that they would be asked to press one of two buttons corresponding to the “same” and “different” options in order to test their memory. However, what these options meant depended on the instruction provided before each trial. Fig. 1. Illustration of the four task conditions. After the appearance of each instruction, 1, 2, or 3 emotional faces (and incongruent emotion words) were presented followed by a maintenance period. A 3-item trial is illustrated here. All contrasts reported in this manuscript compare the 6-s maintenance periods between different task conditions. The decision period that followed included making a simple same/different judgment from memory (where the correct answer was different depending on the instruction associated with that condition; described further in the text). The circles shown around same or different options were not included in the task; they are simply added to the figure to indicate what the correct answer would be for a given instruction type. Before each trial, an instruction appeared (in pseudo-random order) stating either “Facial Feeling,” “Facial Identity,” “Word,” or “Pleasantness.” The “Facial Feeling” instruction meant that they should “pay attention to the face(s) you see, and imagine the feeling that you believe the person(s) are feeling” and that “you should ignore the words you hear.” During the pause, they were asked to hold the feeling(s) in mind and then compare those feelings to the image of the person shown after the pause. If one of the emotions they were holding in mind matched the emotion of the person shown after the pause, they were told to push “same” (otherwise they should push “different”). “Facial Identity” meant they should instead hold the visual images of the people they saw in mind during the pause (while still ignoring the words), and that they should push “same” if the person shown after the pause matched the identity of one of the faces shown before the pause (otherwise they should push “different”). “Word” meant that they should ignore the faces entirely (but keep their eyes open) and only remember the emotion words they heard. If the emotion on the face shown after the pause matched one of the words held in mind, they should push “same” (otherwise they should push “different”). Finally, the “Pleasantness” instruction meant that they didn’t need to attend to or remember anything during the pause, and that they would simply need to indicate by button press whether the face shown after the pause was displaying a “Pleasant” or “Unpleasant” emotion. Subjects also did not need to remember the word “pleasantness” during the delay period, as they would be prompted at the end of the trial with the two words (pleasant or unpleasant) that they needed to choose between to complete the trial. This condition acted as a control condition in which nothing was held in WM during the maintenance period, but where all stimulus conditions were identical. Each time one of these instructions was presented, it also indicated whether they would need to remember 1, 2 or 3 items of information on that trial (i.e. whether 1, 2 or 3 faces/words would be sequentially presented). Finally, they were reminded to use particular strategies during the pause period for each trial type. For the “Pleasantness” condition, they were asked to “not hold anything in mind during the pause.” For the “Facial Identity” condition, they were asked to “hold the visual image of the faces in mind.” For the “Word” condition, they were asked to “hold the words you heard in mind.” For the “Facial Feeling” condition, they were asked to “hold the emotional feelings in mind.” After reading these instructions, participants were offered an opportunity to ask questions to clarify their meaning, and then they were allowed to practice the task for several trials on the laptop. This practice period gave two exposures to each instruction type at each of the three difficulty levels (i.e. involving WM for 1, 2 or 3 items). In the practice version, they also received feedback (correct/incorrect) after each trial to aid in learning the task. After this practice period, participants could again ask any clarifying questions if something was still not fully understood. Participants were then taken to the magnetic resonance imaging (MRI) scanner at the University of Arizona where they underwent functional MRI scanning (see Neuroimaging Methods) while completing the EWM task. Before scanning began, they were also given a small number of practice trials to become accustomed to performing the task inside the scanner environment. However, no feedback regarding accuracy was provided during these in-scanner practice trials, nor during the trials in the actual task. For this task, the facial images used were taken from the Ekman 60 faces test ( Ekman and Friesen, 1976 ), which contains photographs of 10 different actors (six photographs of each), all displaying each of the basic emotions one time (happiness, anger, disgust, fear, surprise, and sadness). The words participants heard corresponded to each of these six basic emotions as well (“happy,” “angry,” “disgusted,” “afraid,” “surprised,” “sad”), read by the same voice in the same neutral tone. However, a word never matched the emotion shown in the face with which it was simultaneously presented. Counterbalancing within the task was done with respect to all stimulus and condition variables to the greatest extent possible. This included ensuring that the facial identities, emotional expressions, and words presented were used roughly the same number of times for each trial type, and that each emotional expression was paired with each incongruent emotion word the same number of times. It also included ensuring that “same” (or “pleasant”) and “different” (or “unpleasant”) were each the correct responses an equivalent number of times both within and across each trial type. For the Facial Feeling condition, trials were also constructed so that the emotion displayed after the pause (i.e. for the same/different judgment) was always shown on a different face than those used to display that emotion during the encoding phase (i.e. before the pause). This was done to help ensure that participants were truly holding feelings in mind, and not simply matching the same facial images before and after the pause when choosing their responses. Each participant performed two runs of the task, each lasting 14 min and 22 s. The trial order was pseudo-randomized between runs, in order to prevent participants from being able to learn what stimuli to expect on upcoming trials during the second run. Across the two runs, this allowed for 24 trials each (eight at each of the three difficulty levels) within the Facial Feeling, Facial Identity, and Word conditions, as well as 12 trials (four at each difficulty level) within the Pleasantness condition. On each trial, the timing was as follows: Trial Instruction  =  3 s, Image/Word  =  2 s (each), Maintenance Period = 6 s, Comparison Image  =  2 s, Decision Period (displaying the “same”/“pleasant” and “different”/“unpleasant” options) = 3 s. After the decision period, there was also a variable-length inter-trial interval (displaying a crosshair), which was jittered so as to last either 0.5 s, 2 s, or 3.5 s. After completing scanning, participants were then escorted back to the lab, seated at a laptop, and asked to complete some additional measures. Secondary measures 
 Emotional Awareness.  Participants also completed an on-line version of the levels of emotional awareness scale (LEAS) ( www.eleastest.net ) that makes use of a validated automatic scoring program ( Barchard  et al. , 2010 ). The LEAS presents 2–4 sentence descriptions of 20 social situations, each involving two people. The situation descriptions are designed to elicit four types of emotion (sadness, happiness, anger and fear) at five levels of complexity. One situation is presented on each electronically presented page, followed by two questions: “How would you feel?” and “How would the other person feel?” There are separate response boxes for typing in the answers to each question. Participants are instructed to type their responses into these boxes and asked to use as much or as little space as needed to answer. The only rule they are given is that they must use the word “feel” in their responses. Scores for the LEAS are assigned based on the EA level associated with the words participants provide in their responses. The lowest scores are given to non-feeling words (Level 0, e.g. confused). Level 1 scores are given to feeling words related to physiological sensations (e.g. “tired”), whereas level 2 scores reflect feeling-related actions (e.g. “punching”) or simple valence discriminations (e.g. “bad,” “good”) that have inherent avoidance- or approach-related content. Level 3 scores are assigned to single emotion terms (e.g. “happy,” “sad”). Level 4 scores are awarded when at least 2 terms from level 3 are used (i.e. that convey greater emotional differentiation than either word alone). For each item, the self- and other-related responses are scored separately in the manner just described (i.e. with a value of 0-4). A “total” score is also given for each of the 20 LEAS items; this score reflects the higher of the self- and other-related scores, unless a score of 4 is given for both. In that case, a total score of 5 is given for the item, so long as the self- and other-related responses are differentiable (for more detail, see  Lane  et al. , 1990 ). 
 Emotional 
 i 
 ntelligence . In order to explore the potential relationship between EI and EWM, participants completed previously validated, commercially available tests of EI. One test—the Mayer–Salovey–Caruso Emotional Intelligence Test (MSCEIT)—is based on the “Ability model,” which defines EI in terms of the cognitive capacities that allow one to reason about and solve emotion-related problems, and assesses EI based on participants’ performance on a range of different tasks/assessments ( Mayer  et al. , 2002 ). It uses computer-administered items that are designed to measure abilities such as identifying emotions, understanding the causes of emotions, and utilizing emotions to guide behavior and accomplish goals. The MSCEIT provides a total emotional intelligence score (as well as four subscale scores). For this study, raw scores were converted to scaled scores on the basis of the general normative group, adjusted for age, gender and ethnicity. The other major test of EI we used—the Trait Emotional Intelligence questionnaire (TEIQue)—is based on the “Trait model,” which uses self-report inventories (as opposed to problem solving tests), and views EI as a set of personal competencies of which individuals are self aware ( Mikolajczak  et al. , 2007 ;  Petrides  et al. , 2007 ). It contains 153 items and provides a total EI score (as well as several subscale scores). Items consist of statements such as “Understanding the needs and desires of others is not a problem for me,” which must be answered on a 7-point Likert scale ranging from ‘Disagree Completely’ to ‘Agree Completely.’ 
 General 
 i 
 ntelligence . Intelligence quotient (IQ) was assessed with the two-subtest form (FSIQ-2) of the Wechsler Abbreviated Scale of Intelligence – Second Edition (WASI-II; Pearson Assessment, Inc., San Antonio, TX) ( Wechsler, 2011 ). This was done in order to assess the relationship between WM-f ability and general intelligence. 
 Emotional 
 f 
 acial 
 r 
 ecognition.  To examine whether WM-f performance differences were due to differences in WM-f capacity or due to differences in emotion recognition ability, 16 of the 26 participants (7 male; mean age = 22.6 ± 4.0 years) were asked to complete the Ekman 60 faces test ( Ekman and Friesen, 1976 ) 3 . This is a computerized emotion recognition task during which participants are presented with photographs of 10 different actors (six photographs of each), all displaying each of the basic emotions one time (happiness, anger, disgust, fear, surprise and sadness). Participants are asked to choose which emotion best describes the facial expression shown (from a presented list). Photographs are presented in a pseudo-random order, and a total score (0–60) of correct responses for each participant was calculated. Neuroimaging methods Neuroimaging was performed using a 3T Siemens Skyra scanner (Siemens, Erlangen, Germany) using a 32-channel head coil. T1-weighted structural 3D MPRAGE images were acquired (TR/TE/flip angle  =  2.1 s/2.33 ms/12 degree) covering 176 sagittal slices (256 × 256) with a slice thickness of 1 mm (voxel size  =  1 × 1 × 1). Functional T2*-weighted scans were acquired over 32 transverse slices (2.5 mm thickness). Volumes were collected with an interleaved sequence (TR/TE/flip angle  =  2.0 s/25 ms/90 degree). The voxel size of the T2* sequence was 2.5 × 2.5 × 3.5 mm. The field of view (FOV) was 240 mm. Image processing The SPM12 software package (Wellcome Department of Cognitive Neurology, London, UK;  http://www.fil.ion.ucl.ac.uk/spm ) was used to perform all preprocessing steps, and subsequent statistical analyses, on the acquired MRI scans. Preprocessing steps on raw functional images included realignment, unwarping and coregistration to each subject’s MPRAGE image in accordance with standard algorithms. The resulting images were then normalized to Montreal Neurological Institute (MNI) coordinate space, spatially smoothed (6 mm full-width at half maximum), and resliced to 2 × 2 × 2 mm voxels. The standard canonical hemodynamic response function in SPM was used, a 128-second high-pass filter was applied to minimize low-frequency confounds, and serial autocorrelation was corrected using the AR(1) function. The Artifact Detection Tool (ART;  http://www.nitrc.org/projects/artifact_detect / ) was also used to regress out scans as nuisance covariates in the first-level analysis that exceeded 3 SD in mean global intensity and scan-to-scan motion that exceeded 1.0 mm. Statistical analysis For each participant, a general linear model was specified to contrast activation during the maintenance period between the facial feeling, facial identity, word, and pleasantness conditions. WM load within each condition (i.e. 1-, 2- or 3-item trials) was also modeled using first-order parametric modulation. Each trial was modeled as a 6-s interval. Motion regressors (generated by ART – see image processing above) were also added to each of these first-level designs. These contrast images were then entered into second-level SPM analyses (one-sample  T -tests) to assess the main effect of two contrasts of interest. The first contrast was Facial Feeling > Pleasantness, which should highlight all regions activated by maintaining feelings (i.e. relative to a period involving no WM maintenance). The second contrast was Facial Feeling > Facial Identity and Word, which should highlight all regions activated by maintaining feelings that are not also activated by maintaining facial images or maintaining emotion words. Combining the Facial Identity and Word trials was done for this contrast to rule out interpretations involving alternative WM strategies (e.g. activations found in a contrast of Facial Feeling > Word could be attributable to a visual WM strategy, etc.). We also performed some additional second-level neuroimaging analyses to aid in characterizing our results. First, we performed parametric modulation analyses to highlight brain regions that increased in activation with greater WM load in the Facial Feeling condition. These parametric modulation analyses were done for the same two condition contrasts described above (i.e. Facial Feeling > Pleasantness and Facial Feeling > Facial Identity and Word). Second, we also contrasted accurate > inaccurate trials within the Facial Feeling condition, in order to assess which brain regions were more activated during successful WM-f performance. Finally, as detailed within our  supplementary materials , we also performed two additional second-level analyses. To characterize the neural correlates of the visual WM condition of the task, we examined the contrast of Facial Identity > Pleasantness. To characterize the neural correlates of the verbal WM condition of the task, we examined the contrast of Word > Pleasantness. For each of these analyses we used a whole-brain peak significance threshold of  P   <  0.001 (uncorrected), along with a cluster extent threshold of  P   <  0.05 [false discovery rate (FDR) corrected]. For more extensive data analysis, the first eigenvariate across subjects was also extracted from specific clusters found in these analyses (see results section) and correlated with specific secondary measures (described further below). Cluster identification/labeling was done in conjunction with the automated anatomical labeling (AAL) atlas within SPM12 ( Tzourio-Mazoyer  et al. , 2002 ). Results Cognitive/behavioral measures The means (and SDs) for all behavioral measures are presented in  Table 1 . Paired  T -tests indicated that accuracy within the Facial Feeling (FF) condition was significantly lower than within the Facial Identity (FI) condition ( t   =  −12.4,  P   <  0.05) and the Word (WO) condition ( t   =  −6.6,  P   <  0.05). However, a one-sample  T -test also confirmed that accuracy in the FF condition was still significantly greater than chance (i.e. 50%) levels ( t   =  5.8,  P   <  0.05).
 Table 1. Cognitive/behavioral measures: Descriptive statistics Measure Mean Standard deviation Facial Feeling Condition Accuracy 66.0 14.0 Facial Identity Condition Accuracy 93.0 7.3 Word Condition Accuracy 86.0 8.4 Pleasantness Condition Accuracy 97.0 5.2 Ekman 60 Total Scores 51.56 4.26 WASI IQ scores 115.23 11.7 LEAS TOTAL 74.0 9.8 LEAS OTHER 58.5 10.7 LEAS SELF 63.0 8.7 MSCEIT Total Score 106.49 18.22 TEIQue Total Scores 5.15 0.65 Correlations between all variables are reported in  Table 2 . This table indicates that FF accuracy had a significant positive association with FI accuracy, IQ, and LEAS OTHER scores, and a trend-level association with LEAS TOTAL scores. FI accuracy also has a significant positive association with IQ. Interestingly, unlike FF accuracy, WO accuracy had a significant positive association with Ekman 60 total scores and MSCEIT total scores.
 Table 2. Correlations between variables Measures Facial Feeling Accuracy Facial Identity Accuracy Word Accuracy Pleasantness Accuracy Ekman 60 Total WASI IQ LEAS Total LEAS Other LEAS Self MSCEIT Total TEIQue Total Facial Feeling Accuracy 1 0.554 a 0.068 0.068 0.229 0.551 a 0.355 b 0.442 a 0.117 0.084 0.240 Facial Identity Accuracy 1 0.067 0.264 0.257 0.462 a 0.115 0.220 −0.025 0.084 0.020 Word Accuracy 1 0.305 0.515 a 0.136 *0.011 −0.089 0.017 0.390 a 0.133 Pleasantness Accuracy 1 0.573 a 0.261 0.108 0.235 0.167 0.288 −0.104 Ekman 60 Total 1 0.125 −0.219 0.052 −0.187 0.571 a −0.188 WASI IQ 1 0.619 a 0.547 a 0.533 a 0.330 0.235 LEAS Total 1 0.890 a 0.871 a 0.262 0.229 LEAS Other 1 0.694 a 0.137 0.214 LEAS Self 1 0.319 0.076 MSCEIT Total 1 0.303 TEIQue Total 1 a P   <  0.05, two-tailed. b P   =  0.07, two-tailed (i.e. trend-level finding). In line with our hypothesis, the relationship between LEAS OTHER scores and FF accuracy remained significant when controlling for accuracy within the FI and WO conditions ( r   =  0.40,  P   =  0.05). However, the relationship between LEAS OTHER scores and FF accuracy did not remain significant when controlling for IQ ( r   = 0 .20,  P   =  0.34). Further examination revealed that FF accuracy was also not significantly correlated with any of the MSCEIT subscales (−0.22 ≤ r ≤  0.22, for each). Interestingly, however, the TEIQue “relationships” subscale (which measures the self-reported ability to maintain fulfilling personal relationships) was significantly positively correlated with FF accuracy ( r   = 0.45,  P   = 0 .02). This did not remain significant when corrected for multiple comparisons (i.e. correcting for examining correlations with all TEIQue subscales). fMRI activation contrasts 
 Maintenance 
 p 
 eriod: Facial Feeling > Pleasantness.  This contrast revealed eight clusters ( Figure 2 ,  Table 3 ), spanning the left and right dorsolateral prefrontal cortex (DLPFC), the left and right anterior insula (AI), a bilateral posterior portion of the dorsomedial prefrontal cortex (DMPFC; including dorsal anterior cingulate [dACC] and supplementary motor area [SMA]), the left lateral parietal cortex, and left and right basal ganglia and thalamic regions (i.e. mid-caudate and anterior thalamus in each hemisphere). Fig. 2. Illustration of the imaging results contrasting the maintenance period of the facial feeling condition to (Top Row) that of the pleasantness (i.e. rest) condition, and to (Middle Row) that of the facial identity and word conditions. The bottom row displays the imaging results for the contrast of accurate > inaccurate trials within the facial feeling condition. Images are thresholded using a peak threshold of  P   <  0.001 (uncorrected) and a cluster threshold of  P   <  0.05, FDR-corrected. Images are in neurological orientation (i.e. left = left; right = right). 
 Table 3. FMRI activation analyses: Facial Feeling > Pleasantness (FDR-corrected cluster threshold,  P  < 0.05) Brain region AAL atlas labels Peak voxel coordinate Cluster size (k E ) T-score Left DLPFC Frontal_Inf_Tri_L −40, 26, 22 2214 8.14 Frontal_Inf_Oper_L Frontal_Mid_2_L Postcentral_L Precentral_L Posterior DMPFC/SMA/dACC (Bilateral) Supp_Motor_Area_R −6, 14, 48 955 7.84 Frontal_Sup_Medial_R Frontal_Sup_Medial_L Cingulate_Mid_L Cingulate_Mid_R Supp_Motor_Area_L Frontal_Sup_2_L Frontal_Sup_2_R Right AI Putamen_R 34, 20, −2 345 6.70 Frontal_Inf_Oper_R Insula_R Frontal_Inf_Orb_2_R Frontal_Inf_Tri_R Left AI Temporal_Pole_Sup_L −28, 26, −2 441 6.52 Frontal_Inf_Tri_L Frontal_Inf_Oper_L Frontal_Inf_Orb_2_L Insula_L Right DLPFC Frontal_Inf_Oper_R 48, 28, 28 716 5.61 Frontal_Inf_Tri_R Precentral_R Frontal_Mid_2_R Left Mid-Caudate and Anterior Thalamus Caudate_L −14, 0, 12 293 5.32 Putamen_L Thalamus_L Pallidum_L_ Right Mid-Caudate and Anterior Thalamus Caudate_R 10, 4, −4 141 5.10 Thalamus_R Pallidum_R Left Lateral Parietal Cortex Angular_L −32, −56, 40 225 4.75 Parietal_Inf_L Parietal_Sup_L Occipital_Mid_L 
 Parametric modulation analyses for this contrast revealed several regions where activity increased with increasing WM load in the Facial Feeling condition (i.e. relative to the Pleasantness condition, which involved matched load-specific stimulus conditions without any WM demands). These regions included the left and right DLPFC, bilateral posterior DMPFC (including dACC and SMA), left and right lateral parietal cortex, bilateral precuneus and left motor/pre-motor cortex ( Figure 3 ,  Table 4 ). Fig. 3. Illustration of the imaging results for the parametric modulation analysis contrasting the maintenance period of the facial feeling condition to that of the pleasantness (i.e. rest) condition. This analysis reveals regions where activation increased with increasing WM load in the facial feeling condition (but did not similarly increase with exposure to 1, 2 and 3 emotional faces/words in the absence of WM task demands). Images are thresholded using a peak threshold of  P   <  0.001 (uncorrected) and a cluster threshold of  P   <  0.05, FDR-corrected. Images are in neurological orientation (i.e. left = left; right = right). 
 Table 4. FMRI working memory load parametric modulation analyses: Facial feeling > pleasantness (FDR-corrected cluster threshold,  P  < 0.05) Brain Region AAL atlas labels Peak voxel coordinate Cluster size (k E ) T-score Right DLPFC Frontal_Mid_2_R 46, 34, 28 260 5.61 Frontal_Inf_Tri_R Posterior DMPFC/SMA/dACC (bilateral) Supp_Motor_Area_L −12, 14, 48 226 5.23 Supp_Motor_Area_R Frontal_Sup_Medial_L Frontal_Sup_Medial_R Cingulate_Mid_R Frontal_Sup_2_L Left Motor/Pre-Motor Cortex Frontal_Sup_2_L −30, 2, 60 52 5.08 Precentral_L Left Motor/Pre-Motor Cortex Frontal_Mid_2_L −48, 0, 34 137 4.78 Precentral_L Left DLPFC Frontal_Mid_2_L −34, 22, 30 92 4.78 Frontal_Inf_Tri_L Right Motor Cortex Frontal_Mid_2_R 20, 14, 58 69 4.76 Frontal_Sup_2_R Right Lateral Parietal Cortex Supramarginal_R 42, −48, 42 158 4.72 Angular_R Parietal_Inf_R Parietal_Sup_R Left Lateral Parietal Cortex Angular_L −40, −48, 42 227 4.54 Parietal_Inf_L Occipital_Mid_L Parietal_Sup_L Bilateral Precuneus Precuneus_L 8, −60, 44 67 4.52 Precuneus_R 
 
 Maintenance Period: Facial Feeling > Facial Identity + Word.  This contrast revealed clusters within the same left DLPFC, left AI, left lateral parietal cortex, and DMPFC clusters found in the previous contrast ( Figure 2 ,  Table 5 ). A more ventral left lateral prefrontal (VLPFC) cluster was also observed.
 Table 5. FMRI activation analyses: Facial feeling > facial identity + word (FDR-corrected cluster threshold,  P  < 0.05) Brain region AAL atlas labels Peak voxel coordinate Cluster size (k E ) T-score Posterior DMPFC/SMA/dACC (Bilateral) Supp_Motor_Area_R −2, 16, 50 258 6.15 Frontal_Sup_Medial_R Frontal_Sup_Medial_L Cingulate_Mid_R Supp_Motor_Area_L Frontal_Sup_2_L Left DLPFC Frontal_Mid_2_L −36, 2, 62 1324 6.14 Frontal_Inf_Oper_L Frontal_Inf_Tri_L Precentral_L Left VLPFC Frontal_Inf_Orb_2_L −50, 38, 4 67 4.36 Frontal_Inf_Tri_L Frontal_Mid_2_L Left Lateral Parietal Cortex Parietal_Inf_L −36, −48, 46 91 4.31 Left AI Insula_L −34, 34, 0 68 4.28 Frontal_Inf_Tri_L Parametric modulation analyses for this contrast revealed no regions where activity increased with increasing WM load in the Facial Feeling condition relative to the Facial Identity and Word conditions. 
 Maintenance Period: Facial Feeling (Accurate Trials) > Facial Feeling (Inaccurate Trials).  This contrast revealed two clusters. One covered regions of the left temporo-parietal junction (TPJ) and posterior insula, while the other was within right somatosensory cortex ( Figure 2 ,  Table 6 ).
 Table 6. FMRI activation analyses: Facial feeling (accurate trials) > facial feeling (inaccurate trials) (FDR-corrected cluster threshold,  P  < 0.05) Brain region AAL atlas labels Peak voxel coordinate Cluster size (k E ) T-score Left TPJ/Posterior Insula Temporal_Sup_L −58, −32, 24 330 6.54 SupraMarginal_L Rolandic_Oper_L Insula Right Somatosensory Cortex/Motor cortex Precentral_R 54, −8, 28 115 4.92 Postcentral_R 
 Additional analyses.  Because the left AI has been previously implicated in representing emotional feelings ( Craig, 2009 ), we extracted the first eigenvariate of the left AI cluster (from the Facial Feeling > Pleasantness contrast) as a measure of individual differences in left AI activation during WM maintenance of feelings; we then correlated this with LEAS OTHER scores. We also examined whether individual differences in left DLPFC activation might similarly predict LEAS OTHER scores, as our results (in conjunction with previous literature; e.g.  D’Esposito, 2007 ) suggest this structure may be important for holding representations of feelings active within WM. As hypothesized, LEAS OTHER scores were positively correlated with activation of both the left AI ( r   =  0.49,  P   <  0.05) and the left DLPFC ( r   =  0.44,  P   < 0.05). Interestingly, LEAS SELF scores (left AI:  r   = 0 .16; left DLPFC:  r   =  0.14) and LEAS TOTAL scores (left AI:  r   =  0.33; left DLPFC:  r   = 0 .32) did not show a significant relationship with either of these clusters. 
 Supplementary Contrasts.  For results of the additional contrast analyses we performed, which examined the neural activations separately associated with the Facial Identity and Word conditions, see the Supplementary results section ( Supplementary Table S1 .1–2, Figure S1). In general, these analyses suggested that neural activation associated with the Facial Identity (i.e. visual WM) and Word (i.e. verbal WM) conditions included many of the same lateral frontal-parietal network regions found in the Facial Feeling (i.e. WM-f) condition, and which have been highlighted in large meta-analyses of previous neuroimaging studies of WM ( Rottschy et al., 2012 ;  Nee  et al. , 2013 ). Discussion In this study, we designed a socio-emotional WM task that compared three different cognitive strategies one could use to hold the emotions of others in mind: holding feelings, visual images or words. Performance scores on the FF condition were not significantly correlated with Ekman 60 scores, suggesting that individual differences in visual emotion recognition ability cannot account for performance differences in this condition. FF condition performance differences therefore more plausibly reflect differences in the ability to hold feelings in mind. In further support of the validity of this condition as a measure of WM-f, we found that individual differences in performance during the FF condition, when controlling for performance within the FI and WO condition, predicted scores on the LEAS—a previously validated measure of EA. In addition to confirming task validity, this suggests that WM-f may represent an important contributing mechanism underlying EA that deserves further experimental investigation. Interestingly, the relationship between WM-f performance and LEAS scores was present only for the condition involving the emotions of others, and not for awareness of one’s own emotions. This makes sense given that our task only involves holding the emotions of others in mind, but it also suggests that EA for self and others may depend on at least partially distinct neural mechanisms. This suggestion is also consistent with our subsequent finding that task-related activation in the left AI and left DLPFC predicted LEAS OTHER scores but not LEAS SELF scores. Using this task, we then tested the hypothesis that WM-f, relative to maintaining emotion words or visual images of emotional expressions, would be associated with mFP activation. Our results did not support this hypothesis. Instead, we found that WM-f was associated with significantly greater activation of the left DLPFC, left lateral parietal cortex, and left AI, as well as a DMPFC region (spanning dACC and SMA) more posterior than that found in previous SWM studies ( Meyer et al., 2012 ,  2015 ). Contrary to our hypothesis, this pattern of findings suggests that WM for the feelings of others still involves the same major lFP network regions previously observed in meta-analyses of exteroceptive WM studies (e.g.  Rottschy  et al. , 2012 ;  Nee  et al. , 2013 ). We further found that accurate (relative to inaccurate) performance in the FF condition was associated with greater left TPJ, left insula, and right somatosensory cortex activation. As these regions have previously been linked to social cognition and representation of bodily feelings ( Craig, 2002 ;  Samson  et al. , 2004 ;  Blanke  et al. , 2005 ;  Zink  et al. , 2011 ), this is also consistent with the idea that individuals were holding the feelings of others in mind. The idea that WM-f still draws on the same lFP networks as exteroceptive WM was further supported by our parametric modulation analyses. The results of these analyses suggested that greater activation with greater WM load was present in the FF condition across a bilateral network of lFP regions. However, no region showed this load effect to a significantly greater degree for the FF condition than for the exteroceptive WM conditions (i.e. FI and WO). Our results are therefore more supportive of the previous suggestion ( Lieberman, 2007 ;  Xin and Lei, 2015 ) that lFP vs mFP activation may instead correspond to an external vs internal source of the to-be-maintained information. For example, perhaps, even in the case of feelings, lFP systems are involved when the information source is external perception (as in our task and that of  Xin and Lei, 2015 ), whereas the mFP system is more involved when the source of information is internal (e.g. from long-term memory or interoception)—as in the other EWM/SWM studies described in the introduction ( Meyer  et al. , 2012 ,  2015 ;  Waugh  et al. , 2014 ). 4  As self-related cognition will almost always draw heavily on internal sources of information (i.e. long-term memory and interoception), this could also explain why cognitive processes directed at the self (e.g.  Mitchell  et al. , 2005 ;  Buckner and Carroll, 2007 ), and at one’s own emotions (e.g.  Ochsner  et al. , 2004 ;  Smith  et al. , 2014 ), have typically been linked to the mFP system. Future studies should therefore be designed to directly test the possibility that it is the source of information, and not the information content itself, that primarily determines the extent of lFP vs. mFP involvement during WM. This could be done, for example, by designing WM tasks that compare holding the psychological states/traits of others in mind based on perceptual stimuli vs based on memory. It is important to highlight, however, that the underlying neural processes during WM-f could still be different than during exteroceptive WM, even if the same lFP network regions are involved (e.g. for a review of evidence supporting the claim that the same brain regions can support different neural/psychological processes in different contexts, see  Anderson, 2014 ). Such underlying process differences might be reflected in the greater activation levels we observed during WM-f in these regions, and they could also explain, for example, why we observed that WM-f performance, but not exteroceptive WM performance, was a significant predictor of EA. This possibility would be consistent with our finding that left AI and DLPFC activation during WM-f predicted EA as well; and although the left AI and DLPFC are part of the lFP network, the AI specifically has also separately been linked to the representation of bodily/emotional feelings ( Craig, 2009 ;  Gu  et al. , 2013 ;  Barrett and Simmons, 2015 ) and to emotion-cognition interactions ( Dolcos  et al. , 2011 ;  Harlé,  et al. , 2012 ). Our findings could therefore suggest that the AI’s role in WM and its role in interoception/emotion may be related; they also suggest that differences in the underlying processes activated by WM-f, and not the brain regions involved, may best account for its unique relationship to EA in our results. A secondary aim of this study was to explore the relationship between WM-f and measures of IQ and EI. Because the FF condition of the task mimics a social scenario in which one must hold the feelings of multiple others in mind (and use this information to make a decision), we examined whether better WM-f performance would be associated with the abilities that EI tests are designed to measure. While we observed that WM-f performance was significantly correlated with IQ, it was non-significantly associated with both the TEIQue and MSCEIT measures of EI. Further, only one EI subscale—the “relationships” subscale of the TEIQue—was found to have a significant positive association with WM-f (and only at an uncorrected significance level). This raises the possibility that better WM-f capacity may facilitate a person’s ability to maintain satisfying relationships with others, but it also suggests that WM-f is best thought of as a component of IQ. This conclusion was further supported by our finding that the positive correlation between WM-f capacity and LEAS scores was no longer significant after controlling for IQ. LEAS scores were also significantly correlated with IQ, and non-significantly correlated with EI (as previously found by  Lumley  et al. , 2005 ). This further supports the independence of the construct measured by these EI tests from the overlapping functions underlying WM-f, EA, and IQ. Therefore, while WM-f represents a cognitive ability that should theoretically contribute to EI, current EI measures appear largely insensitive to it, and it does not appear to be fully distinct from either exteroceptive WM or IQ in terms of its neural correlates and its relation to other cognitive measures. The present study has a number of important limitations. First, as we made use of a new task design, it will be important for future studies to replicate our results and provide further validation of this task. Second, our task design did not allow for a separate examination of WM for different emotions, which represents another possible topic for future research. However, current models suggest there are not unique neural correlates of different emotions ( Barrett, 2006 ;  Smith and Lane, 2015 ); based on these models we would instead expect WM for each emotion in our task to involve a similar set of brain regions associated with representing body states and learned emotion concept categories. Third, it appears the FF condition was more difficult than the FI and WO conditions. Thus, we cannot rule out that the activation we observed in the ‘facial feeling > facial identity + word’ contrast is partially explained by this difficulty difference. However, the stimulus presentation and the WM load (i.e. number of items to remember) were each identical across conditions. Thus, these difficulty differences may be specific to the content-domain of each condition, and are not attributable to differences in WM load itself. Future studies should therefore confirm whether WM-f is intrinsically more difficult (and therefore requires more cognitive effort) than WM for other content-domains, and assess its potential implications. It should also be kept in mind, however, that, even if difficulty differences resulted in greater left lFP activation in the FF condition, this still refutes the alternative hypothesis that FF would instead recruit mFP networks; it also supports our conclusion that the lFP networks associated with exteroceptive WM are primarily involved. Thus, this issue of difficulty does not threaten the major conclusions of our study. A related limitation of our task design is that, in order to keep stimulus presentation identical between conditions, individuals were required to suppress attention to interfering stimuli. As such, we also cannot rule out that this type of attentional suppression may have been more difficult in some conditions than others (e.g. perhaps suppressing attention to an emotion word in the FF condition was more difficult than suppressing attention to the facial emotion in the WO condition). This could lead to mean accuracy differences between conditions not solely attributable to WM capacity differences. That being said, these selective attention processes are thought to overlap considerably with WM processes in the brain ( Kane and Engle, 2003 ;  McCabe  et al. , 2010 ;  Gazzaley and Nobre, 2012 ). Therefore, they would be expected to activate the same brain regions and engage the same underlying functions, and individual differences in accuracy within the FF condition should still reflect differential efficiency in the same cognitive control processes. An additional consideration concerns the ecological validity of this task. To minimize ambiguity in assessing accuracy, we made use of facial expressions of strong, incongruent emotions. While there are some circumstances in which an individual might need to hold such strongly incongruent emotions in mind simultaneously 5 , it is likely more common that social situations will require holding subtler and more similar emotions in mind. Future studies should therefore examine whether similar or distinct neuro-cognitive processes are involved when holding less starkly different emotions in WM. Finally, it is important to highlight that we cannot be certain of the WM strategies actually used by our participants in the different conditions. Thus, even though our design allowed us to remove activation associated with a visual and auditory strategy, future studies would benefit from adding additional post-task measures to confirm the cognitive strategies actually employed during performance. It is worth pointing out, however, that performance scores on the FF condition were not significantly correlated with performance scores in the WO condition, and the WO condition, but not the FF condition, was significantly correlated with the Ekman 60 emotion recognition measure. This suggests that individuals were not adopting an auditory strategy in the FF condition; as the WO condition required participants to apply verbal labels held in WM to emotion faces (i.e. similar to the Ekman 60), this appears to independently support its validity as well. In contrast, FF performance scores were significantly correlated with FI performance scores; thus, we cannot rule out that a visual strategy was partially involved during the FF condition. However, FF performance, but not FI performance, correlated with scores on the LEAS (a test that requires imagining the feelings of others); this strongly suggests that the WM-f strategy was used in the FF condition but not the FI condition. In conclusion, the present study demonstrated that holding the feelings of others in mind—when controlling for the use of alternative visual/auditory WM strategies—still recruits left lFP network regions. These regions are similar to those observed for other types of working memory ( Rottschy  et al. , 2012 ), and they are also similar to those activated by the visual and verbal WM conditions of the present study (see Supplementary results). Accuracy in holding the feelings of others in mind (i.e. contrasting accurate > inaccurate trials) was also associated with other regions—the left TPJ, left posterior insula, and right somatosensory cortex—that have been previously linked to body representation and social cognition ( Craig, 2002 ;  Samson  et al. , 2004 ;  Blanke  et al. , 2005 ;  Zink  et al. , 2011 ). We further found that increasing WM-f load also led to greater lFP network activation bilaterally, but that this pattern was not significantly different from the influence of load within visual or verbal WM conditions. This suggests considerable overlap in the mechanisms underlying maintenance of emotional and non-emotional information—at least when that information is derived from an exteroceptive input channel. We also found that individual differences in the ability to hold the feelings of others in mind are positively related to IQ, EA, and the self-reported ability to maintain satisfying relationships with others. However, it was not associated with total TEIQue scores, total MSCEIT scores, or any other subscales of either of these EI tests. This suggests that current measures of EI may be insensitive to an important cognitive ability contributing to social/emotional functioning; however, it is consistent with our neuroimaging results in suggesting that WM-f reflects a domain-general cognitive ability as well as with previous suggestions that EI-related functions are not fully distinct from IQ ( Webb  et al. , 2014 ). Future studies should further investigate the relationship between WM-f and EA, EI, and IQ, while specifically accounting for differences that may be attributable to distinctions between (1) internal and external sources of information and (2) whether the feelings in question correspond to the self or others. Supplementary data 
 Supplementary data  are available at  SCAN  online. 
 Conflict of interest . None declared. Ethical approval All procedures performed in studies involving human participants were in accordance with the ethical standards of the institutional and/or national research committee and with the 1964 Helsinki declaration and its later amendments or comparable ethical standards. Supplementary Material Supplementary Data Click here for additional data file. Acknowledgment The authors would like to acknowledge and thank Omar Khodr for assistance with data collection and analysis. 1 To be clear, this idea would  not  require that individuals actually generate, perceive, and then maintain a congruent bodily emotional reaction in WM in response to a face (although such automatic emotional reactions to faces may occur; e.g. see  Dimberg  et al. , 2000 ;  Tamietto  et al. , 2009 ). Instead, it would only require that individuals activate  representations  of bodily/emotional feelings in a top-down manner (i.e. even if these representations don’t correspond to actual body state changes). This is analogous to any other goal- and/or cue-directed perceptual imagery generation process (e.g. being instructed to imagine seeing a house and then to hold this image in mind). Previous studies have suggested that perceptual systems in the brain represent such imagined percepts by producing activation patterns very similar to those evoked during actual stimulus presentation ( O’Craven and Kanwisher, 2000 ;  Kreiman  et al. , 2000 ). This is also consistent with the results of previous studies that have specifically asked individuals to imagine feeling particular emotions (e.g.  Jabbi  et al. , 2008 ). 2 Previous studies have found little to no relationship between measures of EA and EI ( Barchard and Hakstian, 2004 ;  Lumley  et al. , 2005 ), and the validity of current EI measures has also been questioned on a number of grounds ( Roberts  et al. , 2006 ;  Maul, 2012 ;  Fiori  et al. , 2014 ;  Webb  et al. , 2014 ). Therefore, while we had an independent rationale for expecting WM-f to correlate with EA (described above), the expected relationship between WM-f and EI was unclear. We therefore framed our analyses of EI as exploratory. 3 Unfortunately, Ekman 60 scores were not gathered on the first 10 participants due to an error during data collection. 4 Similarly, a large number of studies on motor control have also suggested that lateral vs. medial cortical regions are associated with the use of external vs. internal sources of information in guiding skeletomotor movement (reviewed in  Passingham  et al. , 2010 ). 5 For example, after deciding to give one employee a raise over another employee (making the first employee happy and the second sad), an employer would likely need to simultaneously consider the feelings of both employees when making decisions (e.g. about how to minimize conflict and maximize motivation going forward). The employer would also plausibly benefit from actually imagining how these employees feel, as opposed to simply using an auditory strategy (e.g. internally repeating the words “happy” and “sad”). References 
 Anderson M.  ( 2014 ).  After Phrenology: Neural Reuse and the Interactive Brain . 
 Cambridge, MA : 
 MIT Press . 
 Baddeley A.  ( 2007 ).  Working Memory, Thought, and Action . 
 Oxford : 
 Oxford University Press . 
 Barbey A. ,  Koenigs M. ,  Grafman J.  ( 2013 ). 
 Dorsolateral prefrontal contributions to human working memory .  Cortex ,  49 ( 5 ), 1195 – 205 . 22789779 
 Barchard K. ,  Bajgar J. ,  Leaf D. ,  Lane R.  ( 2010 ). 
 Computer scoring of the Levels of Emotional Awareness Scale .  Behavior Research Methods ,  42 ( 2 ), 586 – 95 . 20479190 
 Barchard K. ,  Hakstian A.  ( 2004 ). 
 The nature and measurement of emotional intelligence abilities: basic dimensions and their relationships with other cognitive ability and personality variables .  Educational and Psychological Measurement ,  64 ( 3 ), 437 – 62 .  
 Barrett L.  ( 2006 ). 
 Are emotions natural kinds? Perspectives on Psychological Science 1 ( 1 ), 28 – 58 .  26151184 
 Barrett L. ,  Simmons W.  ( 2015 ). 
 Interoceptive predictions in the brain .  Nature Reviews. Neuroscience ,  16 ( 7 ), 419 – 29 .  26016744 
 Blanke O. ,  Mohr C. ,  Michel C.M. ,   ( 2005 ). 
 Linking out-of-body experience and self processing to mental own-body imagery at the temporoparietal junction .  Journal of Neuroscience ,  25 ( 3 ),550–7. 
 Buckner R. ,  Carroll D.C.  ( 2007 ). 
 Self-projection and the brain .  Trends in Cognitive Sciences ,  11 ( 2 ), 49 – 57 . 17188554 
 Conway A.R.A. ,  Kane M.J. ,  Engle R.W.  ( 2003 ). 
 Working memory capacity and its relation to general intelligence .  Trends in Cognitive Sciences ,  7 ( 12 ), 547 – 52 .  14643371 
 Craig A.D.  ( 2002 ). 
 How do you feel? Interoception: the sense of the physiological condition of the body .  Nature Reviews. Neuroscience ,  3 ( 8 ), 655 – 66 . 12154366 
 Craig A.D.  ( 2009 ). 
 How do you feel–now? The anterior insula and human awareness .  Nature Reviews Neuroscience ,  10 ( 1 ), 59 – 70 . 19096369 
 D’Esposito M.  ( 2007 ). 
 From cognitive to neural models of working memory .  Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences ,  362 ( 1481 ), 761 – 72 .  17400538 
 Dimberg U. ,  Thunberg M. ,  Elmehed K.  ( 2000 ). 
 Unconscious facial reactions to emotional facial expressions .  Psychological Science ,  11 ( 1 ), 86 – 9 . 11228851 
 Dolcos F. ,  Iordan A. ,  Dolcos S.  ( 2011 ). 
 Neural correlates of emotion-cognition interactions: a review of evidence from brain imaging investigations .  Journal of Cognitive Psychology ,  23 ( 6 ), 669 – 94 .  22059115 
 Duncan J. ,  Owen A.  ( 2000 ). 
 Common regions of the human frontal lobe recruited by diverse cognitive demands .  Trends in Neurosciences ,  23 ( 10 ), 475 – 83 . (00)01633-7 11006464 
 Ekman P. ,  Friesen W.  ( 1976 ).  Pictures of Facial Affect . 
 Palo Alto, CA : 
 Consulting Psychologists Press . 
 Engle R.  ( 2002 ). 
 Working memory capacity as executive attention .  Current Directions in Psychological Science ,  11 ( 1 ), 19 – 23 .  
 Fiori M. ,  Antonietti J.P. ,  Mikolajczak M. ,  Luminet O. ,  Hansenne M. ,  Rossier J.  ( 2014 ). 
 What Is the ability emotional intelligence test (MSCEIT) good for? An evaluation using item response theory .  PLoS ONE 9 ( 6 ),  e98827. 24901541 
 Gazzaley A. ,  Nobre A.C.  ( 2012 ). 
 Top-down modulation: bridging selective attention and working memory .  Trends in Cognitive Sciences ,  16 ( 2 ), 129 – 35 .  22209601 
 Glahn D.C. ,  Kim J. ,  Cohen M.S. ,   ( 2002 ). 
 Maintenance and manipulation in spatial working memory: dissociations in the prefrontal cortex .  NeuroImage ,  17 ( 1 ), 201 – 13 .  12482077 
 Gu X. ,  Hof P. ,  Friston K. ,  Fan J.  ( 2013 ). 
 Anterior insular cortex and emotional awareness .  The Journal of Comparative Neurology ,  521 ( 15 ), 3371 – 88 .  23749500 
 Gusnard D. ,  Akbudak E. ,  Shulman G. ,  Raichle M.  ( 2001 ). 
 Medial prefrontal cortex and self-referential mental activity: relation to a default mode of brain function .  Proceedings of the National Academy of Sciences ,  98 ( 7 ), 4259 – 64 . 
 Harlé K. ,  Chang L. ,  van ’t Wout M. ,  Sanfey A.  ( 2012 ). 
 The neural mechanisms of affect infusion in social economic decision-making: a mediating role of the anterior insula .  NeuroImage ,  61 ( 1 ),  32 – 40 .  22374480 
 Jabbi M. ,  Bastiaansen J. ,  Keysers C.  ( 2008 ). 
 A common anterior insula representation of disgust observation, experience and imagination shows divergent functional connectivity pathways .  PLoS ONE ,  3 ( 8 ), e2939. 18698355 
 Kane M. ,  Engle R.  ( 2002 ). 
 The role of prefrontal cortex in working-memory capacity, executive attention, and general fluid intelligence: an individual-differences perspective .  Psychonomic Bulletin & Review ,  9 ( 4 ), 637 – 71 .  12613671 
 Kane M. ,  Engle R.  ( 2003 ). 
 Working-memory capacity and the control of attention: the contributions of goal neglect, response competition, and task set to Stroop interference .  Journal of Experimental Psychology: General ,  132 ( 1 ), 47 – 70 .  12656297 
 Koechlin E. ,  Ody C. ,  Kouneiher F.  ( 2003 ). 
 The architecture of cognitive control in the human prefrontal cortex .  Science ,  302 ( 5648 ), 1181 – 5 .  
 Kreiman G. ,  Koch C. ,  Fried I.  ( 2000 ). 
 Imagery neurons in the human brain .  Nature ,  408 ( 6810 ), 357 – 61 .  11099042 
 Lane R. ,  Fink G. ,  Chua P. ,  Dolan R.  ( 1997 ). 
 Neural activation during selective attention to subjective emotional responses .  Neuroreport ,  8 ( 18 ),  3969 – 72 . 9462476 
 Lane R. ,  Quinlan D. ,  Schwartz G. ,  Walker P. ,  Zeitlin S.  ( 1990 ). 
 The Levels of Emotional Awareness Scale: a cognitive-developmental measure of emotion .  Journal of Personality Assessment ,  55 ( 1–2 ), 124 – 34 .  2231235 
 Levy R. ,  Goldman-Rakic P.  ( 2000 ). 
 Segregation of working memory functions within the dorsolateral prefrontal cortex .  Experimental Brain Research ,  133 ( 1 ), 23 – 32 . 10933207 
 Lieberman M.  ( 2007 ). 
 Social cognitive neuroscience: a review of core processes .  Annual Review of Clinical Psychology ,  58 ,  259 – 89 . 
 Lumley M. ,  Gustavson B. ,  Partridge R. ,  Labouvie-Vief G.  ( 2005 ). 
 Assessing alexithymia and related emotional ability constructs using multiple methods: interrelationships among measures .  Emotion ,  5 ( 3 ), 329 – 42 . 16187868 
 Maul A.  ( 2012 ). 
 The validity of the Mayer-Salovey-Caruso emotional intelligence test (MSCEIT) as a measure of emotional intelligence .  Emotion Review ,  4 ( 4 ), 394 – 402 .  
 Mayer J. ,  Salovey P. ,  Caruso D.  ( 2002 ).  Mayer-Salovey-Caruso Emotional Intelligence Test (MSCEIT) – User’s Manual . 
 North Tonawanda, NY : 
 Multi-Health Systems . 
 Mayer J. ,  Salovey P. ,  Caruso D. ,  Sitarenios G.  ( 2001 ). 
 Emotional intelligence as a standard intelligence .  Emotion ,  1 ( 3 ), 232 – 42 . 12934682 
 McCabe D. ,  Roediger H. ,  McDaniel M. ,  Balota D. ,  Hambrick D.  ( 2010 ). 
 The relationship between working memory capacity and executive functioning: evidence for a common executive attention construct .  Neuropsychology ,  24 ( 2 ), 222 – 43 .  20230116 
 McVay J. ,  Kane M.  ( 2012 ). 
 Why does working memory capacity predict variation in reading comprehension? On the influence of mind wandering and executive attention .  Journal of Experimental Psychology: General ,  141 ( 2 ), 302 – 20 .  21875246 
 Meyer M. ,  Lieberman M.  ( 2012 ). 
 Social working memory: neurocognitive networks and directions for future research .  Frontiers in Psychology ,  3 ,  1 – 11 .  22279440 
 Meyer M. ,  Spunt R. ,  Berkman E. ,  Taylor S. ,  Lieberman M.  ( 2012 ). 
 Evidence for social working memory from a parametric functional MRI study .  Proceedings of the National Academy of Sciences of the United States of America ,  109 ( 6 ), 1883 – 8 . 22308468 
 Meyer M. ,  Taylor S. ,  Lieberman M.  ( 2015 ). 
 Social working memory and its distinctive link to social cognitive ability: an fMRI study .  Social Cognitive and Affective Neuroscience ,  10 ( 10 ),1338–47.  
 Mikels J. ,  Reuter-Lorenz P. ,  Beyer J. ,  Fredrickson B.  ( 2008 ). 
 Emotion and working memory: evidence for domain-specific processes for affective maintenance .  Emotion 8 ( 2 ), 256 – 66 . 18410199 
 Mikolajczak M. ,  Luminet O. ,  Leroy C. ,  Roy E.  ( 2007 ). 
 Psychometric properties of the Trait Emotional Intelligence Questionnaire: factor structure, reliability, construct, and incremental validity in a french-speaking population .  Journal of Personality Assessment ,  88 ( 3 ), 338 – 53 . 17518555 
 Mitchell J. ,  Banaji M. ,  MacRae C.  ( 2005 ). 
 The link between social cognition and self-referential thought in the medial prefrontal cortex .  Journal of Cognitive Neuroscience , 17 (8), 1306–15. 
 Nee D. ,  Brown J. ,  Askren M. ,   ( 2013 ). 
 A meta-analysis of executive components of working memory .  Cerebral Cortex ,  23 ( 2 ), 264 – 82 .  22314046 
 O’Craven K.M. ,  Kanwisher N.  ( 2000 ). 
 Mental imagery of faces and places activates corresponding stimulus-specific brain regions .  Journal of Cognitive Neuroscience ,  12 ( 6 ), 1013 – 23 .  11177421 
 Ochsner K. ,  Knierim K. ,  Ludlow D.H. ,   ( 2004 ). 
 Reflecting upon feelings: an fMRI study of neural systems supporting the attribution of emotion to self and other .  Journal of Cognitive Neuroscience ,  16 ( 10 ), 1746 – 72 . 15701226 
 Passingham R. ,  Bengtsson S. ,  Lau H.  ( 2010 ). 
 Medial frontal cortex: from self-generated action to reflection on one’s own performance .  Trends in Cognitive Sciences ,  14 ( 1 ), 16 – 21 .  19969501 
 Petrides M.  ( 2000 ).  Middorsolateral and midventrolateral prefrontal cortex: two levels of executive control for the processing of mnemonic information  In  Monsell S. ,  Driver J. , editors.  Control of Cognitive Processes: Attention and Performance XVIII , pp.  535 – 548 . 
 Cambridge, MA : 
 MIT Press . 
 Petrides K. ,  Pita R. ,  Kokkinaki F.  ( 2007 ). 
 The location of trait emotional intelligence in personality factor space .  British Journal of Psychology (London, England : 1953 ) ,  98 ( Pt 2 ), 273 – 89 .  
 Ranganath C. ,  D’Esposito M.  ( 2005 ). 
 Directing the mind’s eye: prefrontal, inferior and medial temporal mechanisms for visual working memory .  Current Opinion in Neurobiology ,  15 ( 2 ), 175 – 82 .  15831399 
 Roberts R. ,  Schulze R. ,  O’Brien K. ,  MacCann C. ,  Reid J. ,  Maul A.  ( 2006 ). 
 Exploring the validity of the Mayer-Salovey-Caruso Emotional Intelligence Test (MSCEIT) with established emotions measures .  Emotion ,  6 ( 4 ), 663 – 9 .  17144757 
 Rottschy C. ,  Langner R. ,  Dogan I. ,   ( 2012 ). 
 Modelling neural correlates of working memory: a coordinate-based meta-analysis .  NeuroImage ,  60 ( 1 ), 830 – 46 .  22178808 
 Samson D. ,  Apperly I. ,  Chiavarino C. ,  Humphreys G.  ( 2004 ). 
 Left temporoparietal junction is necessary for representing someone else’s belief .  Nature Neuroscience ,  7 ( 5 ), 499 – 500 .  15077111 
 Smith R. ,  Fass H. ,  Lane R.  ( 2014 ). 
 Role of medial prefrontal cortex in representing one’s own subjective emotional responses: a preliminary study .  Consciousness and Cognition ,  29 ,  117 – 30 .  25282525 
 Smith R. ,  Lane R.  ( 2015 ). 
 The neural basis of one’s own conscious and unconscious emotional states .  Neuroscience & Biobehavioral Reviews ,  57 ,  1 – 29 .  26363579 
 Sreenivasan K.K. ,  Curtis C.E. ,  D’Esposito M.  ( 2014 ). 
 Revisiting the role of persistent neural activity during working memory .  Trends in Cognitive Sciences ,  18 ( 2 ), 82 – 9 .  24439529 
 Tamietto M. ,  Castelli L. ,  Vighetti S. ,   ( 2009 ). 
 Unseen facial and bodily expressions trigger fast emotional reactions .  Proceedings of the National Academy of Sciences of the United States of America ,  106 ( 42 ), 17661 – 666 .  19805044 
 Tzourio-Mazoyer N. ,  Landeau B. ,  Papathanassiou D. ,   ( 2002 ). 
 Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain .  NeuroImage ,  15 ( 1 ), 273 – 89 .  11771995 
 Veltman D.J. ,  Rombouts S.A.R. ,  Dolan R.J.  ( 2003 ). 
 Maintenance versus manipulation in verbal working memory revisited: an fMRI study .  NeuroImage ,  18 ( 2 ), 247 – 56 . (02)00049-6 12595179 
 Waugh C. ,  Lemus M. ,  Gotlib I.  ( 2014 ). 
 The role of the medial frontal cortex in the maintenance of emotional states .  Social Cognitive and Affective Neuroscience ,  9 ( 12 ), 2001 – 9 .  24493835 
 Webb C. ,  DelDonno S. ,  Killgore W.  ( 2014 ). 
 The role of cognitive versus emotional intelligence in Iowa Gambling task performance: what’s emotion got to do with it? Intelligence ,  44 ,  112 – 9 .  25635149 
 Webb C. ,  Schwab Z. ,  Weber M. ,   ( 2013 ). 
 Convergent and divergent validity of integrative versus mixed model measures of emotional intelligence .  Intelligence ,  41 ( 3 ), 149 – 56 .  Wechsler D. (2011).  Wechsler Abbreviated Scale of Intelligence-Second Edition (WASI-II) . San Antonio, TX: NCS Pearson. 
 Xin F. ,  Lei X.  ( 2015 ). 
 Competition between frontoparietal control and default networks supports social working memory and empathy .  Social Cognitive and Affective Neuroscience ,  10 ( 8 ), 1144 – 52 .  25556209 
 Zink C. ,  Kempf L. ,  Hakimi S. ,  Rainey C. ,  Stein J. ,  Meyer-Lindenberg A.  ( 2011 ). 
 Vasopressin modulates social recognition-related activity in the left temporoparietal junction in humans .  Translational Psychiatry ,  1 ( 4 ), e3. 22832391