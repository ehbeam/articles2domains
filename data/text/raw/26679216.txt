
 properties manuscript? 
 
 
 8910747 
 20835 
 J Cogn Neurosci 
 J Cogn Neurosci 
 
 Journal of cognitive neuroscience 
 
 0898-929X 
 1530-8898 
 
 
 26679216 
 4861322 
 10.1162/jocn_a_00908 
 NIHMS778788 
 
 
 Article 
 
 
 
 Semantics of the visual environment encoded in parahippocampal cortex 
 
 
 
 
 Bonner 
 Michael F. 
 
 1 
 
 
 
 Price 
 Amy Rose 
 
 1 
 
 
 
 Peelle 
 Jonathan E. 
 
 2 
 
 
 
 Grossman 
 Murray 
 
 1 
 
 
 1 Department of Neurology, University of Pennsylvania, Philadelphia, PA 19104, USA 
 2 Department of Otolaryngology, Washington University in St. Louis, St. Louis, MO 63110, USA 
 
 Please address correspondence to: Michael F. Bonner or Murray Grossman, Department of Neurology – 2 Gibson, University of Pennsylvania, 3400 Spruce Street, Philadelphia, PA 19104, phone: 215-662-3361; fax: 215-349-8464,  michafra@mail.med.upenn.edu  or  mgrossma@mail.med.upenn.edu 
 
 
 20 
 4 
 2016 
 
 
 17 
 12 
 2015 
 
 
 3 
 2016 
 
 
 09 
 5 
 2016 
 
 28 
 3 
 361 
 378 
 
 
 This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law. 
 
 
 
 Semantic representations capture the statistics of experience and store this information in memory. A fundamental component of this memory system is knowledge of the visual environment, including knowledge of objects and their associations. Visual semantic information underlies a range of behaviors, from perceptual categorization to cognitive processes such as language and reasoning. Here we examine the neuroanatomic system that encodes visual semantics. Across three experiments, we found converging evidence indicating that knowledge of verbally mediated visual concepts relies on information encoded in a region of the ventral-medial temporal lobe centered on parahippocampal cortex. In an fMRI study, this region was strongly engaged by the processing of concepts relying on visual knowledge but not by concepts relying on other sensory modalities. In a study of patients with the semantic variant of primary progressive aphasia (semantic dementia), atrophy that encompassed this region was associated with a specific impairment in verbally mediated visual semantic knowledge. Finally, in a structural study of healthy adults from the fMRI experiment, gray matter density in this region related to individual variability in the processing of visual concepts. The anatomic location of these findings aligns with recent work linking the ventral-medial temporal lobe with high-level visual representation, contextual associations, and reasoning through imagination. Together this work suggests a critical role for parahippocampal cortex in linking the visual environment with knowledge systems in the human brain. 
 
 
 semantic memory 
 parahippocampal 
 concrete concepts 
 object knowledge 
 visual semantics 
 medial temporal lobe 
 semantic dementia 
 
 
 
 
 INTRODUCTION 
 The human brain constructs knowledge representations of objects in the visual environment. We use this information to categorize objects in perception, to refer to objects in language, and to reason about objects in thought. It remains unclear, however, how this semantic content is represented in the brain. Here we demonstrate that semantic knowledge of visual objects relies on information encoded in the ventral-medial temporal lobe—specifically, parahippocampal cortex. 
 Theories of semantic memory have often linked object concepts with the fusiform gyrus ( Binder & Desai, 2011 ;  Martin, 2007 ;  Mion et al., 2010 ), an area that contributes to high-level object perception ( Kravitz, Saleem, Baker, Ungerleider, & Mishkin, 2013 ). There is indeed strong evidence that the anterior portions of the fusiform gyrus encode object representations in semantic memory ( Martin, 2007 ). However, a number of other regions are also frequently implicated in object semantics. These include parahippocampal and perirhinal cortices, the angular gyrus, the precuneus, and the posterior cingulate ( Binder & Desai, 2011 ;  Binder, Desai, Graves, & Conant, 2009 ;  Tyler et al., 2004 ;  Wang, Conder, Blitzer, & Shinkareva, 2010 ). Recent work has begun to elucidate the contributions of these other regions to semantic memory. 
 One relevant theory proposes that regions of the medial temporal lobe (which includes the hippocampus and parahippocampal, perirhinal, and entorhinal cortices) encode high-level object representations that underlie both perception and memory ( Barense, Henson, & Graham, 2011 ;  Bussey & Saksida, 2007 ;  Murray, Bussey, & Saksida, 2007 ). This account is largely motivated by the strong connectivity of the medial temporal lobe with anterior portions of the ventral visual system ( Kravitz et al., 2013 ). In particular, perirhinal cortex has received considerable attention in theories of visual-mnemonic representation ( Murray et al., 2007 ;  Suzuki & Amaral, 1994 ). However, parahippocampal cortex, a region just posterior to perirhinal cortex, is also well situated for processing high-level visual information and linking this information to a number of polymodal association cortices ( Suzuki & Amaral, 1994 ). Indeed, parahippocampal cortex is commonly activated in studies of concrete semantics ( Binder et al., 2009 ;  Thompson-Schill, Aguirre, D’Esposito, & Farah, 1999 ;  Wang et al., 2010 ;  Wise et al., 2000 ), and it contains similar codes for object categories across both vision and language ( Fairhall & Caramazza, 2013 ). Although this evidence suggests that parahippocampal cortex may be another critical node in the semantic network that underlies knowledge of the visual environment, it has received comparatively little attention in theories of semantic memory. 
 Here we examine the semantic representations of words with strong visual associations and demonstrate that parahippocampal cortex encodes visually weighted semantic knowledge. Our approach is similar to previous work examining the concreteness and imageability of words ( Binder, Westbury, McKiernan, Possing, & Medler, 2005 ;  Sabsevitz, Medler, Seidenberg, & Binder, 2005 ), but it differs in that we characterize semantic associations in specific sensory modalities (i.e., visual, auditory, and motor). In three experiments we find that: 1) neural activity in parahippocampal cortex is strongly engaged by the processing of visual concepts but not by concepts in other sensory modalities; 2) gray matter atrophy of parahippocampal cortex in patients with the semantic variant of primary progressive aphasia is associated with a specific impairment on visual semantics; and 3) the structure of parahippocampal cortex in healthy adults relates to individual differences in the processing of visual concepts. 
 
 
 MATERIALS AND METHODS 
 
 General methods 
 
 Overview 
 We examined the neural basis for visual semantic processing in three experiments. In Experiment 1, we characterized the functional neuroanatomy of visually weighted lexical semantics using fMRI in healthy adults. In Experiment 2, we examined the anatomic basis for impairments on visually weighted semantic knowledge in patients with the semantic variant of primary progressive aphasia (svPPA). In Experiment 3, we identified individual differences in structural neuroanatomy in healthy adults that relate to individual variability in the processing of words that depend on visual semantic information. For all three experiments, we used the same lexical-semantic task, which allowed us to test for converging anatomic findings across studies. Furthermore, because we used verbal materials rather than images in our experiments, we were able to examine stored object knowledge separate from the perceptual processes that underlie object vision. 
 
 
 Word-association task 
 The core experimental task in the three studies below was a two-alternative forced-choice task, similar in structure to the Pyramids and Palm Trees test, a standard neuropsychological assessment of semantic memory ( Howard & Patterson, 1992 ). In this task, subjects indicated which of two word choices “best goes with” an index word. For example, given the index word  pencil  and the choices  crayon  and  spoon , subjects should choose  crayon . Slight variations of this task were created to accommodate the procedure for the fMRI and patient experiments, as detailed below. 
 All stimuli (n = 88 triads of words) were nouns, and no words were repeated in the task. We obtained the stimuli from a set of 489 nouns probed in a norming study with 22 young adults in which words were rated on a scale from 0 to 6 for how strongly they were associated with semantic features in each of three modalities: visual, auditory, and motor-manipulation ( Bonner & Grossman, 2012 ;  Bonner, Peelle, Cook, & Grossman, 2013 ). Subsets of 22 triads were created to exhibit weightings for visual (e.g., index: diamond; target: gold; foil: lake), auditory (e.g., index: thunder; target: downpour; foil: rocket) or motor-manipulation features (e.g., index: pencil; target: crayon; foil: spoon), and we also created a set of abstract trials that included words with low ratings on all three modalities (e.g., index: saga; target: epic; foil: proxy). Distributions and pairwise scatter plots of the feature ratings for all subsets are illustrated in  Figure 1 . The distribution plots were generated through kernel density estimation using a Gaussian kernel and Scott’s rule of thumb for bandwidth selection ( Scott, 2015 ). The stimuli are listed in  Appendix A , and their psycholinguistic characteristics are summarized in  Table 1 . These subsets were matched on letter length, lexical frequency ( Francis & Kucera, 1982 ), and “semantic-associativity” values of the index-target and index-foil pairs (all pairwise comparisons p > .2). Semantic-associativity values were determined in a norming study in which 16 young adults rated all index-target and index-foil word pairs for how semantically associated they were with one another on a scale of 0 to 6. These ratings were used to balance the difficulty of answer choices across conditions. Concreteness and imageability ratings from the MRC Psycholinguistic database were available for 60% of the stimuli, which we report in  Table 1  ( Coltheart, 1981 ;  Gilhooly & Logie, 1980 ;  Paivio, Yuille, & Madigan, 1968 ). In the patient study, we focused on two of these subsets (the visual and abstract subsets), as described in Experiment 2. In the fMRI study, we combined the stimuli across all subsets and used a parametric modulation analysis to model the BOLD activation for semantic feature associations in the visual, auditory, and motor modalities (details of this analysis are described in Experiment 1). 
 During testing, subjects saw triads of words and indicated by button press which of two answer choices below “best goes with” the index word above. Half of the target responses were on the left and half on the right. There were an equal number of left and right responses across categories, and the stimuli were presented in a random order. We administered a practice session before all experiments to familiarize participants with the task and to ensure that task instructions were understood. The practice session for the fMRI experiment was presented outside of the scanner before imaging. Participants received feedback about their responses only in this practice session and not during administration of the experimental task. Stimulus items in the practice session were not presented in the experimental trials. We used E-Prime 2.0 to present stimuli and record responses for all experiments (Psychology Software Tools, Inc.). 
 
 
 MRI image acquisition 
 Participants were scanned on a Siemens 3.0T Trio scanner. We acquired T1-weighted structural images using an MPRAGE protocol (repetition time [TR] = 1620 ms, echo time [TE] = 3 ms, flip angle = 15°, 1 mm slice thickness, 192 × 256 matrix, voxel size = .98 × .98 × 1 mm). In healthy adults, we also collected BOLD fMRI images (TR = 3 s, effective TE = 30 ms, flip angle = 90°, 64 × 64 matrix, 3 mm isotropic voxels, with fat saturation). 
 
 
 
 Experiment 1: Functional neuroimaging in healthy adults 
 
 Participants 
 Eighteen healthy young adults from the University of Pennsylvania community participated in the fMRI study (10 female; mean age = 23.5 years, standard deviation = 2.4 years). All were right-handed, and all were native English speakers with no history of neurological difficulty as determined by a pre-experiment screening procedure. Two subjects were later excluded (as explained in the neuroimaging methods below). The demographics of the remaining subjects were: 9 female, mean age = 23.4 years, standard deviation = 2.5 years. All participants completed an informed consent procedure approved by the University of Pennsylvania Institutional Review Board. 
 
 
 Word-association task 
 The word association task described above was administered to subjects in the fMRI scanner. 
 
 
 Letter-matching task 
 In the fMRI study, subjects also performed a letter-matching task on triads of pronounceable pseudowords. This task was included as a low-level baseline in order to assess overall lexical-semantic activation in the fMRI study. There were 22 trials in this task with no repeated stimuli. The pronounceable pseudowords were matched to the real-word stimuli on letter length (t(328) = .34, p > .7). Each triad contained an index stimulus at the top of the screen with two answer choices below (a target and a foil). Subjects indicated by button press which of the two choices ended with the same letter as the index. Half of the target responses were on the left and half on the right. 
 
 
 
 Functional neuroimaging methods 
 
 Experimental procedure 
 Participants performed both the word-association task and the pseudoword letter-matching task, which served as a low-level baseline. Trials from these two tasks were interspersed in a random order. Each trial was composed of two 3000 ms events. In the first event, subjects saw a blank white screen for 2000 ms, followed by a 1000 ms presentation of the task name, which was “Word Match” for the word-association task and “Letter Match” for the letter-matching task. In the second event, a word or pseudoword triad appeared on the screen for 3000 ms, during which time subjects indicated their answer choice by button press. A quarter of all trials were 3000-ms null events. 
 
 
 Functional MRI analysis 
 We processed and analyzed BOLD fMRI images using SPM8 (Wellcome Trust Centre for Neuroimaging, London, UK) and MATLAB (R2013a Mathworks). For each subject, the functional images were realigned to the first image ( Friston et al., 1995 ), coregistered with the structural image ( Ashburner & Friston, 1997 ), and normalized to standard Montreal Neurological Institute (MNI) space using unified segmentation with resampling of images into isotropic 2 mm voxels ( Ashburner & Friston, 2005 ). We inspected movement parameters generated during image realignment. One participant who moved more than 1.5 mm during the scan was excluded from further analyses. No other subjects moved more than 1 mm during the entire scan. We removed low-frequency drifts by applying a high-pass filter with a cutoff period of 90 s, and we modeled autocorrelations with a first-order autoregressive model. The images were spatially smoothed using a 10 mm full-width at half-maximum (FWHM) isotropic Gaussian kernel. 
 We used a general linear model to calculate parameter estimates for each variable, and to perform linear contrasts for comparisons of interest. In a single model, we modeled the fMRI BOLD responses to the word-match and letter-match trials (i.e., the word and pseudoword tasks) and included parametric modulators for the visual, auditory, and motor associations of each word trial. These three parametric modulators were created from the average values of the visual, auditory, and motor associations in each triad. The parametric modulators were modeled with serial orthogonalization in the following order: auditory, motor, and visual. This orthogonalization approach means that the effect for the visual parametric modulator reflects variance that is uniquely accounted for by visual associations and not by auditory or motor associations or by variance shared between the three regressors. (Similar results were obtained regardless of the ordering of the orthogonalized modulators). In order to make inferences across participants, we entered the parameter estimates into a second-level random-effects analysis. One subject showed right lateralized language activation (the only subject whose peak activation for the word association task was right inferior frontal cortex rather than left) and was excluded from the group-level analysis. 
 
 
 
 Experiment 2: Structural neuroimaging in patients 
 
 Participants 
 Eight patients with svPPA (also known as semantic dementia) participated in the study (4 female; mean age = 64.1 years, standard deviation = 7.9 years). This syndrome is a variant of frontotemporal dementia and is predominantly associated with temporal lobe atrophy ( Bonner, Ash, & Grossman, 2010 ;  Hodges & Patterson, 2007 ;  Hodges, Patterson, Oxbury, & Funnell, 1992 ). Patients were diagnosed according to published criteria ( Gorno-Tempini et al., 2011 ), and diagnoses were confirmed in a consensus conference based on a review of a semi-structured history, a comprehensive mental status exam, and a complete neurological exam by at least two independent, trained reviewers. The demographic and clinical characteristics of the patients are shown in  Table 2 . This table includes: the Mini Mental State Exam, which assesses general cognitive performance ( Folstein, Folstein, & McHugh, 1975 ); the Pyramids and Palm Trees test, which assesses semantic memory ( Howard & Patterson, 1992 ); and a modified Rey Complex Figure test, which assesses visuospatial abilities and episodic recall ( Libon et al., 2011 ). 
 Twenty-two healthy older adults performed the word-association task as an age-matched control group for the behavioral analysis in patients (11 female; mean age = 60.9 years, standard deviation = 7.6 years). A separate group of 38 healthy older adults were scanned as age-matched controls for the structural neuroimaging analysis in patients (17 female; mean age = 64.8 years, standard deviation = 8.6 years). All participants and the legal representatives of the patients completed an informed consent procedure approved by the University of Pennsylvania Institutional Review Board. 
 
 
 Word-association task 
 For the behavioral study in patients, we examined performance on two subsets of words that differed strongly on their visual-association ratings but were otherwise psycholinguistically matched. We refer to these subsets of stimuli as visual words (n = 22 triads; mean visual association strength = 5.5, standard deviation = 0.3) and abstract words (n = 22 triads; mean visual association strength = 0.6, standard deviation = 0.6). The patients and a group of age-matched controls performed the word-association task as described in the General methods. 
 
 
 
 Structural neuroimaging methods 
 
 Structural MRI analysis 
 We processed the T1-weighted structural images with Advanced Normalization Tools ( Avants, Epstein, Grossman, & Gee, 2008 ) (ANTS;  http://stnava.github.io/ANTs/ ). The images were inhomogeneity-corrected using the N4ITK algorithm ( Tustison et al., 2010 ), warped to a local template space using symmetric diffeomorphic normalization, segmented into tissue probability maps without modulation using template-based priors, registered to MNI template space, and smoothed with a 12 mm FWHM Gaussian kernel. The preprocessed images were further analyzed using SPM8 and MATLAB. We analyzed overall gray matter atrophy with a two-sample t-test comparing gray matter density in patients to gray matter density in the group of 38 age-matched healthy controls. We performed voxelwise regression analyses to identify brain regions where gray matter density was related to behavioral performance across individuals. As no global covariates were included, the regression results reflect differences in measured gray matter density ( Peelle, Cusack, & Henson, 2012 ). In the patient group, we performed a regression analysis using each subject’s performance on visual relative to abstract concepts (i.e., the difference in accuracy for visual and abstract trials). We also performed a regression analysis in patients using overall accuracy. 
 
 
 Inter-study similarity analysis 
 To examine the similarity of whole-brain effects across Experiments 1 and 2, we performed a nonparametric permutation test based on a previously published method for assessing the similarity of effects at corresponding cortical locations ( Csernansky et al., 2008 ;  Hill et al., 2010 ;  Van Essen et al., 2006 ). This method has been used for examining the similarity of findings across hemispheres; here we used it to assess similarity across studies. Specifically, we used this method to test the hypothesis that the effects from the structural MRI study in patients are anatomically similar to the fMRI activation effects for visual semantics in healthy adults. 
 We first quantified interaction effects at each voxel by multiplying together the unthresholded, whole-brain statistical maps from each study. The first statistical map contains t-values for the positive effects of the visual parametric modulator in the fMRI study. The second statistical map contains correlation coefficients for the relationship between gray matter density and behavior. In the case of the patient study, the behavioral measure is the accuracy difference score. We then performed a permutation test by randomizing the subject labels in the patient study ( Nichols & Holmes, 2002 ). On each permutation the following three procedures are performed: 1) the correlation coefficient for the patient study is re-calculated at each voxel using the randomized subject labels; 2) interaction effects are re-calculated by multiplying the new correlation map with the t-map from the fMRI study; and 3) the value of the maximum interaction effect is selected from across all voxels. This procedure was repeated in 10,000 permutations. The value of the maximum interaction statistic at the 95 th -percentile across permutations corresponds to a p-value of 0.05 corrected for whole-brain family-wise error. Note that the statistical map from the fMRI study was held constant across all permutations. This means that the test specifically assesses the probability of finding strong effects in the patient study in voxels where there are also strong effects in the fMRI study. 
 
 
 
 Experiment 3: Structural neuroimaging in healthy adults 
 
 Participants and task 
 These were the participants in the fMRI study in Experiment 1. We analyzed performance on the word-association task (described above). 
 
 
 
 Structural neuroimaging methods 
 
 Structural MRI analysis 
 The images were processed using the same protocol as described in the structural neuroimaging methods section of Experiment 2. 
 
 
 Visual-feature sensitivity analysis 
 We analyzed individual differences in the behavioral performance of healthy adults on the word-association task. As a group, subjects showed a processing advantage for highly visual concepts. This effect was evident in subjects’ response latencies (see Figure 6 for plots of behavioral data). This is a common behavioral finding in studies of lexical-semantic processing and is often referred to as a concreteness effect ( Paivio, 1991 ). For our analysis, we examined individual variability in the strength of this effect. We quantified each subject’s processing advantage for visual concepts by examining the relationship between response latencies and the visual-association strengths of the stimuli. We first filtered the data to remove latencies that were more than two standard deviations from the mean for all experimental conditions within each subject (mean number of trials removed = 8, standard deviation = 1.5). As expected, there was an inverse relationship between response latencies and visual-association ratings in all subjects (i.e., higher visual-association values were associated with shorter response times). Using these data, we calculated a “visual-feature sensitivity” score for each subject. This score was the negative correlation coefficient from a Spearman correlation of response latencies and visual association ratings. A larger value indicates a stronger behavioral advantage for visual relative to abstract concepts. We then used these values to examine the relationship between visual semantic performance and structural neuroanatomy. To do this, we performed a correlation analysis within a region of interest based on the fMRI activation cluster for visual concepts. We also performed a whole-brain regression analysis to identify voxels where gray matter density was related to individual differences in visual-feature sensitivity. 
 
 
 Inter-study similarity analysis 
 We performed an inter-study similarity analysis between Experiments 1 and 3 to test the hypothesis that the whole-brain effects from the structural MRI study in healthy adults were anatomically similar to the fMRI activation effects for visual semantics. This procedure is identical to the inter-study similarity analysis described in Experiment 2, except for the fact that the structural MRI effects in the current analysis are from the individual-differences data in healthy adults (rather than from the patient data). Hence, we performed 10,000 permutations with randomization of subject labels from the structural MRI study of healthy adults and quantified the probability of obtaining strong structural effects in voxels that also exhibited strong effects in the fMRI study. 
 
 
 
 
 RESULTS 
 
 Experiment 1: Visual semantic activation in healthy adults 
 We sought to identify regions where neural activity was modulated by the visual semantic information associated with words. In this fMRI experiment, healthy young adults performed a word association task and a pseudoword letter-matching task. Mean accuracy on the word task was 94.8% ± 4.9. Mean accuracy on the pseudoword task was 98.9% ± 2.6. We first identified regions that were activated overall during the word association task by contrasting the activation for word trials with the activation for pseudoword trials. During the word task, subjects recruited a large network of lexical-semantic regions, as shown  Figure 2  (p < 0.001 voxelwise, cluster-level p < 0.05 corrected for whole-brain family-wise error (FWE) using random field theory ( Worsley, Evans, Marrett, & Neelin, 1992 )). The coordinates for this and all other MRI analyses are listed in  Table 3 . 
 We next examined parametric modulation effects related to the visual, auditory, and motor semantic associations of the stimuli. We found that visual association strength modulated activity in regions of the left ventral-medial temporal lobe ( Fig. 3A ; p < 0.001 voxelwise, cluster-level p < 0.05 whole-brain FWE-corrected). This cluster was centered on the collateral sulcus and parahippocampal cortex and extended into the hippocampus and fusiform gyrus. There were no other significant clusters in this analysis. 
 An analysis of the reverse contrast for the visual parametric modulator showed regions that were more active for abstract concepts. This was associated with activity in a large network of regions, including areas of the lateral temporal and inferior frontal lobes that are commonly implicated in language processing ( Fig. 4 ; p < 0.001 voxelwise, cluster-level p < 0.05 whole-brain FWE-corrected). There were no significant effects for the parametric modulators for auditory and motor associations. 
 These findings suggest that regions of the ventral-medial temporal lobe, including parahippocampal cortex, encode visual semantic information that can be accessed through language. However, a rigorous test of this hypothesis requires corroborating evidence that the representations in this region have functional implications for visual semantic behavior. Specifically, this finding leads to the prediction that atrophy of the ventral-medial temporal lobe will impair visual semantic knowledge. We examine this issue in the next experiment. 
 
 
 Experiment 2: Impaired visual semantic knowledge in patients 
 Using structural MRI we tested the prediction that atrophy of the ventral-medial temporal lobe would result in impaired knowledge of visual concepts. We examined a rare group of patients with svPPA, a focal neurodegenerative disease associated with left-lateralized anterior ventral, medial, and lateral temporal lobe atrophy ( Grossman, 2010 ;  Hodges & Patterson, 2007 ). As a group, the patients in this analysis exhibited a typical pattern of gray matter atrophy for this syndrome ( Fig. 5 ; voxelwise p < 0.05 whole-brain FWE-corrected). In order to assess accuracy on this task we analyzed performance on two categories of items: visual concepts and abstract concepts. Accuracy in age-matched controls was near ceiling (mean on visual concepts = 98.8% ± 0.02 and abstract concepts = 96.5% ± 0.03). Patients were significantly impaired overall (F(1,28) = 76.6, p < 0.001; mean on visual concepts = 77.3% ± 0.16 and abstract concepts = 72.2% ± 0.15), and showed no group-level differences across conditions. There was no main effect for stimulus category (F(1,28) = 3.5, p = 0.07) and no interaction (F(1,28) = 0.52, p = 0.48). T-tests showed better performance for visual relative to abstract concepts in controls (t(21) = 2.4, p = 0.02), which is a common finding ( Paivio, 1991 ). This relative advantage for visual concepts was not significant in patients (t(7) = 0.8, p = 0.44). 
 The patients varied considerably on their relative accuracy for visual and abstract concepts. We used this variability to test the prediction that performance on visual relative to abstract concepts would be related to individual differences in gray matter atrophy of the ventral-medial temporal lobe. In a whole-brain regression analysis, we found a strong relationship between gray matter atrophy in the left ventral-medial temporal lobe and relative performance on visual concepts ( Fig. 3A ; p < 0.001 voxelwise, cluster-level p < 0.05 whole-brain FWE-corrected, adjusted for nonstationarity). This cluster encompassed parahippocampal cortex, the hippocampus, and the collateral sulcus. There were no other significant clusters in this analysis, and there were no significant effects when we performed this contrast in the reverse direction. We also examined a whole-brain regression relating overall accuracy with gray matter atrophy, which detected no significant effects. 
 The finding from the regression with visual semantic performance in svPPA patients partially overlapped with the whole-brain corrected results for the visual parametric modulator in the fMRI study ( Fig. 3A ). This overlap suggests a convergence of anatomic effects in parahippocampal cortex across the fMRI and patient experiments. However, a large portion of the whole-brain corrected cluster from the patient study includes regions that are more medial than those identified in the fMRI experiment. To further assess the overlap across these studies, we performed a whole-brain inter-study similarity analysis. This analysis quantifies the probability of finding strong overlapping effects by randomly permuting the analysis in the patient experiment and then finding the maximum interaction statistic with the fMRI results across all voxels on each permutation. The result is a statistical map corrected for whole-brain family-wise error showing voxels where there are strong effects across both studies. The inter-study similarity analysis revealed a cluster of significantly overlapping effects in a region of the ventral-medial temporal lobe centered on the lateral aspect of parahippocampal cortex ( Fig. 3B ; p < 0.05 whole-brain FWE-corrected; cluster size: 232 μl). 
 Altogether, the findings from the patient experiment indicate a functional role for the ventral-medial temporal lobe in the representation of visual semantic knowledge. In conjunction with the findings from the fMRI study, these results point most consistently to the parahippocampal cortex as a critical region for visual semantics. 
 
 
 Experiment 3: Individual differences in visual semantic processing in healthy adults 
 The above results illustrate a critical relationship between the ventral-medial temporal lobe and knowledge of visual concepts. Here we examine whether individual differences in the neuroanatomy of this region might also relate to the performance of healthy subjects ( Kanai & Rees, 2011 ). As a group, subjects from the fMRI experiment exhibited a performance advantage for visual concepts ( Fig. 6A ), which is a common behavioral finding ( Paivio, 1991 ). However, there was a wide range of individual differences in this effect ( Fig. 6B and C ). We quantified the degree of each subject’s performance advantage for visual concepts by measuring the relationship between their response latencies and the visual-association ratings of the stimuli. This measurement is referred to as each subject’s “visual-feature sensitivity.” We predicted that individual differences in visual-feature sensitivity would be related to individual differences in the gray matter density of parahippocampal cortex. 
 We tested this prediction in a region of interest consisting of the activation cluster for visual semantics from the fMRI experiment ( Fig. 3A ). Within this region, we found a significant relationship between visual-feature sensitivity and the structural anatomy of parahippocampal cortex, whereby increased gray matter density was associated with stronger visual-feature sensitivity scores ( Fig. 6D ; Spearman rho = 0.68, p = 0.002). A whole-brain regression analysis showed no significant effects, but inspection of the uncorrected t-maps showed a trending effect in the ventral-medial temporal lobe. We compared the similarity of these whole-brain effects with those from the fMRI activation results for visual semantics by performing an inter-study similarity analysis. As described above, this analysis quantifies the probability of finding strong overlapping effects across studies. This analysis revealed a cluster of significantly overlapping effects in a region of the ventral-medial temporal lobe centered on the lateral aspect of parahippocampal cortex ( Fig. 6E ; p<0.05 whole-brain FWE-corrected; cluster size: 464 μl). These findings demonstrate that even in the healthy adult brain, individual differences in gray matter structure in parahippocampal cortex are related to individual differences in the processing of visual semantics. 
 
 
 
 DISCUSSION 
 Here we find that visual semantic knowledge relies on information encoded in parahippocampal cortex. In a series of experiments, we observed that the function and structure of parahippocampal cortex are linked to the processing of verbally mediated visual semantic information, and that atrophy encompassing this region is associated with impaired knowledge of visually weighted concepts. These findings suggest that parahippocampal cortex provides a critical neural interface between visual perception and long-term semantic knowledge. 
 The structures of the ventral-medial temporal lobe receive major white matter projections from high-level visual association cortices ( Suzuki, 1996 ;  Suzuki & Amaral, 1994 ), which makes them well suited for processing complex visual information and storing this information in memory ( Murray et al., 2007 ). Consistent with this, previous work has demonstrated the contribution of perirhinal cortex to high-level object representations, which may interface between perception and declarative memory ( Barense et al., 2011 ;  Murray et al., 2007 ). Indeed, perirhinal cortex receives strong projections from visual associations areas TE and TEO in the monkey brain ( Suzuki & Amaral, 1994 ). However, parahippocampal cortex is also strongly connected to high-level visual association cortices—area TF in the monkey receives ~30% of its cortical inputs from area V4 and ~10% from areas TE and TEO ( Suzuki & Amaral, 1994 ). Furthermore, parahippocampal cortex has strong reciprocal connectivity with a large network of regions that support visual, visuospatial, mnemonic, and executive processes ( Lavenex, Suzuki, & Amaral, 2002 ). This pattern of connectivity suggests that parahippocampal cortex processes complex visual information and interacts with a number of high-level cognitive systems. We thus suggest that parahippocampal cortex encodes representations that support our understanding of the visual world across multiple cognitive domains, including language, vision, and long-term memory. 
 Although the medial temporal lobe has traditionally been characterized as supporting the formation of declarative memories ( Scoville & Milner, 1957 ), several lines of work now indicate that this characterization is incomplete. There is a growing consensus that the medial temporal lobe contributes to numerous other cognitive functions, and cognitive theories of the medial temporal lobe may need to reconcile these disparate processes. In addition to memory formation, these medial structures have been linked with aspects of visual perception ( Murray et al., 2007 ), mental imagery ( Buckner & Carroll, 2007 ;  Hassabis & Maguire, 2009 ), spatial perception ( Bird & Burgess, 2008 ), contextual associations ( Aminoff, Kveraga, & Bar, 2013 ), and high-level visual-object representation ( Barense et al., 2011 ). Interestingly, many of these cognitive functions rely strongly on visual information, and it has been suggested that some of these processes recruit a common mechanism for integrating high-level visual representations in perception and memory ( Barense et al., 2011 ;  Buckner & Carroll, 2007 ;  Hassabis & Maguire, 2009 ;  Murray et al., 2007 ). Our findings fit well with such an account, indicating that parahippocampal cortex contributes to knowledge of the visual world. 
 Some previous findings lend support to the hypothesis that parahippocampal cortex encodes semantic information. In fact, parahippocampal cortex is commonly activated in fMRI studies of semantic memory ( Binder et al., 2009 ). Furthermore, a recent study found similar representations of object categories in parahippocampal cortex across both vision and language tasks ( Fairhall & Caramazza, 2013 ). Despite this, few theories of semantic memory have explicitly proposed a role for parahippocampal cortex in conceptual representation ( Binder & Desai, 2011 ;  Martin, 2007 ;  Patterson, Nestor, & Rogers, 2007 ). One recent study found parahippocampal cortex to be activated by multiple sensory associations when subjects were deciding whether single-word concepts referred to things that could be experienced through the senses ( Fernandino et al., 2015 ). The authors of this study propose that parahippocampal cortex functions as a multimodal hub in the semantic system. This is broadly consistent with our findings, with the exception that we did not find parahippocampal cortex to be modulated by non-visual features. This exception may be related to the mental imagery demands of their task, which may elicit a stronger embodiment effect than that elicited by our semantic association task. Nonetheless, the diverse connectivity of parahippocampal cortex indicates that it contains information from modalities outside of vision, and our hypothesis is that its semantic representations are strongly weighted in the visual modality but are not solely visual in nature. It will be of interest in future work to examine the interaction of task demands and the modalities of information represented in parahippocampal cortex. 
 Another model with possible implications for semantic memory theories is the contextual-association model, which proposes that parahippocampal cortex encodes the contextual associations of objects in both vision and episodic memory ( Aminoff et al., 2013 ). Although we did not specifically probe contextual relationships in this study, our anatomic results are similar to those observed in studies of contextual associations in vision. Considering our findings and previous work implicating parahippocampal cortex in lexical semantics, it appears that the information encoded by this region is not specifically tied to context but, rather, encompasses the semantics of the visual environment more broadly. 
 As with many semantic effects, the semantic activation of parahippocampal cortex is likely modulated by task demands ( Binder & Desai, 2011 ). Simple lexical tasks may engage only brief and sparse semantic representations that are difficult to observe with fMRI, whereas tasks involving explicit semantic judgments likely elicit stronger and more sustained activation of the semantic network. Indeed, activation of parahippocampal cortex has not always been observed in studies of concrete or visual semantics when using simple lexical-decision tasks ( Binder et al., 2005 ;  Bonner et al., 2013 ). Here we used a task requiring explicit retrieval of semantic knowledge, which may have been helpful in detecting the contribution of parahippocampal cortex to conceptual processing. 
 It is worth noting that our findings do not indicate a simple embodiment of semantic knowledge through explicit simulations of perceptual processes ( Caramazza, Anzellotti, Strnad, & Lingnau, 2014 ;  Chatterjee, 2010 ). Rather, these findings are consistent with the idea that representations at the highest levels of the ventral visual system encode abstract stimulus associations learned over a lifetime of experience ( Khaligh-Razavi & Kriegeskorte, 2014 ;  Peelen & Caramazza, 2012 ;  Sha et al., 2014 ;  Stansbury, Naselaris, & Gallant, 2013 ), and that such representations may be accessible through modalities other than vision ( Fairhall & Caramazza, 2013 ;  Mahon, Anzellotti, Schwarzbach, Zampini, & Caramazza, 2009 ). Because these cortical regions encode more information than could be extracted from any given perceptual episode, the distinction between visual-perceptual processes and abstract-conceptual processes becomes blurred. In the same sense, these considerations blur the distinction between embodied and amodal theoretical accounts for our findings. Therefore, we suggest that rather than focusing on the degree to which semantic content is embodied or amodal in nature, a more useful direction for future work is to begin characterizing the computational properties that underlie such visuo-semantic representations ( Khaligh-Razavi & Kriegeskorte, 2014 ). 
 Previous studies of svPPA have reported relative impairments for concrete concepts ( Bonner et al., 2009 ;  Breedin, Saffran, & Coslett, 1994 ;  Warrington, 1975 ) or for highly visual object concepts in particular ( Hoffman, Jones, & Ralph, 2012 ), but there have also been exceptions noted ( Hoffman & Lambon Ralph, 2011 ). One other study of these patients has related impairments in object semantics to an adjacent potion of the ventral-medial temporal lobe, the anterior fusiform gyrus ( Mion et al., 2010 ). Other work has related object knowledge deficits in part to disease in the right anterior temporal lobe ( Lambon Ralph, Cipolotti, Manes, & Patterson, 2010 ;  Lambon Ralph, McClelland, Patterson, Galton, & Hodges, 2001 ), although we did not find evidence implicating right hemisphere regions in our studies. The results of our experiments suggest another anatomic explanation that may reconcile these apparently disparate findings. Although patients with svPPA have often been examined as a group, these patients in fact differ somewhat in the anatomic extent of their disease. The differences in cognitive findings across studies may be explained in part by differences in the underlying brain atrophy of the patients. Indeed, it has previously been suggested that individual variability in visual semantic impairments in svPPA can be accounted for by the degree of atrophy in more posterior ventral temporal regions ( Hoffman et al., 2012 ;  Hoffman & Lambon Ralph, 2010 ). The findings from our study appear to bear this out. 
 We found that individual differences in the structure of parahippocampal cortex in healthy adults are related to individual differences in the processing of visual semantic knowledge. Although previous work has indicated that individual differences in brain structure are related to variations in behavioral performance in healthy adults, this work has not focused on differences in semantic memory ( Kanai & Rees, 2011 ). Semantic representations are often assumed to be highly similar across individuals, which is, to some extent, a prerequisite for a shared language. However, the findings from this study indicate that there may indeed be relevant individual variations in structural neuroanatomy that relate to behavioral differences in semantic-memory processing. It will be of interest in future studies to further explore how neuroanatomic differences in healthy adults can account for individual variability in semantic-memory performance. 
 It is important to note that of the three studies presented here, only the fMRI study directly tested for neural correlates that were uniquely associated with the visual-semantic modality and not the auditory or motor modalities. The patient and individual-differences studies directly contrasted visual and abstract semantics, and though the results are consistent with the fMRI findings, we emphasize that the analyses are not as specific as in the fMRI study. We also note that the distribution of feature ratings differed somewhat across modalities (as can be seen in  Fig. 1 ). In particular, the ratings for the visual modality were distributed more evenly across the full range, whereas the distributions of the auditory and motor ratings had larger proportions at the lower end of the scale. These differences may have contributed to the stronger effects for the visual modality and the lack of significant findings for the auditory and motor modalities. 
 Finally, it is important to emphasize that visual information is only one of many feature dimensions in semantic memory. Indeed, most concepts comprise a rich network of other sensory, motor, affective and abstract feature associations ( Bonner & Grossman, 2012 ;  Kemmerer, Castillo, Talavage, Patterson, & Wiley, 2008 ;  Leshinskaya & Caramazza, 2014 ;  Reilly, Peelle, Garcia, & Crutch, In press ;  Skipper & Olson, 2014 ) and may additionally rely on higher-level heteromodal association cortices, such as the angular gyrus and regions of the anterior temporal lobe, for binding and integrating these features ( Binder & Desai, 2011 ;  Bonner et al., 2013 ;  Patterson et al., 2007 ;  Price, Bonner, Peelle, & Grossman, 2015 ). Furthermore, semantic memory encompasses a broad range of relationships among concepts, including both taxonomic associations (e.g., similar category membership) and thematic associations (e.g., complementary roles in an event). The studies presented here have not examined the possible differential roles of taxonomic or thematic information, and it will be important in future work to quantify how categories of semantic features and relationships interact. 
 In summary, our findings indicate that parahippocampal cortex is critical for representing semantic knowledge of the visual environment, and they are consistent with the hypothesis that the ventral-medial temporal lobe encodes visual-mnemonic representations across multiple cognitive domains, linking the perceptual world with declarative-memory systems in the human brain. 
 
 
 
 
 
 
 
 Aminoff 
 EM 
 
 
 Kveraga 
 K 
 
 
 Bar 
 M 
 
 
 2013 
 The role of the parahippocampal cortex in cognition 
 Trends in Cognitive Sciences 
 17 
 8 
 379 
 390 
 23850264 
 
 
 
 
 
 
 Ashburner 
 J 
 
 
 Friston 
 K 
 
 
 1997 
 Multimodal Image Coregistration and Partitioning--A Unified Framework 
 Neuroimage 
 6 
 3 
 209 
 217 
 9344825 
 
 
 
 
 
 
 Ashburner 
 J 
 
 
 Friston 
 KJ 
 
 
 2005 
 Unified segmentation 
 NeuroImage 
 26 
 3 
 839 
 851 
 15955494 
 
 
 
 
 
 
 Avants 
 BB 
 
 
 Epstein 
 CL 
 
 
 Grossman 
 M 
 
 
 Gee 
 JC 
 
 
 2008 
 Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain 
 Medical Image Analysis 
 12 
 1 
 26 
 41 
 17659998 
 
 
 
 
 
 
 Barense 
 MD 
 
 
 Henson 
 RN 
 
 
 Graham 
 KS 
 
 
 2011 
 Perception and conception: temporal lobe activity during complex discriminations of familiar and novel faces and objects 
 Journal of Cognitive Neuroscience 
 23 
 10 
 3052 
 3067 
 21391761 
 
 
 
 
 
 
 Binder 
 J 
 
 
 Desai 
 R 
 
 
 2011 
 The neurobiology of semantic memory 
 Trends in Cognitive Sciences 
 15 
 11 
 527 
 536 
 22001867 
 
 
 
 
 
 
 Binder 
 J 
 
 
 Desai 
 R 
 
 
 Graves 
 W 
 
 
 Conant 
 L 
 
 
 2009 
 Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies 
 Cerebral Cortex 
 19 
 12 
 2767 
 2796 
 19329570 
 
 
 
 
 
 
 Binder 
 JR 
 
 
 Westbury 
 CF 
 
 
 McKiernan 
 KA 
 
 
 Possing 
 ET 
 
 
 Medler 
 DA 
 
 
 2005 
 Distinct brain systems for processing concrete and abstract concepts 
 Journal of Cognitive Neuroscience 
 17 
 905 
 917 
 16021798 
 
 
 
 
 
 
 Bird 
 CM 
 
 
 Burgess 
 N 
 
 
 2008 
 The hippocampus and memory: Insights from spatial processing 
 Nature Reviews Neuroscience 
 9 
 3 
 182 
 194 
 18270514 
 
 
 
 
 
 
 Bonner 
 MF 
 
 
 Ash 
 S 
 
 
 Grossman 
 M 
 
 
 2010 
 The new classification of primary progressive aphasia into semantic, logopenic, or nonfluent/agrammatic variants 
 Current Neurology and Neuroscience Reports 
 10 
 6 
 484 
 490 
 20809401 
 
 
 
 
 
 
 Bonner 
 MF 
 
 
 Grossman 
 M 
 
 
 2012 
 Gray matter density of auditory association cortex relates to knowledge of sound concepts in primary progressive aphasia 
 The Journal of Neuroscience 
 32 
 23 
 7986 
 7991 
 22674273 
 
 
 
 
 
 
 Bonner 
 MF 
 
 
 Peelle 
 JE 
 
 
 Cook 
 PA 
 
 
 Grossman 
 M 
 
 
 2013 
 Heteromodal conceptual processing in the angular gyrus 
 Neuroimage 
 71 
 0 
 175 
 186 
 23333416 
 
 
 
 
 
 
 Bonner 
 MF 
 
 
 Vesely 
 L 
 
 
 Price 
 C 
 
 
 Anderson 
 C 
 
 
 Richmond 
 L 
 
 
 Farag 
 C 
 
 
 
 2009 
 Reversal of the concreteness effect in semantic dementia 
 Cognitive Neuropsychology 
 26 
 568 
 579 
 20183015 
 
 
 
 
 
 
 Breedin 
 SD 
 
 
 Saffran 
 EM 
 
 
 Coslett 
 HB 
 
 
 1994 
 Reversal of the concreteness effect in a patient with semantic dementia 
 Cognitive Neuropsychology 
 11 
 6 
 617 
 660 
 
 
 
 
 
 
 Buckner 
 RL 
 
 
 Carroll 
 DC 
 
 
 2007 
 Self-projection and the brain 
 Trends in Cognitive Sciences 
 11 
 2 
 49 
 57 
 17188554 
 
 
 
 
 
 
 Bussey 
 TJ 
 
 
 Saksida 
 LM 
 
 
 2007 
 Memory, perception, and the ventral visual-perirhinal-hippocampal stream: Thinking outside of the boxes 
 Hippocampus 
 17 
 9 
 898 
 908 
 17636546 
 
 
 
 
 
 
 Caramazza 
 A 
 
 
 Anzellotti 
 S 
 
 
 Strnad 
 L 
 
 
 Lingnau 
 A 
 
 
 2014 
 Embodied cognition and mirror neurons: a critical assessment 
 Annual Review of Neuroscience 
 37 
 1 
 15 
 
 
 
 
 
 
 Chatterjee 
 A 
 
 
 2010 
 Disembodying cognition 
 Language and Cognition 
 2 
 1 
 79 
 116 
 20802833 
 
 
 
 
 
 
 Coltheart 
 M 
 
 
 1981 
 The MRC Psycholinguistic database 
 Quarterly Journal of Experimental Psychology 
 33 
 a 
 497 
 505 
 
 
 
 
 
 
 Csernansky 
 JG 
 
 
 Gillespie 
 SK 
 
 
 Dierker 
 DL 
 
 
 Anticevic 
 A 
 
 
 Wang 
 L 
 
 
 Barch 
 DM 
 
 
 
 2008 
 Symmetric abnormalities in sulcal patterning in schizophrenia 
 Neuroimage 
 43 
 3 
 440 
 446 
 18707008 
 
 
 
 
 
 
 Fairhall 
 SL 
 
 
 Caramazza 
 A 
 
 
 2013 
 Brain regions that represent amodal conceptual knowledge 
 The Journal of Neuroscience 
 33 
 25 
 10552 
 10558 
 23785167 
 
 
 
 
 
 
 Fernandino 
 L 
 
 
 Binder 
 JR 
 
 
 Desai 
 RH 
 
 
 Pendl 
 SL 
 
 
 Humphries 
 CJ 
 
 
 Gross 
 WL 
 
 
 
 2015 
 Concept Representation Reflects Multimodal Abstraction: A Framework for Embodied Semantics 
 Cerebral Cortex 
 
 
 
 
 
 
 Folstein 
 MF 
 
 
 Folstein 
 SF 
 
 
 McHugh 
 PR 
 
 
 1975 
 “Mini Mental State.” A practical method for grading the cognitive state of patients for the clinician 
 Journal of Psychiatric Research 
 12 
 189 
 198 
 1202204 
 
 
 
 
 
 
 Francis 
 WN 
 
 
 Kucera 
 H 
 
 
 1982 
 The frequency analysis of English usage 
 Boston 
 Houghton-Mifflin Co 
 
 
 
 
 
 
 Friston 
 KJ 
 
 
 Ashburner 
 J 
 
 
 Frith 
 CD 
 
 
 Poline 
 JB 
 
 
 Heather 
 JD 
 
 
 Frackowiak 
 RSJ 
 
 
 1995 
 Spatial registration and normalization of images 
 Human Brain Mapping 
 3 
 3 
 165 
 189 
 
 
 
 
 
 
 Gilhooly 
 KJ 
 
 
 Logie 
 RH 
 
 
 1980 
 Age-of-acquisition, imagery, concreteness, familiarity, and ambiguity measures for 1,944 words 
 Behavior Research Methods & Instrumentation 
 12 
 4 
 395 
 427 
 
 
 
 
 
 
 Gorno-Tempini 
 ML 
 
 
 Hillis 
 AE 
 
 
 Weintraub 
 S 
 
 
 Kertesz 
 A 
 
 
 Mendez 
 M 
 
 
 Cappa 
 SF 
 
 
 
 2011 
 Classification of primary progressive aphasia and its variants 
 Neurology 
 76 
 11 
 1006 
 1014 
 21325651 
 
 
 
 
 
 
 Grossman 
 M 
 
 
 2010 
 Primary progressive aphasia: clinicopathological correlations 
 Nature Reviews Neurology 
 6 
 88 
 97 
 20139998 
 
 
 
 
 
 
 Hassabis 
 D 
 
 
 Maguire 
 EA 
 
 
 2009 
 The construction system of the brain 
 Philosophical Transactions of the Royal Society B: Biological Sciences 
 364 
 1521 
 1263 
 1271 
 
 
 
 
 
 
 Hill 
 J 
 
 
 Inder 
 T 
 
 
 Neil 
 J 
 
 
 Dierker 
 D 
 
 
 Harwell 
 J 
 
 
 Van Essen 
 D 
 
 
 2010 
 Similar patterns of cortical expansion during human development and evolution 
 Proceedings of the National Academy of Sciences 
 107 
 29 
 13135 
 13140 
 
 
 
 
 
 
 Hodges 
 JR 
 
 
 Patterson 
 K 
 
 
 2007 
 Semantic dementia: a unique clinicopathological syndrome 
 Lancet Neurology 
 6 
 11 
 1004 
 1014 
 17945154 
 
 
 
 
 
 
 Hodges 
 JR 
 
 
 Patterson 
 K 
 
 
 Oxbury 
 S 
 
 
 Funnell 
 E 
 
 
 1992 
 Semantic dementia: progressive fluent aphasia with temporal lobe atrophy 
 Brain 
 115 
 1783 
 1806 
 1486461 
 
 
 
 
 
 
 Hoffman 
 P 
 
 
 Jones 
 RW 
 
 
 Ralph 
 MA 
 
 
 2012 
 The degraded concept representation system in semantic dementia: damage to pan-modal hub, then visual spoke 
 Brain 
 135 
 Pt 12 
 3770 
 3780 
 23250888 
 
 
 
 
 
 
 Hoffman 
 P 
 
 
 Lambon Ralph 
 MA 
 
 
 2010 
 Reverse Concreteness Effects Are Not a Typical Feature of Semantic Dementia: Evidence for the Hub-and-Spoke Model of Conceptual Representation 
 Cerebral Cortex 
 
 
 
 
 
 
 Hoffman 
 P 
 
 
 Lambon Ralph 
 MA 
 
 
 2011 
 Reverse concreteness effects are not a typical feature of semantic dementia: evidence for the hub-and-spoke model of conceptual representation 
 Cerebral Cortex 
 21 
 9 
 2103 
 2112 
 21285258 
 
 
 
 
 
 
 Howard 
 D 
 
 
 Patterson 
 K 
 
 
 1992 
 Pyramids and Palm Trees: A Test of Semantic Access from Pictures and Words 
 Bury St. Edmonds 
 Thames Valley Test Co 
 
 
 
 
 
 
 Kanai 
 R 
 
 
 Rees 
 G 
 
 
 2011 
 The structural basis of inter-individual differences in human behaviour and cognition 
 Nature Reviews Neuroscience 
 12 
 4 
 231 
 242 
 
 
 
 
 
 
 Kemmerer 
 D 
 
 
 Castillo 
 JG 
 
 
 Talavage 
 T 
 
 
 Patterson 
 S 
 
 
 Wiley 
 C 
 
 
 2008 
 Neuroanatomical distribution of five semantic components of verbs: evidence from fMRI 
 Brain and Language 
 107 
 16 
 43 
 17977592 
 
 
 
 
 
 
 Khaligh-Razavi 
 SM 
 
 
 Kriegeskorte 
 N 
 
 
 2014 
 Deep Supervised, but Not Unsupervised, Models May Explain IT Cortical Representation 
 PLoS Comput Biol 
 10 
 11 
 e1003915 
 25375136 
 
 
 
 
 
 
 Kravitz 
 DJ 
 
 
 Saleem 
 KS 
 
 
 Baker 
 CI 
 
 
 Ungerleider 
 LG 
 
 
 Mishkin 
 M 
 
 
 2013 
 The ventral visual pathway: An expanded neural framework for the processing of object quality 
 Trends in Cognitive Sciences 
 17 
 1 
 26 
 49 
 23265839 
 
 
 
 
 
 
 Lambon Ralph 
 MA 
 
 
 Cipolotti 
 L 
 
 
 Manes 
 F 
 
 
 Patterson 
 K 
 
 
 2010 
 Taking both sides: do unilateral anterior temporal lobe lesions disrupt semantic memory? 
 Brain 
 133 
 3243 
 3255 
 20952378 
 
 
 
 
 
 
 Lambon Ralph 
 MA 
 
 
 McClelland 
 JL 
 
 
 Patterson 
 K 
 
 
 Galton 
 CJ 
 
 
 Hodges 
 JR 
 
 
 2001 
 No right to speak? The relationship between object naming and semantic impairment: Neuropsychological evidence and a computational model 
 Journal of Cognitive Neuroscience 
 13 
 3 
 341 
 356 
 11371312 
 
 
 
 
 
 
 Lavenex 
 P 
 
 
 Suzuki 
 WA 
 
 
 Amaral 
 DG 
 
 
 2002 
 Perirhinal and parahippocampal cortices of the macaque monkey: Projections to the neocortex 
 Journal of Comparative Neurology 
 447 
 4 
 394 
 420 
 11992524 
 
 
 
 
 
 
 Leshinskaya 
 A 
 
 
 Caramazza 
 A 
 
 
 2014 
 Nonmotor Aspects of Action Concepts 
 Journal of Cognitive Neuroscience 
 26 
 12 
 2863 
 2879 
 24960046 
 
 
 
 
 
 
 Libon 
 DJ 
 
 
 Rascovsky 
 K 
 
 
 Gross 
 RG 
 
 
 White 
 MT 
 
 
 Xie 
 SX 
 
 
 Dreyfuss 
 M 
 
 
 
 2011 
 The Philadelphia Brief Assessment of Cognition (PBAC): a validated screening measure for dementia 
 Clin Neuropsychol 
 25 
 8 
 1314 
 1330 
 22084867 
 
 
 
 
 
 
 Mahon 
 BZ 
 
 
 Anzellotti 
 S 
 
 
 Schwarzbach 
 J 
 
 
 Zampini 
 M 
 
 
 Caramazza 
 A 
 
 
 2009 
 Category-Specific Organization in the Human Brain Does Not Require Visual Experience 
 Neuron 
 63 
 3 
 397 
 405 
 19679078 
 
 
 
 
 
 
 Martin 
 A 
 
 
 2007 
 The representation of object concepts in the brain 
 Annual Review of Psychology 
 58 
 25 
 45 
 
 
 
 
 
 
 Mion 
 M 
 
 
 Patterson 
 K 
 
 
 Acosta-Cabronero 
 J 
 
 
 Pengas 
 G 
 
 
 Izquierdo-Garcia 
 D 
 
 
 Hong 
 YT 
 
 
 
 2010 
 What the left and right anterior fusiform gyri tell us about semantic memory 
 Brain 
 133 
 11 
 3256 
 3268 
 20952377 
 
 
 
 
 
 
 Murray 
 EA 
 
 
 Bussey 
 TJ 
 
 
 Saksida 
 LM 
 
 
 2007 
 Visual perception and memory: a new view of medial temporal lobe function in primates and rodents 
 Annual Review of Neuroscience 
 30 
 99 
 122 
 
 
 
 
 
 
 Nichols 
 TE 
 
 
 Holmes 
 AP 
 
 
 2002 
 Nonparametric permutation tests for functional neuroimaging: a primer with examples 
 Human Brain Mapping 
 15 
 1 
 1 
 25 
 11747097 
 
 
 
 
 
 
 Paivio 
 A 
 
 
 1991 
 Images in mind: The evolution of a theory 
 Hertfordshire, HP2 7EZ, England 
 Harvester Wheatsheaf 
 
 
 
 
 
 
 Paivio 
 A 
 
 
 Yuille 
 JC 
 
 
 Madigan 
 SA 
 
 
 1968 
 Concreteness, imagery, and meaningfulness: Values for 925 nouns 
 American Psychological Association 
 
 
 
 
 
 
 Patterson 
 K 
 
 
 Nestor 
 P 
 
 
 Rogers 
 T 
 
 
 2007 
 Where do you know what you know? The representation of semantic knowledge in the human brain 
 Nature Reviews Neuroscience 
 8 
 976 
 987 
 18026167 
 
 
 
 
 
 
 Peelen 
 MV 
 
 
 Caramazza 
 A 
 
 
 2012 
 Conceptual object representations in human anterior temporal cortex 
 The Journal of Neuroscience 
 32 
 45 
 15728 
 15736 
 23136412 
 
 
 
 
 
 
 Peelle 
 JE 
 
 
 Cusack 
 R 
 
 
 Henson 
 RN 
 
 
 2012 
 Adjusting for global effects in voxel-based morphometry: gray matter decline in normal aging 
 Neuroimage 
 60 
 2 
 1503 
 1516 
 22261375 
 
 
 
 
 
 
 Price 
 AR 
 
 
 Bonner 
 MF 
 
 
 Peelle 
 JE 
 
 
 Grossman 
 M 
 
 
 2015 
 Converging evidence for the neuroanatomic basis of combinatorial semantics in the angular gyrus 
 Journal of Neuroscience 
 35 
 7 
 3276 
 3284 
 25698762 
 
 
 
 
 
 
 Reilly 
 J 
 
 
 Peelle 
 JE 
 
 
 Garcia 
 A 
 
 
 Crutch 
 SJ 
 
 
 In press 
 Linking somatic and symbolic representation in semantic memory: The dynamic multilevel reactivation framework 
 Psychonomic Bulletin and Review 
 
 
 
 
 
 
 Sabsevitz 
 DS 
 
 
 Medler 
 DA 
 
 
 Seidenberg 
 M 
 
 
 Binder 
 JR 
 
 
 2005 
 Modulation of the semantic system by word imageability 
 Neuroimage 
 27 
 1 
 188 
 200 
 15893940 
 
 
 
 
 
 
 Scott 
 DW 
 
 
 2015 
 Multivariate density estimation: theory, practice, and visualization 
 John Wiley & Sons 
 
 
 
 
 
 
 Scoville 
 WB 
 
 
 Milner 
 B 
 
 
 1957 
 Loss of recent memory after bilateral hippocampal lesions 
 Journal of Neurology, Neurosurgery and Psychiatry 
 20 
 1 
 11 
 21 
 
 
 
 
 
 
 Sha 
 L 
 
 
 Haxby 
 JV 
 
 
 Abdi 
 H 
 
 
 Guntupalli 
 JS 
 
 
 Oosterhof 
 NN 
 
 
 Halchenko 
 YO 
 
 
 
 2014 
 The Animacy Continuum in the Human Ventral Vision Pathway 
 Journal of Cognitive Neuroscience 
 1 
 14 
 24047384 
 
 
 
 
 
 
 Skipper 
 LM 
 
 
 Olson 
 IR 
 
 
 2014 
 Semantic memory: distinct neural representations for abstractness and valence 
 Brain and Language 
 130 
 1 
 10 
 24561187 
 
 
 
 
 
 
 Stansbury 
 D 
 
 
 Naselaris 
 T 
 
 
 Gallant 
 J 
 
 
 2013 
 Natural Scene Statistics Account for the Representation of Scene Categories in Human Visual Cortex 
 Neuron 
 79 
 5 
 1025 
 1034 
 23932491 
 
 
 
 
 
 
 Suzuki 
 WA 
 
 
 1996 
 Neuroanatomy of the monkey entorhinal, perirhinal and parahippocampal cortices: Organization of cortical inputs and interconnections with amygdala and striatum 
 Seminars in Neuroscience 
 8 
 1 
 3 
 12 
 
 
 
 
 
 
 Suzuki 
 WL 
 
 
 Amaral 
 DG 
 
 
 1994 
 Perirhinal and parahippocampal cortices of the macaque monkey: Cortical afferents 
 The Journal of Comparative Neurology 
 350 
 4 
 497 
 533 
 7890828 
 
 
 
 
 
 
 Thompson-Schill 
 SL 
 
 
 Aguirre 
 G 
 
 
 D’Esposito 
 M 
 
 
 Farah 
 MJ 
 
 
 1999 
 A neural basis for category and modality specificity of semantic knowledge 
 Neuropsychologia 
 37 
 671 
 676 
 10390028 
 
 
 
 
 
 
 Tustison 
 NJ 
 
 
 Avants 
 BB 
 
 
 Cook 
 PA 
 
 
 Yuanjie 
 Z 
 
 
 Egan 
 A 
 
 
 Yushkevich 
 PA 
 
 
 
 2010 
 N4ITK: Improved N3 Bias Correction 
 Medical Imaging, IEEE Transactions on 
 29 
 6 
 1310 
 1320 
 
 
 
 
 
 
 Tyler 
 LK 
 
 
 Stamatakis 
 EA 
 
 
 Bright 
 P 
 
 
 Acres 
 K 
 
 
 Abdallah 
 S 
 
 
 Rodd 
 J 
 
 
 
 2004 
 Processing objects at different levels of specificity 
 Journal of Cognitive Neuroscience 
 16 
 3 
 351 
 362 
 15072671 
 
 
 
 
 
 
 Van Essen 
 DC 
 
 
 Dierker 
 D 
 
 
 Snyder 
 AZ 
 
 
 Raichle 
 ME 
 
 
 Reiss 
 AL 
 
 
 Korenberg 
 J 
 
 
 2006 
 Symmetry of cortical folding abnormalities in Williams syndrome revealed by surface-based analyses 
 Journal of Neuroscience 
 26 
 20 
 5470 
 5483 
 16707799 
 
 
 
 
 
 
 Wang 
 J 
 
 
 Conder 
 JA 
 
 
 Blitzer 
 DN 
 
 
 Shinkareva 
 SV 
 
 
 2010 
 Neural representation of abstract and concrete concepts: a meta-analysis of neuroimaging studies 
 Human Brain Mapping 
 31 
 10 
 1459 
 1468 
 20108224 
 
 
 
 
 
 
 Warrington 
 EK 
 
 
 1975 
 The selective impairment of semantic memory 
 Quarterly Journal of Experimental Psychology 
 27 
 635 
 657 
 1197619 
 
 
 
 
 
 
 Wise 
 RJS 
 
 
 Howard 
 D 
 
 
 Mummery 
 CJ 
 
 
 Fletcher 
 P 
 
 
 Leff 
 A 
 
 
 Büchel 
 C 
 
 
 
 2000 
 Noun imageability and the temporal lobes 
 Neuropsychologia 
 38 
 7 
 985 
 994 
 10775709 
 
 
 
 
 
 
 Worsley 
 KJ 
 
 
 Evans 
 AC 
 
 
 Marrett 
 S 
 
 
 Neelin 
 P 
 
 
 1992 
 A three-dimensional statistical analysis for CBF activation studies in human brain 
 Journal of Cerebral Blood Flow and Metabolism 
 12 
 6 
 900 
 918 
 1400644 
 
 
 
 
 
 Appendix A 
 
 
 
 
 Category 
 Index 
 Target 
 Foil 
 
 
 
 
 abstract 
 prediction 
 foresight 
 loyalty 
 
 
 abstract 
 upkeep 
 preservation 
 weekend 
 
 
 abstract 
 internship 
 employee 
 hindrance 
 
 
 abstract 
 solution 
 dilemma 
 voyage 
 
 
 abstract 
 luck 
 lottery 
 honor 
 
 
 abstract 
 skill 
 vocation 
 strife 
 
 
 abstract 
 creed 
 dogma 
 budget 
 
 
 abstract 
 greed 
 wealth 
 paradox 
 
 
 abstract 
 analogy 
 metaphor 
 menace 
 
 
 abstract 
 crime 
 bribe 
 origin 
 
 
 abstract 
 chore 
 task 
 cult 
 
 
 abstract 
 motive 
 behavior 
 enigma 
 
 
 abstract 
 burden 
 affliction 
 sequel 
 
 
 abstract 
 charity 
 donation 
 pact 
 
 
 abstract 
 testimony 
 perjury 
 fetish 
 
 
 abstract 
 merit 
 qualification 
 pacifism 
 
 
 abstract 
 synopsis 
 anecdote 
 allegory 
 
 
 abstract 
 saga 
 epic 
 proxy 
 
 
 abstract 
 apathy 
 malaise 
 protocol 
 
 
 abstract 
 fate 
 soul 
 gist 
 
 
 abstract 
 satire 
 drama 
 fraud 
 
 
 abstract 
 guilt 
 grief 
 heir 
 
 
 auditory 
 engine 
 propeller 
 rattlesnake 
 
 
 auditory 
 thunder 
 downpour 
 rocket 
 
 
 auditory 
 choir 
 orchestra 
 waterfall 
 
 
 auditory 
 parrot 
 rooster 
 airplane 
 
 
 auditory 
 dog 
 wolf 
 jet 
 
 
 auditory 
 siren 
 ambulance 
 festival 
 
 
 auditory 
 lullaby 
 baby 
 volcano 
 
 
 auditory 
 alarm 
 buzzer 
 symphony 
 
 
 auditory 
 applause 
 speech 
 avalanche 
 
 
 auditory 
 fireworks 
 celebration 
 subway 
 
 
 auditory 
 singer 
 jukebox 
 storm 
 
 
 auditory 
 opera 
 musician 
 heartbeat 
 
 
 auditory 
 dialogue 
 conversation 
 chime 
 
 
 auditory 
 stereo 
 television 
 infant 
 
 
 auditory 
 riot 
 uproar 
 melody 
 
 
 auditory 
 cricket 
 cicada 
 concert 
 
 
 auditory 
 belch 
 hiccup 
 noise 
 
 
 auditory 
 ruckus 
 commotion 
 narration 
 
 
 auditory 
 gunshot 
 dynamite 
 song 
 
 
 auditory 
 circus 
 laughter 
 carol 
 
 
 auditory 
 foghorn 
 ocean 
 arcade 
 
 
 auditory 
 utterance 
 announcement 
 melody 
 
 
 manipulable 
 pencil 
 crayon 
 spoon 
 
 
 manipulable 
 hairbrush 
 comb 
 clay 
 
 
 manipulable 
 syringe 
 scalpel 
 cigar 
 
 
 manipulable 
 key 
 doorknob 
 shoelace 
 
 
 manipulable 
 fork 
 chopsticks 
 drumstick 
 
 
 manipulable 
 chisel 
 screwdriver 
 lipstick 
 
 
 manipulable 
 shovel 
 pitchfork 
 lighter 
 
 
 manipulable 
 sword 
 spear 
 cup 
 
 
 manipulable 
 calculator 
 computer 
 utensil 
 
 
 manipulable 
 chess 
 checkers 
 corkscrew 
 
 
 manipulable 
 spatula 
 ladle 
 camera 
 
 
 manipulable 
 cigarette 
 pipe 
 handle 
 
 
 manipulable 
 tissue 
 handkerchief 
 flashlight 
 
 
 manipulable 
 axe 
 hatchet 
 tape 
 
 
 manipulable 
 wheelchair 
 crutch 
 knife 
 
 
 manipulable 
 razor 
 brush 
 kite 
 
 
 manipulable 
 chalk 
 eraser 
 dart 
 
 
 manipulable 
 rope 
 knot 
 tool 
 
 
 manipulable 
 scissors 
 stapler 
 arrow 
 
 
 manipulable 
 paperclip 
 thumbtack 
 dough 
 
 
 manipulable 
 soap 
 sponge 
 cane 
 
 
 manipulable 
 ball 
 toy 
 lever 
 
 
 visual 
 carrot 
 potato 
 lightbulb 
 
 
 visual 
 penguin 
 turtle 
 blueberry 
 
 
 visual 
 building 
 elevator 
 tombstone 
 
 
 visual 
 diamond 
 gold 
 lake 
 
 
 visual 
 lemon 
 pineapple 
 scorpion 
 
 
 visual 
 corn 
 sandwich 
 raft 
 
 
 visual 
 balloon 
 confetti 
 zebra 
 
 
 visual 
 trophy 
 ribbon 
 apple 
 
 
 visual 
 necklace 
 bracelet 
 broccoli 
 
 
 visual 
 raincoat 
 parka 
 crown 
 
 
 visual 
 cactus 
 tree 
 brick 
 
 
 visual 
 tent 
 igloo 
 tire 
 
 
 visual 
 newspaper 
 magazine 
 noodle 
 
 
 visual 
 snail 
 slug 
 bread 
 
 
 visual 
 pyramid 
 desert 
 salad 
 
 
 visual 
 mountain 
 boulder 
 chocolate 
 
 
 visual 
 fence 
 lawn 
 peach 
 
 
 visual 
 chimney 
 roof 
 refrigerator 
 
 
 visual 
 candle 
 lantern 
 daffodil 
 
 
 visual 
 lamp 
 sofa 
 gravel 
 
 
 visual 
 submarine 
 whale 
 cupcake 
 
 
 visual 
 trashcan 
 dumpster 
 butterfly 
 
 
 
 
 
 
 
 
 
 Figure 1 
 
 Distributions and scatter plots of feature ratings for all word stimuli. Feature ratings were on a 0 to 6 scale. Plots in the off-diagonal cells show pairwise relationships between modalities of feature ratings. Plots in the on-diagonal cells illustrate the distributions of feature ratings for each modality. 
 
 
 
 
 Figure 2 
 
 Overall fMRI activation for the word association task in healthy young adults. This is the activation for all word-association trials relative to a baseline condition in which subjects performed a letter-matching task with pronounceable pseudowords. 
 
 
 
 
 Figure 3 
 
 Converging neuroanatomic findings for visual semantic processing in functional and structural MRI.  (A)  The fMRI experiment revealed one significant cluster, located in the ventral-medial temporal lobe, in which activation was parametrically modulated by the visual associations of concepts (light blue cluster). The structural MRI experiment in patients revealed one significant cluster, also in the ventral-medial temporal lobe, in which gray matter atrophy was strongly associated with a specific impairment on visual semantics (green cluster). This finding partially overlapped with the whole-brain corrected cluster identified in the fMRI experiment of healthy adults (overlap shown in dark blue).  (B)  An inter-study similarity analysis was performed to statistically assess the overlap of findings across the two studies (see Methods for details). This analysis quantifies the probability of finding overlapping effects by randomly permuting the analysis in the patient experiment and then finding the maximum interaction statistic with the fMRI study across all voxels on each permutation. The result is a statistical map corrected for whole-brain family-wise error showing voxels where there are strong effects across both studies. This analysis revealed a cluster of significantly overlapping effects in a region of the ventral-medial temporal lobe centered on the lateral aspect of parahippocampal cortex. 
 
 
 
 
 Figure 4 
 
 fMRI activation for abstract concepts in healthy young adults. These results show regions where activation was strongly modulated by the processing of abstract concepts, which have very weak associations with visual semantics. 
 
 
 
 
 Figure 5 
 
 Gray matter atrophy in patients relative to age-matched controls. The patients have atrophy primarily affecting lateral, ventral, and medial regions of the anterior temporal lobe. 
 
 
 
 
 Figure 6 
 
 Individual variability in parahippocampal gray matter density is related to the processing of visual semantics in healthy adults.  (A)  This plot shows group-averaged response latencies for each item. The dots are the group means and the gray bars are the standard errors. At the group level, subjects exhibited faster performance for concepts that are more strongly associated with visual semantics.  (B)  Individual subjects varied in the degree of their performance advantage for visual concepts. Each subject’s performance advantage was quantified as the correlation of response latency and visual association strength. This metric is referred to as “visual-feature sensitivity.” This scatter plot shows each subject’s response latencies across all items. Subjects are color coded according to their visual-feature sensitivity scores, with the cooler colors indicating stronger visual-feature sensitivity scores and warmer colors indicating weaker visual-feature sensitivity scores. The distribution of response latencies shows that subjects with higher visual-feature sensitivity scores tend to have faster responses for concepts with strong visual associations. This can be seen in the clustering of blue dots at the bottom right corner of the plot.  (C)  This plot shows the relationship for each subject between response latency and visual association strength. Each line represents a regression within a single subject. Steeper slopes indicate faster performance for visual relative to abstract concepts. Subjects varied on the extent to which they exhibited this performance advantage, as illustrated by the range of regression lines in this figure (cooler colors indicate stronger visual-feature sensitivity and warmer colors indicate weaker visual-feature sensitivity).  (D)  Individual differences in visual-feature sensitivity were correlated with the gray matter density of parahippocampal cortex. The visual-feature sensitivity values used in this analysis reflect the relationship between response latency and the visual association strength of the stimuli within each subject. They are calculated by taking the negative of the Spearman’s rho values from a correlation of response latency and visual association strength. The gray matter density values were taken from a region of interest consisting of the significant cluster from the fMRI analysis of visual semantics (see  Fig. 3 ).  (E)  Although there were no whole-brain corrected results for the regression analysis of visual-feature sensitivity and gray matter density, inspection of the uncorrected t-maps showed a trending effect in the ventral-medial temporal lobe. To explore the anatomic overlap of this effect with findings from the fMRI study of visual semantics, an inter-study similarity analysis was performed (as in  Fig. 3 ). This analysis revealed a cluster of similar effects in a region of the ventral-medial temporal lobe centered on the lateral aspect of parahippocampal cortex. 
 
 
 
 
 Table 1 
 
 Properties of the Stimulus Set 
 
 
 
 
 Stimulus characteristics 
 
 
 
 
 
 
 
 Visual 
 Abstract 
 Auditory 
 Manipulable 
 
 
 
 
 Visual association ratings (scale: 0 to 6) 
 5.5 (0.3) 
 0.6 (0.6) 
 3.5 (1.8) 
 5.2 (0.3) 
 
 
 Auditory association ratings (scale: 0 to 6) 
 0.5 (0.5) 
 0.3 (0.3) 
 4.6 (0.7) 
 0.9 (0.5) 
 
 
 Motor-manipulation association ratings (scale: 0 to 6) 
 1.5 (0.8) 
 0.4 (0.4) 
 1.1 (0.8) 
 4.1 (0.5) 
 
 
 Letter length 
 6.4 (1.8) 
 6.5 (2.0) 
 6.9 (2) 
 6.2 (2.2) 
 
 
 Lexical frequency 
 16 (24) 
 16 (18) 
 16 (20) 
 15 (24) 
 
 
 Semantic associativity of target (scale: 0 to 6) 
 4.3 (0.8) 
 4.3 (0.8) 
 4.5 (0.7) 
 4.8 (0.7) 
 
 
 Semantic associativity of foil (scale: 0 to 6) 
 0.4 (0.6) 
 0.6 (0.5) 
 0.8 (0.8) 
 0.6 (0.7) 
 
 
 Concreteness (scale: 100 to 700) 
 601 (21) 
 325 (49) 
 531 (90) 
 591 (38) 
 
 
 Imageability (scale: 100 to 700) 
 598 (26) 
 370 (62) 
 570 (74) 
 581 (38) 
 
 
 
 
 
 Table 2 
 
 Characteristics of the Patient Group 
 
 
 
 
 Demographic and clinical characteristics of patients 
 
 
 
 
 
 
 
 
 
 
 
 
 1 
 
 
 2 
 
 
 3 
 
 
 4 
 
 
 5 
 
 
 6 
 
 
 7 
 
 
 8 
 
 
 
 
 
 Age 
 60 
 71 
 70 
 72 
 59 
 69 
 63 
 49 
 
 
 Education 
 20 
 12 
 12 
 14 
 17 
 22 
 22 
 16 
 
 
 Years from symptom onset 
 1 
 4 
 8 
 5 
 3 
 4 
 3 
 3 
 
 
 Months from first clinic visit 
 10 
 22 
 10 
 37 
 7 
 6 
 0 
 9 
 
 
 MMSE (max=30) 
 18 
 6 
 25 
 27 
 28 
 22 
 27 
 15 
 
 
 Pyramids and Palm Trees: pictures (max=52) 
 35 
 36 
 49 
 NA 
 26 
 36 
 44 
 47 
 
 
 Pyramids and Palm Trees: words (max=52) 
 31 
 30 
 52 
 41 
 29 
 35 
 46 
 40 
 
 
 Rey Complex Figure: copy (max=12) 
 11 
 12 
 9 
 12 
 10 
 12 
 12 
 12 
 
 
 Rey Complex Figure: recall (max=12) 
 2 
 5 
 0 
 11 
 5 
 9 
 9 
 10 
 
 
 
 
 
 The Mini Mental State Exam (MMSE) is a general assessment of cognitive impairment. The Pyramids and Palm Trees test assesses semantic memory. The Rey Complex Figure test examines visuospatial abilities and episodic recall. “Years from symptom onset” measures the number of years between the test date and the year that the patients or their caregivers reported first observing symptoms. “Months from first clinic visit” measures the number of months between the test date and the date of the patient’s first visit to the neurology clinic at the University of Pennsylvania. 
 
 
 
 
 Table 3 
 
 MRI Coordinates 
 
 
 
 
 Analysis 
 Peak coordinates 
 Peak location 
 Cluster size (μl) 
 Z-score 
 
 
 x 
 y 
 z 
 
 
 
 
 fMRI words > pseudowords 
 −34 
 28 
 −12 
 L inferior frontal gyrus 
 29296 
 5.07 
 
 
 −4 
 42 
 52 
 L superior frontal gyrus 
 7248 
 4.97 
 
 
 −32 
 −40 
 −24 
 L fusiform gyrus 
 2496 
 4.73 
 
 
 10 
 −80 
 −26 
 R calcarine sulcus 
 2320 
 4 
 
 
 30 
 26 
 −10 
 R inferior frontal gyrus 
 4224 
 3.78 
 
 
 fMRI visual semantics 
 −30 
 −36 
 −12 
 L parahippocampal gyrus / collateral sulcus 
 2656 
 4.9 
 
 
 fMRI abstract semantics 
 −50 
 20 
 −12 
 L superior temporal gyrus 
 34984 
 5.38 
 
 
 −38 
 −90 
 −2 
 L middle occipital gyrus 
 2832 
 4.62 
 
 
 0 
 16 
 56 
 L / R superior frontal gyrus 
 7480 
 4.29 
 
 
 −4 
 −20 
 10 
 L thalamus 
 4048 
 4.23 
 
 
 Patient atrophy 
 −29 
 −5 
 −34 
 L fusiform gyrus 
 93387 
 8.54 
 
 
 48 
 −1 
 −22 
 R middle temporal gyrus 
 10194 
 6.13 
 
 
 −17 
 41 
 11 
 L cingulate gyrus 
 1290 
 5.75 
 
 
 54 
 −44 
 −13 
 R inferior temporal gyrus 
 910 
 5.44 
 
 
 −31 
 12 
 32 
 L middle frontal gyrus 
 166 
 5.27 
 
 
 −57 
 −57 
 −6 
 L inferior temporal gyrus 
 214 
 5.15 
 
 
 −15 
 15 
 35 
 L cingulate gyrus 
 53 
 5.08 
 
 
 Patient regression analysis 
 −28 
 −32 
 −7 
 L parahippocampal gyrus / hippocampus 
 2660 
 4.11 
 
 
 
 
 
 The results for “fMRI words > pseudowords” come from the contrast of word-association trials with pseudoword letter-matching trials. The results for “fMRI visual semantics” reflect the positive effects of the parametric modulator for visual association strength. The results for “fMRI abstract semantics” reflect the negative effects of the parametric modulator for visual association strength. The results for “Patient atrophy” are from the contrast of gray matter density in patients relative to controls. The results for the “Patient regression analysis” are from the regression of gray matter density and performance on visual relative to abstract concepts. 
 
 
 
 
