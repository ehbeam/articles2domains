
 properties manuscript? 
 
 
 101541838 
 38415 
 Dev Cogn Neurosci 
 Dev Cogn Neurosci 
 
 Developmental cognitive neuroscience 
 
 1878-9293 
 1878-9307 
 
 
 22337757 
 3278275 
 NIHMS353610 
 
 
 Article 
 
 
 
 Developmental changes in the inferior frontal cortex for selecting semantic representations 
 
 
 
 
 Lee 
 Shu-Hui 
 
 a 
 
 
 
 Booth 
 James R. 
 
 b 
 
 
 
 Chen 
 Shiou-Yuan 
 
 c 
 
 
 
 Chou 
 Tai-Li 
 
 a 
 d 
 * 
 
 
 a Department of Psychology, National Taiwan University, Taipei, Taiwan 
 b Department of Communication Sciences and Disorders, Northwestern University, Evanston, IL, USA 
 c Department of Early Childhood Education, Taipei Municipal University of Education, Taipei, Taiwan 
 d Neurobiology and Cognitive Science Center, National Taiwan University, Taipei, Taiwan 
 
 * Corresponding author at: Department of Psychology, National Taiwan University, No. 1, Sec. 4, Roosevelt Road, Taipei, 106, Taiwan. Tel.: +886 2 33663082; fax: +886 2 23631463.  tlchou25@ntu.edu.tw  (T.-L. Chou) 
 
 
 1 
 2 
 2012 
 
 
 1 
 7 
 2011 
 
 
 13 
 2 
 2012 
 
 1 
 3 
 338 
 350 
 
 
 This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law. 
 
 
 
 Functional magnetic resonance imaging (fMRI) was used to examine the neural correlates of semantic judgments to Chinese words in a group of 10–15 year old Chinese children. Two semantic tasks were used: visual–visual versus visual–auditory presentation. The first word was visually presented (i.e. character) and the second word was either visually or auditorily presented, and the participant had to determine if these two words were related in meaning. Different from English, Chinese has many homophones in which each spoken word corresponds to many characters. The visual–auditory task, therefore, required greater engagement of cognitive control for the participants to select a semantically appropriate answer for the second homophonic word. Weaker association pairs produced greater activation in the mid-ventral region of left inferior frontal gyrus (BA 45) for both tasks. However, this effect was stronger for the visual–auditory task than for the visual–visual task and this difference was stronger for older compared to younger children. The findings suggest greater involvement of semantic selection mechanisms in the cross-modal task requiring the access of the appropriate meaning of homophonic spoken words, especially for older children. 
 
 
 fMRI 
 Semantic 
 Visual 
 Auditory 
 Association strength 
 Age 
 
 
 
 National Institute of Child Health & Human Development : NICHD 
 R01 HD042049-09 || HD 
 
 
 
 
 
 1. Introduction 
 Reading fluency requires the capability to integrate orthographic, phonological and semantic representations ( Cao et al., 2009 ;  Cone et al., 2008 ). The current study used functional magnetic resonance imaging (fMRI) to examine developmental changes in Chinese children (aged 10–15) during a cross-modal semantic association task in which words were presented in the visual and auditory modality. 
 Effective word recognition involves the rapid correspondence between orthography, phonology, and semantics ( Coltheart et al., 2001 ;  Plaut et al., 1996 ). Previous studies have used cross-modal paradigms to examine the conversion between orthography and phonology in word recognition in English ( Noppeney et al., 2007 ;  Marslen-Wilson and Zwitserlood, 1989 ;  Whatmough et al., 1999 ) and French ( Grainger et al., 2001 ;  Kiyonaga et al., 2007 ). However, these languages have writing systems with fewer homophones. In contrast, there exist many homophones in Chinese and thus mapping is particularly unsystematic from spoken to written word forms. Spoken Chinese (Mandarin) uses four tones to differentiate different words with different meanings. Chinese has about 5000 common words, but only about 400 different syllables independent of tone, or around 1300 if a change in tone is considered to create a different syllable ( Reich et al., 2003 ). Therefore, Chinese contains many monosyllabic homophones with different meanings. About 55 percent of monosyllables correspond to more than five homophones ( Institute of Linguistics, 1985 ). When a Chinese word is pronounced without context, it is almost impossible for the listener to know which visual word or meaning is referred to. For example, the monosyllable “yi4” has about 90 homophones with different word forms and different meanings (number indicates the tone), and there are about 171 homophones for this monosyllable when four tones are included. 
 The present study took advantage of this lack of systematicity in Chinese by using a cross-modal presentation in which the first word was presented visually and the second word was presented auditorily (visual–auditory). Participants were asked to judge if these two sequentially presented words were related in meaning or not in a semantic judgment task. In hearing the sound in the visual–auditory task, the participants may activate all the possible orthographic candidates and meanings ( Hung et al., 2010 ;  Booth et al., 2007 ). Thus, the goal of this study was to test whether the existence of multiple homophones may increase phonological mediation to access meaning or whether the multiple homophones may induce greater engagement of selecting an appropriate character and/or meaning among spoken homophones when words are presented auditorily in Chinese. 
 During the semantic judgment task, semantic association has been used to evaluate meaning processing such as selection, retrieval and integration in English and Chinese ( Fletcher et al., 2000 ;  Chou et al., 2006a , b ,  2009a ;  Raposo et al., 2006 ). Aforementioned studies have identified two critical regions including left inferior parietal lobule for processing closely related pairs (i.e. stronger association) and left inferior frontal gyrus for processing distantly related pairs (i.e. weaker association) to be engaged in semantic processing. Processing closely related word pairs has elicited greater activation in left inferior parietal lobule (BA 39, 40), suggesting the integration of multiple shared features between word pairs ( Grossman et al., 2003 ;  Koenig et al., 2005 ). In addition, greater activation was observed in left inferior parietal lobule when participants were cued to be aware of the semantic features of the incoming word target ( Cristescua et al., 2006 ) and/or merging the incoming information into current syntactic structures ( Lau et al., 2008 ). 
 Processing distantly related pairs has elicited greater activation in left ventrolateral regions of inferior frontal gyrus (BA 45, 47). The greater activation in left inferior frontal gyrus is thought to reflect the difficulty of retrieving or selecting the shared features between distantly related word pairs ( Fletcher et al., 2000 ). Moreover, previous semantic studies examining semantic retrieval or selection have found greater activation in the left inferior frontal gyrus, such as abstract versus concrete word ( Pexman et al., 2007 ), matching specific features versus global similarity ( Snyder et al., 2007 ;  Thompson-Schill et al., 1997 ,  1999 ), indirectly versus directly related word pairs ( Kuperberg et al., 2008 ), inconsistent versus consistent word processing ( Bedny et al., 2008 ). These aforementioned studies support the idea that greater difficulty of semantic retrieval or selection required greater engagement of the left inferior frontal gyrus. 
 Previous studies suggest that different regions of left inferior frontal gyrus may support processing of different linguistic functions ( Liu et al., 2009 ;  Poldrack et al., 1999 ). The dorsal regions of left inferior fontal gyrus (BA 9, 44) are engaged in phonological mediation ( Booth et al., 2004 ;  Liu et al., 2009 ;  Poldrack et al., 1999 ). Studies have found greater activations in the dorsal regions of left inferior frontal gyrus for phonetic monitoring, phoneme generation, or phonological segmentation ( Binder et al., 2004 ;  Fiez et al., 1999 ;  Gandour et al., 2003 ;  Liu et al., 2009 ). In the current study, distantly related pairs had significantly fewer overlapping features than closely related pairs, presumably making mapping to semantics less efficient and possibly increasing phonological mediation. Greater phonological mediation may be enhanced in the visual–auditory task due to multiple homophones being activated, as compared to when both words are presented visually (visual–visual). Previous behavioral studies in Chinese have shown that when participants were given homophones during auditory word processing in Chinese, increasing phonological information appeared to speed up the process of access to meaning ( Li and Yip, 1998 ). 
 In contrast to dorsal regions, the ventral regions of inferior IFG (BA 45, 47) seem to be involved in semantic processing ( Badre and Wagner, 2007 ;  Liu et al., 2009 ;  Poldrack et al., 1999 ).  Badre and Wagner (2007)  further proposed different cognitive functions for ventral regions of the inferior frontal gyrus. The anterior ventral region of left inferior frontal gyrus (BA 47) may support controlled access to stored semantic representations, whereas the mid-ventral region of left inferior frontal gyrus (BA 45) may support a selection process among active representations. In particular, the mid-ventral region of left inferior frontal gyrus (BA 45) has been proposed to be involved in cognitive control, including inhibiting irrelevant responses/information and selecting relevant responses/information ( Botvinick et al., 2001 ,  2004 ;  Bunge et al., 2002 ). The mechanism underlying the activation of multiple competitors has been put forth in the biased competition model ( Kan and Thompson-Schill, 2004 ). This model assumes that when a word is presented, multiple associated representations are activated automatically. Upon the presentation of a second word, associated meanings of that word are also activated, but the weight of each active meaning is biased by the preceding word. Meanings of the second word relevant to the context have greater weight, whereas the irrelevant meanings have lower weights. This model also assumes that relevant meanings with greater weight inhibit irrelevant meanings. In the current study, the selection demand may be low (i.e., greater weight) for target words in closely related pairs, because they have many overlapping features and few irrelevant features. In contrast, the selection demand may be high (i.e., lower weight) for target words in distantly related pairs, because few overlapping features and many irrelevant features. In other words, the first word of the related pairs may act as a semantic constraint for the second word. The semantic constraint may be weaker in the distantly related pairs, in which the demand to select among multiple competitors may be greater than in the closely related pairs. Processing distantly related pairs might, therefore, result in greater cognitive control of inhibiting irrelevant features and selecting relevant features. 
 In the current study, distantly related pairs may be characterized by greater activation of distinctive/irrelevant features and weaker activation of shared/relevant features. Processing distantly related pairs might, therefore, result in greater cognitive control of inhibiting irrelevant features and selecting relevant features. Moreover, in the visual–auditory task, participants needed to select the target among competing homophones, and therefore this task may place greater demands on cognitive control as compared to the visual–visual task. The evidence supporting demanding cognitive control is that in a cross-modal task to disambiguate various homophonic meanings in Chinese, multiple homophones may compete and thus require the use of context to select the correct answer ( Li and Yip, 1998 ). 
 In addition, behavioral studies of cognitive control have shown changes from childhood through adolescence in performance in a variety of tasks including a go/no-go task ( Eigsti et al., 2006 ), Stroop task ( Leon-Carrion et al., 2004 ), and antisaccade task ( Luna et al., 2004 ). Neuroimaging studies have identified prolonged developmental changes in structure of the prefrontal cortex including density reduction in gray matter ( Giedd, 1999 ;  Gogtay et al., 2004 ;  Shaw et al., 2006 ;  Sowell et al., 2001 ,  2003 ) and volume increases in white matter ( Barnea-Goraly et al., 2005 ;  Liston et al., 2005 ;  Nagy et al., 2004 ;  Paus et al., 1999 ) and in functional activation in prefrontal regions during a variety of cognitive control tasks including response inhibition using a Stroop task ( Adleman et al., 2002 ) and using go/no-go tasks ( Bunge et al., 2002 ;  Tamm et al., 2002 ). Several studies have also demonstrated that adolescents between ages 13 and 17 are more capable of dealing with interference during cognitive control tasks than children between ages 8 and 12 ( Adleman et al., 2002 ;  Lamm et al., 2006 ;  Luna et al., 2004 ;  Williams et al., 1999 ). This improvement during adolescence suggests that teenagers are more capable of maintaining multiple dimensions of concepts in the mind and using a flexible mechanism to filter out irrelevant information during cognitive control tasks ( Blakemore and Choudhury, 2006 ). 
 In the current study, the first goal was to examine differences between a unimodal (visual–visual presentation) and a cross-modal semantic judgment task (visual–auditory presentation). If there is greater phonological mediation for the visual–auditory task than the visual–visual task, there should be greater activation in the dorsal region of left inferior frontal gyrus (BA 44, 9). However, if there are greater demands on cognitive control for the visual–auditory task than the visual–visual task, we expected to find greater activation in the mid-ventral region of left inferior frontal gyrus (BA 45). The second goal was to determine whether age in 10–15-year-old Chinese children was differentially related to activation in the visual–auditory versus the visual–visual tasks. Because studies have shown substantial improvement in cognitive control from childhood to adolescence, we expected to see greater age related changes in the inferior frontal gyrus for the visual–auditory task due to greater demands on cognitive control for this task. 
 
 
 2. Methods 
 
 2.1. Participants 
 In the visual–visual meaning judgment task, a group of twenty-three native monolingual Chinese children (mean age = 12.8, standard deviation = 1.5, 11 girls) participated. In the visual–auditory meaning judgment task, another group of twenty-three native monolingual Chinese children (mean age = 12.8, standard deviation = 1.5, 11 girls) participated. All forty-six children were recruited from the Taipei city metropolitan area and their parents were given an informal interview to insure that their children met the following inclusionary criteria: (1) right-handedness, (2) normal hearing (3) normal or corrected-to-normal vision, (4) free of neurological disease or psychiatric disorders, (5) no history of intelligence, reading, or oral-language deficits, and (6) no learning disability or attention deficit hyper-activity disorder (ADHD). After the administration of the informal interview, informed consent was obtained. The informed consent procedures were approved by the Institutional Review Board at the National Taiwan University Hospital. Standardized intelligence testing was administered, using the Wechsler Intelligence Scale for Children (WISC-III) Chinese version (The Psychological Corporation, 1999). In the visual–visual semantic judgment task, participants’ standard scores (mean ± SD) were 112 ± 10 on the verbal scale and 114 ± 11 on the performance scale. In the visual–auditory semantic judgment task, participants’ standard scores (mean ± SD) were 110 ± 11 on the verbal scale and 111 ± 12 on the performance scale. 
 
 
 2.2. Functional activation tasks 
 The children were given two practice sessions, one outside the scanner and the other in the scanner, to make sure that they understood the task. The practice items were different stimuli than those used in fMRI sessions. Each participant was at least 80% correct for each condition separately for both practice sessions. In the scanner, participants performed either a visual–visual semantic judgment task or a visual–auditory semantic judgment task to Chinese word pairs. Both semantic judgment tasks included forty-eight related pairs and twenty-four unrelated pairs. These lexical pairs in both tasks were the same stimuli. Forty-eight related pairs included strongly to weakly associated items chosen from a Chinese association norm ( Hue et al., 2005 ). Forty-eight character pairs were semantically related according to their free association values (mean = 0.14, SD = 0.13, ranging from 0.73 to 0.01). The word pairs chosen from the Chinese association norm were based on their semantic relation including synonyms, antonyms, in the same category, or with similar functions ( Lee et al., 2009 ). The Chinese association norm ( Hue et al., 2005 ) was constructed by presenting a list of Chinese words to 100 native Taiwan undergraduates. They were asked to write down the first word that came into mind. The association value to each pair was calculated as follows. For example, if 30 out of 100 undergraduates generated the same word to a given target word, then the association value would be 0.3 for the pair. This method of establishing association norms has been used in English ( Nelson et al., 1998 ). Character pairs were arranged in a continuous variable according to association values ( Chou et al., 2009b ). In addition, twenty-four word pairs were semantically unrelated with zero association values. Because all participants were right-handed, the use of the dominant hand (i.e., the right hand) was natural for them to perform the task. The use of the left hand may have increased selection demands due to shifting hands. To avoid potential confusion for children, our participants were instructed to use their right hand for the button-press responses. Therefore, the participants were instructed to quickly and accurately press with their right hand the yes button to the related pairs and the no button to the unrelated pairs. 
 
 
 2.3. Visual–visual semantic judgment task 
 In the visual–visual meaning judgment task, two Chinese words were presented sequentially and the participant had to determine whether the word pair was related in meaning. Trials lasted 4500 ms and consisted of a solid square (500 ms), followed by the first word (800 ms), a 200 ms blank interval, and the second word for 3000 ms. The participant was instructed to make a response during the presentation of the second word. The perceptual control condition had 24 pairs of non-characters. Non-characters were created by replacing radicals of real characters with other radicals that did not form real Chinese characters. Non-characters were larger (50 font size) than real characters (40 font size) in order to encourage participants to perform the task based on the recognition of low level visual similarity and not on the extraction of semantic information. For the perceptual control condition, trials consisted of a solid square (500 ms), followed by the first non-character (800 ms), a 200 ms blank interval, and the second non-character for 3000 ms. Participants determined whether the pair of stimuli were identical or not by pressing a yes or no button with their right hand. There were also 24 baseline events as “null” trials so that we could better deconvolve the response to the lexical and perceptual trials. The participant was instructed to press a button when a solid square (1300 ms) at the center of the visual field turned to a hollow square (3000 ms) after a blank interval (200 ms). 
 
 
 2.4. Visual–auditory semantic judgment task 
 In the visual–auditory meaning judgment task, the first word was visually presented and the second word was auditorily presented. Each trial lasted 4500 ms with a solid square as fixation (500 ms) in the beginning of each trial. The two words were presented sequentially in a cross-modal manner, with a 200 ms blank in between. The first word was visually presented (800 ms). The second word was auditorily presented through headphones (800 ms). The second words of the visual–auditory task were recorded by a native Mandarin-Chinese female in a sound attenuated booth. The average sampling rate was 44.1 kHz with an average volume of approximately 75 dB. The sound files were modified by Praat to have an 800-ms duration ( Boersma and Weenink, 2007 ). The spoken words were reported by the participants as sounding natural. A hollow square was visually presented simultaneously during the presentation of the second word, indicating the need to make a response in a 3000 ms interval. Reaction time was measured from the onset of the second word. The perceptual condition had 24 trials consisting of tone matching judgments. Trials consisted of a solid square (500 ms), followed by a visual word indicating up or down (800 ms), a blank interval (200 ms), and an ascending or a descending tone presented to the participants through headphones (800 ms) with a hollow square visually presented simultaneously on the screen (3000 ms). Participants determined whether the visual word (i.e. up or down) and the tone (i.e. ascending or descending) matched in direction by pressing a yes or no button with their right hand. This condition was used as a control for the word pairs in the fMRI analyses because it equated aspects of perceptual input and response demands. There were also 24 baseline events as “null” trials in order to better deconvolve the response to the word and perceptual trials. In the null trials, the participant was instructed to press a button when a solid square at the center of the visual field turned to a hollow square. We also used baseline events (i.e. fixation cross) as control conditions that were the same in both semantic judgment tasks. The patterns of activation in regions related to meaning processing, including left inferior frontal gyrus and left middle temporal gyrus, were essentially the same as to those when using the perceptual control conditions. We chose to present data comparing the semantic to the perceptual control conditions to subtract out activation in the primary visual/auditory cortex that it is not likely due to semantic processing. 
 
 
 2.5. Stimulus characteristics 
 In both the visual–visual and the visual–auditory semantic judgment tasks, several lexical variables were controlled across the related and unrelated word pairs. First, all Chinese words were monosyllabic. Second, the first word and the second word did not share radicals. Third, the first and second word together did not form another word ( Huang, 1998 ;  Wu and Liu, 1987 ). Fourth, words were matched for visual complexity (in terms of strokes per word) across conditions. A 2 word (first, second) × 2 condition (related, unrelated) ANOVA showed that the main effect of relatedness nor its interaction with word was significant. Fifth, words were matched for written frequency for adults ( Wu and Liu, 1987 ) and written familiarity for children across the related and unrelated conditions. Familiarity scores were obtained from pre-tests in which all the words were rated on a 7-point scale by thirty age-matched children who were native Mandarin speakers from Taiwan. A 2 word (first, second) × 2 condition (related, unrelated) ANOVA showed no main effects or interactions with the frequency or the familiarity measure. The correlation of the word frequency or familiarity measure with association strength was not significant indicating that association effects should not be due to frequency or familiarity differences. In addition, the second words in the visual–auditory semantic task were matched for the numbers of homophones across the related and unrelated conditions ( Lee et al., 2009 ). The correlation of number of homophones and association strength was not significant. In the visual–auditory semantic judgment task, all the stimulus characteristics (frequency, strokes, and homophones) examined for the second word were according to the visual form in the visual–visual semantic judgment task ( Wu et al., 2004 ) ( Table 1 ). 
 We also collected norms of overlapping features for both closely and distantly related pairs. Seventy-six undergraduates were asked to fill out a semantic-feature generation questionnaire. The questionnaire contained 96 words from the 48 related pairs used in the semantic judgment task. The participants were required to write down at least 8 features for each word, similar to the way “target concepts total” was used to generate features according to  Cree et al. (2006) . We then calculated how many overlapping features were between the first and the second word. The questionnaire showed greater overlapping features for the 24 closely related pairs (mean = 49.5,  SD  = 15.6) compared to the 24 distantly related pairs (mean = 33.2,  SD  = 8.6),  t (46) = 4.48,  p  < .0001. The correlation between the association strength and the numbers of features was significant ( r (48) = 0.51,  p  < .0001). 
 
 
 2.6. MRI data acquisition 
 Participants lay in the scanner with their head position secured with a specially designed vacuum pillow. An optical response box was placed in the participants’ right hand. The head coil (CP Transmit/Receive Head Coil) was positioned over the participants’ head (Siemens, Erlangen, Germany). Participants viewed visual stimuli projected onto a screen via a mirror attached to the inside of the head coil. Participants wore headphones to hear auditory stimuli (Nordic NeuroLab, San Antonio, TX). Each participant performed two functional runs (4.7 min each). 
 All images were acquired using a 3 T Siemens scanner. Gradient-echo localizer images were acquired to determine the placement of the functional slices. For the functional imaging studies, a susceptibility weighted single-shot EPI (echo planar imaging) method with BOLD (blood oxygenation level-dependent) was used. Functional images were collected parallel to AC-PC plane with interleaved whole brain EPI acquisition from bottom to top. The following scan parameters were used: TE = 24 ms, flip angle = 90°, matrix size = 64 × 64, field of view = 25.6 cm, slice thickness = 3 mm, number of slices = 34, TR = 2000 ms. Each functional run had 136 image volumes. In addition, a high resolution, T1 weighted 3D image was acquired (TR = 1560 ms, TE = 3.68 ms, flip angle = 15°, matrix size = 256 × 256, field of view = 25.6 cm, slice thickness = 1 mm, number of slices = 192). The orientation of the 3D image was identical to the functional slices. The task was administered in a pseudorandom order for all subjects, in which the order of related, unrelated, perceptual, and baseline trials was optimized for event-related design ( Burock et al., 1998 ). Events were 4500 ms apart with baseline “null” trials to better deconvolve the response to the lexical and perceptual trials. We used the Optseq script for randomized event-related design ( http://surfer.nmr.mgh.harvard.edu/optseq , written by D. Greve, Charlestown, MA) that implemented  Burock et al. (1998) ’s approach. 
 
 
 2.7. Image analysis 
 Data analysis was performed using SPM2 (Statistical Parametric Mapping). The functional images were corrected for differences in slice-acquisition time to the middle volume and were realigned to the first volume in the scanning session using affine transformations. No participant had more than 3 mm of movement in any plane. Co-registered images were normalized to the MNI (Montreal Neurological Institute) average template (12 linear affine parameters for brain size and position, 8 non-linear iterations and 2 × 2 × 2 nonlinear basis functions). Statistical analyses were calculated on the smoothed data (10 mm isotropic Gaussian kernel), with a high pass filter (128 s cutoff period) in order to remove low frequency artifacts. 
 Data from each participant was entered into a general linear model using an event-related analysis procedure ( Josephs and Henson, 1999 ). Word pairs were treated as individual events for analysis and modeled using a canonical HRF (Hemodynamic Response Function). There were four event types: related, unrelated, perceptual, and baseline. For the related pairs, association strength was an item-level parametric modulator in order to differentiate semantic relatedness as a continuous variable according to log transformed free association strength ( Hue et al., 2005 ). The resulting model coefficients for individual subjects were entered into subsequent second-order random effects analyses in a whole brain analysis. Random-effects analysis using one-sample  t -tests across all participants was used to determine whether activation during a contrast was significant (i.e., parameter estimates were reliably greater than 0). 
 In a first series of analyses, we compared the related and unrelated pairs separately to the perceptual control condition, and the related pairs to the unrelated pairs directly. In a second series of analyses, we examined the effect of the continuous variable of log transformed association strength for the related pairs ( Hue et al., 2005 ) with signal intensity. An inclusion mask of related versus unrelated ( p  < .05 uncorrected) was used for stronger association and an inclusive mask of related versus perceptual ( p  < .05 uncorrected) was used for weaker association ( Chou et al., 2006b ). The analysis of the item-level (within-subject) parametric modulator (i.e., association strength in a continuous scale) was based on the related pairs and was not in comparison to baseline (also see  Bolger et al., 2008 ). Positive effects indicated progressively greater activation for word pairs with stronger association strength, whereas negative effects indicated progressively greater activation for word pairs with weaker association strength. In addition, we performed a task comparison between the visual–visual task and the visual–auditory task on the contrast of weaker association with an anatomical mask of left inferior frontal gyrus due to our a priori hypothesis. In a third series of analyses, we examined the effects of behavioral performance for related pairs, including accuracy or reaction time in the scanner as a within-subject covariate. The analysis of the item-level (within-subject) parametric modulator (i.e., accuracy or reaction time) was based on the related pairs and was not in comparison to baseline. In the analysis of accuracy, positive effects indicated greater activation with higher accuracy, whereas negative effects indicated greater activation with lower accuracy. In the analysis of reaction time, positive effects indicated greater activation with slower reaction times, whereas negative effects indicated greater activation with faster reaction times. In the fourth series of analyses, we used multiple regression to correlate the continuous variable of age in months with signal intensity, including accuracy or reaction time performance in the scanner as a between-subject covariate, for the related or the unrelated pairs separately compared to the perceptual control condition. We used an inclusive mask related versus perceptual ( p  < .05 uncorrected) for the age effect ( Chou et al., 2006b ). These analyses allowed us to examine age-related increases or decreases in activation that were independent of accuracy or reaction time differences. All reported areas of activation were significant using  p  < .05 corrected for FDR (false discovery rate) at the voxel level with a cluster size greater than or equal to 10 voxels. 
 In order to examine developmental differences between the visual–auditory task and the visual–visual task, we extracted the beta values from peak voxels of brain regions that showed similar strength of association effects across tasks (i.e. inferior frontal gyrus). First, we compared the weaker association effect to evaluate selection demands between the two tasks. Second, because the number of the participants was an odd number (23) in each task, we split the children by age into two groups of 11 and did not use the participant in the median position of age for further analysis. Participants were 11 younger children in the younger group (age range = 10–12) and 11 older children in the older group (age range = 13–15) for each task. The younger groups in both the visual–visual task (mean = 11.5,  SD  = 0.7) and the visual–auditory task (mean = 11.5,  SD  = 0.7) were age matched. The older groups in both the visual–visual task (mean = 14.2,  SD  = 0.6) and the visual–auditory task (mean = 14.2,  SD  = 0.6) were also age matched. This allowed us to do a 2 task (visual–visual, visual–auditory) by 2 age (younger, older) ANCOVA, partialled for behavioral performance (accuracy or reaction time). 
 
 
 
 3. Results 
 
 3.1. Behavior performance 
 
 3.1.1. Analyses of accuracy within and between tasks 
 The accuracy (mean ±  SD ) for the related and unrelated events was 86 ± 10% and 97 ± 4%, respectively, in the visual–visual semantic judgment task. The accuracy (mean ±  SD ) for the related and unrelated events was 71 ± 15% and 94 ± 6%, respectively, in the visual–auditory semantic judgment task. A 2 task (visual–visual, visual–auditory) by 2 condition (related, unrelated) ANOVA was performed. This analysis showed a significant main effect of task,  F (1, 44) = 17.97,  p  = .001, reflecting greater accuracy for the visual–visual task than for the visual–auditory task. The main effect of condition was significant,  F (1, 44) = 73.7,  p  = .001, reflecting greater accuracy for the unrelated word pairs than for the related word pairs. The interaction between task and condition was significant,  F (1, 44) = 7.94,  p  = .007. A simple main effects analysis showed greater accuracy for the visual–visual task than for the visual–auditory task in the related word pairs ( t  = 3.80,  p  = .001). 
 
 
 3.1.2. Analysis of reaction times within and between tasks 
 Reaction times (mean ±  SD ) for the related and unrelated events were 995 ± 225 ms and 957 ± 195 ms, respectively, in the visual–visual semantic judgment task. Reaction times (mean ±  SD ) for the related and unrelated events were 1091 ± 184 ms and 1162 ± 221 ms, respectively, in the visual–auditory semantic judgment task. A 2 task (visual–visual, visual–auditory) by 2 condition (related, unrelated) ANOVA was performed. This analysis showed a significant main effect of task,  F (1, 44) = 6.90,  p  = .012, reflecting faster reaction time for the visual–visual task than for the visual–auditory task. The main effect of condition was not significant,  F (1, 44) = 0.59,  p  = .45. The interaction between task and condition was significant,  F (1, 44) = 6.65,  p  = .01. A simple main effects analysis showed faster reaction time for the visual–visual task than for the visual–auditory task in the unrelated word pairs ( t  = 3.34,  p  = .002). 
 
 
 3.1.3. The visual–visual task: by-item based correlations between association strength and accuracy/reaction times 
 Because word pairs were arranged in a continuous variable according to association strength, we calculated the correlations between association strength for related pairs and behavioral performance. The item-based correlation between accuracy and association strength was not significant,  r (48) = −0.27,  p  = .07; and the item-based correlation between reaction times and association strength was negative,  r (48) = −0.39,  p  < .01. 
 
 
 3.1.4. The visual–auditory task: by-item based correlations between association strength and accuracy/reaction times 
 Because word pairs were arranged in a continuous variable according to association strength, we calculated the correlations between association strength for related pairs and behavioral performance. The item-based correlation between accuracy and association strength was not significant,  r (48) = −0.11,  p  = .47; and the item-based correlation between reaction times and association strength was negative,  r (48) = −0.35,  p  = .02. 
 
 
 3.1.5. The visual–visual task: by-subject based correlations between age and accuracy/reaction times 
 Because there were 2.5% outliers of accuracy trials outside 2.5  SD  from the group mean for each condition, we performed a reciprocal transformation for accuracy ( Kirk, 1995 ). Reaction times did not have outliers outside 2.5  SD  from the group mean for any condition. Therefore, no transformation was performed for reaction times. The correlation of age with accuracy was marginally significant for related pairs [ r (23) = −0.41,  p  = .05] showing that the older children were more accurate than the younger children but the correlation of age with reaction times was not significant for related pairs [ r (23) = −0.37,  p  = .08]. 
 
 
 3.1.6. The visual–auditory task: by-subject based correlations between age and accuracy/reaction times 
 Because there were 3.3% outliers of accuracy trials outside 2.5  SD  from the group mean for each condition, we performed a reciprocal transformation for accuracy ( Kirk, 1995 ). Reaction times did not have outliers outside 2.5  SD  from the group mean for any condition. Therefore, no transformation was performed for reaction times. The correlation of age with accuracy was not significant for related pairs [ r (23) = −.34,  p  = .11] and the correlation of age with reaction times was not significant for related pairs [ r (23) = −0.38,  p  = .07]. 
 
 
 
 3.2. Brain activation patterns 
 The presentation of the results will focus on brain regions that have been implicated in previous studies of semantic processing, namely left inferior frontal gyrus, middle temporal gyrus and inferior parietal lobule. All activation differences are reported in the tables. Because similar results were found for the analysis of correct responses only and the analysis that includes all responses, only results from the analysis with all responses are presented to equate the statistical power between conditions with different accuracies ( Bitan et al., 2007 ). 
 Table 2  shows the main comparisons of the visual–visual and the visual–auditory semantic judgment tasks. The results show the comparison of related pairs or unrelated pairs versus perceptual controls, and the comparison of related pairs versus unrelated pairs. In the visual–visual semantic judgment task, both related and unrelated pairs compared to perceptual controls produced greater activation in the ventral regions of left inferior frontal gyrus (BA 45, 47). In addition, related pairs versus perceptual controls produced activation in left middle temporal gyrus (BA 21). The direct comparison of related versus unrelated pairs elicited greater activation in ventral regions of left inferior frontal gyrus (BA 45, 47) and left middle temporal gyrus (BA 21). In the visual–auditory semantic judgment task, the comparisons of both related and unrelated pairs versus perceptual controls also produced greater activation in the ventral regions of left inferior frontal gyrus (BA 45, 47). In addition, related pairs versus perceptual controls produced activation in left middle temporal gyrus (BA 21). The direct comparison of related versus unrelated pairs elicited greater activation in left middle temporal gyrus (BA 21) and left inferior parietal lobule (BA 39). 
 The effects of the strength of semantic association on signal intensity for related pairs are shown in  Table 3  and  Fig. 1 . In the visual–visual semantic judgment task, stronger association produced greater activation in the posterior region of left inferior parietal lobule (BA 39). Weaker association produced greater activation in the mid-ventral region of left inferior frontal gyrus (BA 45) ( p  < .005 uncorrected,  Z  = 3.11, 39 voxels). In the visual–auditory semantic judgment task, stronger association produced greater activation in the anterior region of left inferior parietal lobule (BA 40) ( Fig. 1a ). Weaker association produced greater activation in the mid-ventral region of left inferior frontal gyrus (BA 45) ( Fig. 1b ). The direct comparison of visual–auditory task versus visual–visual task on the contrast of weaker association elicited greater activation in left inferior frontal gyrus (BA 45). We further examined the effect of accuracy or reaction time on related pairs as an item-based (within-subject) covariate in both tasks. No significant effect was found for lower or higher accuracy for either task. No significant effect was found for slower or faster reaction times for either task. In addition, there was no BA 45 activation for the accuracy or reaction time contrasts at a lowered threshold of  p  < .005 uncorrected. Thus, accuracy or reaction time differences should not be responsible for the observed effects of semantic association strength. 
 The correlation between age in months and signal intensity, partialling out the effect of accuracy or reaction time in the scanner as a between-subject covariate, is shown in  Table 4  and  Fig. 2 . In the visual–visual semantic judgment task, when partialling for accuracy, increasing age was correlated with greater activation in the mid-ventral region of left inferior frontal gyrus (BA 45) ( p  < .005 uncorrected,  Z  = 3.02, 109 voxels) and left posterior middle temporal gyrus ( p  < .005 uncorrected,  Z  = 3.07, 162 voxels) for related pairs compared to perceptual controls. When partialling for reaction time, increasing age was correlated with greater activation in the mid-ventral region of left inferior frontal gyrus (BA 45) ( p  < .005 uncorrected,  Z  = 3.77, 73 voxels) for related pairs compared to perceptual controls. For unrelated pairs compared to perceptual controls, when partialling for accuracy or reaction time, there were no significant age effects. 
 In the visual–auditory semantic judgment task, both correlations show that increasing age was correlated with greater activation for related pairs compared to perceptual controls in the mid-ventral region of left inferior frontal gyrus (BA 45). When partialling for accuracy, additional left inferior frontal activation (BA 47) was found for the related pairs compared to perceptual controls. There was no decreasing age correlation for related pairs compared to perceptual controls. For unrelated pairs compared to perceptual controls, when partialling for accuracy or reaction time, there were no significant age effects. 
 For the task differences, we extracted beta values of the mid-ventral region of left inferior frontal gyrus for weaker association because the peaks of these effects were very close across tasks. The signal intensity in the visual–auditory task (mean = 4.06, standard deviation = 1.94) was greater than in the visual–visual task (mean = 2.77, standard deviation = 1.43), an independent  t  = 2.56,  p  = .01. In order to examine whether task differences changed developmentally, we performed two 2 task (visual–visual, visual–auditory) by 2 age (younger, older) ANCOVAs, partialled for behavioral performance (accuracy or reaction time) ( Fig. 3 ). First, we entered participants’ accuracy (reciprocal transformed) in the related condition as a covariate. This analysis showed a significant main effect of task,  F (1, 39) = 5.24,  p  = .03, reflecting greater signal intensity for the visual–auditory task than for the visual–visual task. The main effect of age was significant,  F (1, 39) = 4.51,  p  = .04, reflecting greater signal intensity for the older group than for the younger group. The interaction between task and age was significant,  F (1, 39) = 5.71,  p  = .02. A simple main effects analysis showed greater signal intensity for the visual–auditory task than for the visual–visual task in the older group ( t  = 3.23,  p  = .004). Second, we entered participants’ reaction time in the related condition as a covariate. This analysis showed a significant main effect of task,  F (1, 39) = 5.83,  p  = .02, reflecting greater signal intensity for the visual–auditory task than for the visual–visual task. The main effect of age was significant,  F (1, 39) = 6.00,  p  = .02, reflecting greater signal intensity for the older group than for the younger group. The interaction between task and age was significant,  F (1, 39) = 5.84,  p  = .02. A simple main effects analysis showed greater signal intensity for the visual–auditory task than for the visual–visual task in the older group ( t  = 3.23,  p  = .004). 
 
 
 
 4. Discussion 
 In the current study, the main goal was to test two competing hypotheses: greater phonological mediation versus greater demand on cognitive control for processing homophonic spoken words in Chinese. We examined the neural correlates of cross-modal semantic processing in a group of Chinese children (aged 10–15), by comparing visual–auditory to the visual–visual presentations. This design allowed us to evaluate mechanisms underlying the access of the appropriate meaning of homophonic spoken words in Chinese. In order to measure activation within the semantic system, we manipulated the strength of association between the words in related pairs. Words pairs with stronger semantic association elicited greater activation for both tasks in regions of the left inferior parietal lobule. In addition, weaker semantic association produced greater activation in the mid-ventral region of left inferior frontal gyrus (BA 45) for both tasks, but this effect was stronger in the visual–auditory presentation as compared to the visual–visual presentation. There were also greater developmental increases in the mid-ventral region of left inferior frontal gyrus (BA 45) in the visual–auditory presentation as compared to the visual–visual presentation. 
 The first major finding of our study was that weaker semantic association was correlated with greater activation in the mid-ventral region of left inferior frontal gyrus (BA 45) for both tasks, but this was greater in the visual–auditory presentation as compared to the visual–visual presentation. Greater activation in mid-ventral inferior frontal gyrus (BA 45) supports the hypothesis of greater engagement of cognitive control for the visual–auditory task than the visual–visual task in Chinese. The lack of task differences of activation in dorsal regions of inferior frontal gyrus (BA 44, 9) is not consistent with the phonological mediation hypothesis. Previous studies using association strength have found greater activation related to weaker association in the mid-ventral region of left inferior frontal gyrus ( Badre et al., 2005 ;  Chou et al., 2006a , b ). The greater activation in mid-ventral inferior frontal gyrus has been suggested to be associated with the selection among multiple competitors ( Thompson-Schill et al., 1999 ). In this study, participants may require greater selection processes to resolve competition among active representations for the visual–auditory task than for the visual–visual task. Greater activation in the mid-ventral region of left inferior frontal gyrus may be related to selecting the semantically correct answer among multiple competing homophones when Chinese words are presented auditorily. Due to the many homophones in Chinese, a sound may map into to an average of ten different visual characters and of ten different meanings, resulting in increased demands on mapping from phonology to orthography and from phonology to semantics. Participants may require, therefore, a greater selection process to perform the computations in the cross-modal task. Greater activation in the mid-ventral region of left inferior frontal gyrus may reflect the process of selection. 
 The task difference between the visual–visual and visual–auditory task in the current study does not seem to be due to modality or behavioral differences. Using auditory only presentation (i.e. the first and the second words were both auditorily presented),  Chou et al. (2006b)  also identified greater activation in the mid-ventral inferior frontal gyrus for the weaker related pairs during semantic judgments. These results suggest that greater activation in this region may be modality-independent (i.e., not affected by sensory modalities). Furthermore, because behavioral performance (reaction time and accuracy) was partialled out when examining association effects, any performance difference between the visual–visual task and the visual–auditory task may not be responsible for the inferior frontal activation. 
 Our second major finding was greater developmental increases in activation in the mid-ventral region of left inferior frontal gyrus (BA 45) for weaker semantic association in the visual–auditory presentation as compared to the visual–visual presentation. Because behavioral performance (reaction time and accuracy) was partialled out when examining age effects, any performance differences may not be responsible for age differences in the inferior frontal activation between the visual–visual task and the visual–auditory task. A Chinese study examining developmental differences has also shown age-related increases in the mid-ventral region of left inferior frontal gyrus with visual–visual presentation during semantic judgments ( Chou et al., 2009b ). In the current study, greater developmental increases in this region in the visual–auditory presentation may indicate that older children engage more thoroughly in selecting a semantically appropriate answer among homophones, producing greater activation in the mid-ventral region of left inferior frontal gyrus. Thus, our results suggest a developmental increase in involvement of semantic selection mechanisms in a cross-modal task requiring the access of the appropriate meaning of homophonic spoken words. In addition, behavioral studies have shown a developmental increase in executive functioning with gradual improvements between ages 11 and 15 ( Eigsti et al., 2006 ;  Leon-Carrion et al., 2004 ;  Luna et al., 2004 ). Imaging studies have also linked cognitive control to the maturation of inferior prefrontal cortex between ages 11 and 15 ( Adleman et al., 2002 ;  Bunge et al., 2002 ;  Tamm et al., 2002 ). Consistent with executive functioning/cognitive control studies, in the current study, greater activation for distantly related pairs in the prefrontal cortex, particularly for the older children, may imply greater cognitive control needed to select relevant features while ignoring irrelevant features. Due to developmental changes in the prefrontal cortex, older children may be more able to effectively recruit this region for cognitive control processes. This developmental trend is pronounced in the visual–auditory task because of the many homophones in Chinese. 
 A developmental increase was also observed in left posterior middle temporal gyrus in the visual–visual task when partialling out accuracy. Previous English and Chinese studies have identified age-related changes in this region ( Chou et al., 2006a , b ;  Szaflarski et al., 2006 ). This region is thought to be responsible for the storage of lexical representations ( Blumenfeld et al., 2006 ;  Booth et al., 2002 ;  Martin, 2007 ). Developmental increases in this region may reflect the elaboration of semantic knowledge with increasing numbers of semantic representations and stronger interconnections between these representations. 
 In the current study, only associative pairs with semantic relations were chosen as stimuli ( Lee et al., 2009 ). As revealed by our behavioral result, closely related pairs also had more overlapping features than distantly related pairs. The first word of the related pairs may act as a semantic constraint to reduce the number of activated candidates upon presentation of the second word. The greater overlapping semantic features in the closely related pairs may serve to reduce the number of meanings activated for the second word. In contrast, fewer shared features in the distantly related pairs may act as a weaker semantic constraint and thus elicit greater parallel activation of meanings for the second word (also see  Li and Yip, 1998 ).  Cree et al. (2006)  propose that distinctive features (that are not shared by other words) are activated much stronger and earlier than shared features. In the current study, the participants were required to perform meaning judgments by matching the shared/relevant features between two words. These judgments may require participants to ignore the irrelevant/distinctive features. The greater irrelevant or distinctive features in distantly related pairs may need greater cognitive control to ignore these features.  Thompson-Schill et al. (2005)  propose that a manipulation of associative strength may result in increased selection demands because weak activation of relevant information in distantly related pairs may make semantic knowledge more susceptible to interference. Therefore, the greater cognitive control needed for the distantly related pairs could be due both to (1) selecting the relevant/shared features and (2) ignoring the irrelevant/distinctive features. Moreover, because of the many homophones in Chinese, there are increased demands on cognitive control when words are presented auditorily as compared to when they are presented visually. 
 Finally, we found that stronger association elicited greater activation for both tasks in inferior parietal lobule, although this activation was slightly more anterior (BA 40) in the visual–auditory presentation, but more posterior (BA 39) in the visual–visual presentation. Posterior left inferior parietal lobule has been suggested to support the integration of lexical input into larger units for semantic processing ( Lau et al., 2008 ). Anterior left inferior parietal lobule has also been implicated as part of the phonological store ( Chen and Desmond, 2005 ;  Paulesu et al., 1993 ). When participants in this study were instructed to perform semantic judgments in the visual–auditory presentation, this may require greater phonological processing to facilitate integrating semantic features for highly related pairs because of the auditory component. Alternatively, multimodal integration studies have identified greater activation in the anterior region of left inferior parietal lobule ( Campbell, 2008 ;  Jones and Callan, 2003 ;  Naumer et al., 2009 ). This region is thought to synthesize multi-sensory information (i.e. visual and auditory inputs) ( Amedi et al., 2005 ;  Calvert, 2001 ;  Jones and Callan, 2003 ). Thus, in this study greater activation in this region may be related to the integration between visual and phonological information for stronger related pairs. 
 In conclusion, when comparing the visual–auditory presentation with the visual–visual presentation, weaker association produced greater activation in the mid-ventral region of left inferior frontal gyrus, suggesting increased demands of selection on processing homophones in Chinese in the cross-modal task. As compared to the visual–visual presentation, we additionally demonstrated greater developmental increases for weaker semantic association in the mid-ventral region of left inferior frontal gyrus in the visual–auditory presentation, suggesting greater involvement of semantic selection mechanisms with age in a cross-modal task requiring the access of the appropriate meaning of homophonic spoken words. 
 
 
 
 This research was supported by grants from the National Science Council of Taiwan (NSC 96-2413-H-002-023-MY2) and National Taiwan University (99R80854) to Tai-Li Chou. This research was also supported by grants from the National Institute of Child Health and Human Development (HD042049) to James R. Booth. This research was supported in part by the Department of Medical Imaging and 3T MRI Lab in National Taiwan University Hospital. 
 
 
 
 
 
 
 Adleman 
 NE 
 
 
 Blasey 
 CM 
 
 
 White 
 CD 
 
 
 Warsofsky 
 IS 
 
 
 Glover 
 GH 
 
 
 Reiss 
 AL 
 
 
 2002 
 A developmental functional fMRI study of the Stroop color-word task 
 NeuroImage 
 16 
 61 
 75 
 11969318 
 
 
 
 
 
 
 Amedi 
 A 
 
 
 von Kriegstein 
 K 
 
 
 van Atteveldt 
 NM 
 
 
 Beauchamp 
 MS 
 
 
 Naumer 
 MJ 
 
 
 2005 
 Functional imaging of human crossmodal identification and object recognition 
 Experimental Brain Research 
 166 
 559 
 571 
 
 
 
 
 
 
 Badre 
 D 
 
 
 Poldrack 
 RA 
 
 
 Pare-Blagoev 
 EJ 
 
 
 Insler 
 RZ 
 
 
 Wagner 
 AD 
 
 
 2005 
 Dissociable controlled retrieval and generalized selection mechanisms in ventrolateral prefrontal cortex 
 Neuron 
 47 
 907 
 918 
 16157284 
 
 
 
 
 
 
 Badre 
 D 
 
 
 Wagner 
 AD 
 
 
 2007 
 Left ventrolateral prefrontal cortex and the cognitive control of memory 
 Neuropsychologia 
 45 
 2883 
 2901 
 17675110 
 
 
 
 
 
 
 Barnea-Goraly 
 N 
 
 
 Menon 
 V 
 
 
 Eckert 
 M 
 
 
 Tamm 
 L 
 
 
 Bammer 
 R 
 
 
 Karchemskiy 
 A 
 
 
 Dant 
 CC 
 
 
 Reiss 
 AL 
 
 
 2005 
 White matter development during childhood and adolescence: a cross-sectional diffusion tensor imaging study 
 Cerebral Cortex 
 15  
 12 
 1848 
 1854 
 15758200 
 
 
 
 
 
 
 Bedny 
 M 
 
 
 McGill 
 M 
 
 
 Thompson-Schill1 
 SL 
 
 
 2008 
 Semantic adaptation and competition during word comprehension 
 Cerebral Cortex 
 18 
 2574 
 2585 
 18308708 
 
 
 
 
 
 
 Binder 
 JR 
 
 
 Liebenthal 
 E 
 
 
 Possing 
 ET 
 
 
 Medler 
 TA 
 
 
 Ward 
 BD 
 
 
 2004 
 Neural correlates of sensory and decision processes in auditory object identification 
 Nature Neuroscience 
 7  
 3 
 295 
 301 
 
 
 
 
 
 
 Bitan 
 T 
 
 
 Burman 
 DD 
 
 
 Chou 
 TL 
 
 
 Lu 
 D 
 
 
 Cone 
 NE 
 
 
 Cao 
 F 
 
 
 Bigio 
 JD 
 
 
 Booth 
 JR 
 
 
 2007 
 The interaction between orthographic and phonological information in children: an fMRI study 
 Human Brain Mapping 
 28  
 9 
 880 
 891 
 17133384 
 
 
 
 
 
 
 Blakemore 
 SJ 
 
 
 Choudhury 
 S 
 
 
 2006 
 Development of the adolescent brain: implications for executive function and social cognition 
 Journal of Child Psychology and Psychiatry 
 47  
 3 
 296 
 312 
 16492261 
 
 
 
 
 
 
 Blumenfeld 
 HK 
 
 
 Booth 
 JR 
 
 
 Burman 
 DD 
 
 
 2006 
 Differential prefrontal–temporal neural correlates of semantic processing in children 
 Brain and Language 
 99 
 226 
 235 
 16098571 
 
 
 
 
 
 
 Boersma 
 P 
 
 
 Weenink 
 D 
 
 
 2007 
 Praat: doing phonetics by computer [Computer program] 
 Version 4.6.22, From  http://www.praat.org/  (retrieved 22.10.07) 
 
 
 
 
 
 
 Bolger 
 DJ 
 
 
 Minas 
 J 
 
 
 Burman 
 DD 
 
 
 Booth 
 JR 
 
 
 2008 
 Differential effects of orthographic and phonological consistency in cortex for children with and without reading impairment 
 Neuropsychologia 
 46 
 3210 
 3224 
 18725239 
 
 
 
 
 
 
 Booth 
 JR 
 
 
 Burman 
 DD 
 
 
 Meyer 
 JR 
 
 
 Gitelman 
 DR 
 
 
 Parrish 
 TD 
 
 
 Mesulam 
 MM 
 
 
 2002 
 Modality independence of word comprehension 
 Human Brain Mapping 
 16 
 251 
 261 
 12112766 
 
 
 
 
 
 
 Booth 
 JR 
 
 
 Cho 
 S 
 
 
 Burman 
 DD 
 
 
 Bitan 
 T 
 
 
 2007 
 Neural correlates of mapping from phonology to orthography in children performing an auditory spelling task 
 Developmental Science 
 10  
 4 
 441 
 451 
 17552934 
 
 
 
 
 
 
 Booth 
 JR 
 
 
 Burman 
 DD 
 
 
 Meyer 
 JR 
 
 
 Gitelman 
 DR 
 
 
 Parrish 
 TB 
 
 
 Mesulam 
 MM 
 
 
 2004 
 Development of brain mechanisms for processing orthographic and phonologic representations 
 Journal of Cognitive Neuroscience 
 16  
 7 
 1234 
 1249 
 15453976 
 
 
 
 
 
 
 Botvinick 
 MM 
 
 
 Braver 
 TS 
 
 
 Barch 
 DM 
 
 
 Carter 
 CS 
 
 
 Cohen 
 JD 
 
 
 2001 
 Conflict monitoring and cognitive control 
 Psychological Review 
 108  
 3 
 624 
 652 
 11488380 
 
 
 
 
 
 
 Botvinick 
 MM 
 
 
 Cohen 
 JD 
 
 
 Carter 
 CS 
 
 
 2004 
 Conflict monitoring and anterior cingulate cortex: an update 
 Trends in Cognitive Sciences 
 8  
 12 
 539 
 546 
 15556023 
 
 
 
 
 
 
 Bunge 
 SA 
 
 
 Dudukovic 
 NM 
 
 
 Thomason 
 ME 
 
 
 Vaidya 
 CJ 
 
 
 Gabrieli 
 J 
 
 
 2002 
 Immature frontal lobe contributions to cognitive control in children: evidence from fMRI 
 Neuron 
 33 
 301 
 311 
 11804576 
 
 
 
 
 
 
 Burock 
 MA 
 
 
 Buckner 
 RL 
 
 
 Woldorff 
 MG 
 
 
 Rosen 
 BR 
 
 
 Dale 
 AM 
 
 
 1998 
 Randomized event-related experimental designs allow for extremely rapid presentation rates using functional MRI 
 Neuroreport 
 9 
 3735 
 3739 
 9858388 
 
 
 
 
 
 
 Calvert 
 GA 
 
 
 2001 
 Crossmodal processing in the human brain: insights from functional neuroimaging studies 
 Cerebral Cortex 
 11 
 1110 
 1123 
 11709482 
 
 
 
 
 
 
 Campbell 
 R 
 
 
 2008 
 The processing of audio-visual speech: empirical and neural bases 
 Philosophical Transactions of the Royal Society B 
 363 
 1001 
 1010 
 
 
 
 
 
 
 Cao 
 F 
 
 
 Peng 
 D 
 
 
 Liu 
 L 
 
 
 Jin 
 Z 
 
 
 Fan 
 N 
 
 
 Deng 
 Y 
 
 
 Booth 
 JR 
 
 
 2009 
 Developmental differences of neurocognitive networks for phonological and semantic processing in Chinese word reading 
 Human Brain Mapping 
 30 
 797 
 809 
 18330872 
 
 
 
 
 
 
 Chen 
 SH 
 
 
 Desmond 
 JE 
 
 
 2005 
 Temporal dynamics of cerebro-cerebellar network recruitment during a cognitive task 
 Neuropsychologia 
 43 
 1227 
 1237 
 15949507 
 
 
 
 
 
 
 Chou 
 TL 
 
 
 Booth 
 JR 
 
 
 Bitan 
 T 
 
 
 Burman 
 DD 
 
 
 Bigio 
 JD 
 
 
 Cone 
 NE 
 
 
 Lu 
 D 
 
 
 Cao 
 F 
 
 
 2006a 
 Developmental and skill effects on the neural correlates of semantic processing to visually presented words 
 Human Brain Mapping 
 27 
 915 
 924 
 16575838 
 
 
 
 
 
 
 Chou 
 TL 
 
 
 Booth 
 JR 
 
 
 Burman 
 DD 
 
 
 Bitan 
 T 
 
 
 Bigio 
 JD 
 
 
 Lu 
 D 
 
 
 Cone 
 NE 
 
 
 2006b 
 Developmental changes in the neural correlates of semantic processing 
 NeuroImage 
 29 
 1141 
 1149 
 16275017 
 
 
 
 
 
 
 Chou 
 TL 
 
 
 Chen 
 CW 
 
 
 Wu 
 MY 
 
 
 Booth 
 JR 
 
 
 2009a 
 The role of inferior frontal gyrus and inferior parietal lobule in semantic processing of Chinese characters 
 Experimental Brain Research 
 198 
 465 
 475 
 
 
 
 
 
 
 Chou 
 TL 
 
 
 Chen 
 CW 
 
 
 Fan 
 LY 
 
 
 Chen 
 SY 
 
 
 Booth 
 JR 
 
 
 2009b 
 Testing for a cultural influence on reading for meaning in the developing brain: The neural basis of semantic processing in Chinese children 
 Frontiers in Human Neuroscience 
 3  
 27 
 1 
 9 
 
 
 
 
 
 
 Coltheart 
 M 
 
 
 Rastle 
 K 
 
 
 Perry 
 C 
 
 
 Langdon 
 R 
 
 
 Ziegler 
 J 
 
 
 2001 
 DRC: a dual route cascaded model of visual word recognition and reading aloud 
 Psychological Review 
 108  
 1 
 204 
 256 
 11212628 
 
 
 
 
 
 
 Cone 
 NE 
 
 
 Burman 
 DD 
 
 
 Bitan 
 T 
 
 
 Bolger 
 DJ 
 
 
 Booth 
 JR 
 
 
 2008 
 Developmental changes in brain regions involved in phonological and orthographic processing during spoken language processing 
 NeuroImage 
 41  
 2 
 623 
 635 
 18413290 
 
 
 
 
 
 
 Cree 
 GS 
 
 
 McNorgan 
 C 
 
 
 McRae 
 K 
 
 
 2006 
 Distinctive features hold a privileged status in the computation of word meaning: implications for theories of semantic memory 
 Journal of Experimental Psychology 
 32  
 4 
 643 
 658 
 16822138 
 
 
 
 
 
 
 Cristescua 
 TC 
 
 
 Devlin 
 JT 
 
 
 Nobre 
 AC 
 
 
 2006 
 Orienting attention to semantic categories 
 NeuroImage 
 33  
 4–3 
 1178 
 1187 
 17011212 
 
 
 
 
 
 
 Eigsti 
 IM 
 
 
 Zayas 
 V 
 
 
 Mischel 
 W 
 
 
 Shoda 
 Y 
 
 
 Ayduk 
 O 
 
 
 Dadlami 
 MB 
 
 
 Davisaon 
 MC 
 
 
 Aber 
 JL 
 
 
 Casey 
 BJ 
 
 
 2006 
 Predicting cognitive control from preschool to late adolescence and young adulthood 
 Psychological Science 
 17  
 6 
 478 
 484 
 16771797 
 
 
 
 
 
 
 Fiez 
 JA 
 
 
 Balota 
 DA 
 
 
 Raichle 
 ME 
 
 
 Petersen 
 SE 
 
 
 1999 
 Effects of lexicality, frequency, and spelling-to-sound consistency on the functional anatomy of reading 
 Neuron 
 24 
 205 
 218 
 10677038 
 
 
 
 
 
 
 Fletcher 
 PC 
 
 
 Shallice 
 T 
 
 
 Dolan 
 RJ 
 
 
 2000 
 Sculpting the response space”—an account of left prefrontal activation at encoding 
 NeuroImage 
 12 
 404 
 417 
 10988034 
 
 
 
 
 
 
 Gandour 
 J 
 
 
 Xu 
 Y 
 
 
 Wong 
 D 
 
 
 Dzemidzic 
 M 
 
 
 Lowe 
 M 
 
 
 Li 
 X 
 
 
 Tong 
 Y 
 
 
 2003 
 Neural correlates of segmental and tonal information in speech perception 
 Human Brain Mapping 
 20 
 185 
 200 
 14673803 
 
 
 
 
 
 
 Giedd 
 JN 
 
 
 1999 
 Brain development during childhood and adolescence: a longitudinal MRI study 
 Nature Neuroscience 
 2 
 861 
 863 
 
 
 
 
 
 
 Gogtay 
 N 
 
 
 Giedd 
 JN 
 
 
 Lusk 
 L 
 
 
 Hayashi 
 KM 
 
 
 Greenstein 
 D 
 
 
 Vaituzis 
 AC 
 
 
 Nugent 
 TF 
 III 
 
 
 Herman 
 DH 
 
 
 Clasen 
 LS 
 
 
 Toga 
 AW 
 
 
 Rapoport 
 JL 
 
 
 Thompson 
 PM 
 
 
 2004 
 Dynamic mapping of human cortical development during childhood through early adulthood 
 Proceedings of the National Academy of Sciences USA 
 101 
 8174 
 8179 
 
 
 
 
 
 
 Grainger 
 J 
 
 
 Van Kang 
 MN 
 
 
 Segui 
 J 
 
 
 2001 
 Cross-modal repetition priming of heterographic homophones 
 Memory and Cognition 
 29  
 1 
 53 
 61 
 
 
 
 
 
 
 Grossman 
 M 
 
 
 Koenig 
 P 
 
 
 Glosser 
 G 
 
 
 DeVita 
 C 
 
 
 Moore 
 P 
 
 
 Rhee 
 J 
 
 
 Detre 
 J 
 
 
 Alsop 
 D 
 
 
 Gee 
 J 
 
 
 2003 
 Neural basis for semantic memory difficulty in Alzheimer’s disease: an fMRI study 
 Brain 
 126 
 292 
 311 
 12538399 
 
 
 
 
 
 
 Huang 
 CR 
 
 
 1998 
 Academia Sinica Balanced Corpus 
 3 
 Academia Sinica 
 Taipei, Taiwan 
 
 
 
 
 
 
 Hue 
 CW 
 
 
 Kao 
 CH 
 
 
 Lo 
 M 
 
 
 2005 
 Association Norms for 600 Chinese Characters 
 Taiwanese Psychological Association 
 
 
 
 
 
 
 Hung 
 KC 
 
 
 Lee 
 SH 
 
 
 Chen 
 SY 
 
 
 Chou 
 TL 
 
 
 2010 
 Effects of semantic radical and semantic association on semantic processing of Chinese characters for adults and fifth graders 
 Chinese Journal of Psychology 
 52  
 3 
 327 
 344 
 
 
 
 
 Institute of Linguistics, the Academy of Social Sciences 
 1985 
 Xiadai hanyu cidian (Modern Chinese dictionary) 
 Commercial Press 
 Beijing 
 
 
 
 
 
 
 Jones 
 JA 
 
 
 Callan 
 DE 
 
 
 2003 
 Brain activity during audiovisual speech perception: an fMRI study of the McGurk effect 
 NeuroReport 
 14  
 8 
 1129 
 1133 
 12821795 
 
 
 
 
 
 
 Josephs 
 O 
 
 
 Henson 
 RN 
 
 
 1999 
 Event-related functional magnetic resonance imaging: modelling, inference and optimization 
 Philosophical Transactions of the Royal Society B 
 354 
 1215 
 1228 
 
 
 
 
 
 
 Kan 
 IP 
 
 
 Thompson-Schill 
 SL 
 
 
 2004 
 Selection from perceptual and conceptual representations 
 Cognitive, Affective, and Behavioral Neuroscience 
 4  
 4 
 466 
 482 
 
 
 
 
 
 
 Kirk 
 RE 
 
 
 1995 
 Experimental Design: Procedures for the Behavioural Sciences 
 3 
 Brooks/Cole 
 Belmont, CA 
 
 
 
 
 
 
 Kiyonaga 
 K 
 
 
 Grainger 
 J 
 
 
 Midgley 
 K 
 
 
 Holcomb 
 PJ 
 
 
 2007 
 Masked cross-modal repetition priming: an event-related potential investigation 
 Language and Cognitive Process 
 22  
 3 
 337 
 376 
 
 
 
 
 
 
 Koenig 
 P 
 
 
 Smith 
 EE 
 
 
 Glosser 
 G 
 
 
 DeVita 
 C 
 
 
 Moore 
 P 
 
 
 McMillan 
 C 
 
 
 Gee 
 J 
 
 
 Grossman 
 M 
 
 
 2005 
 The neural basis for novel semantic categorization 
 NeuroImage 
 24 
 369 
 383 
 15627580 
 
 
 
 
 
 
 Kuperberg 
 GR 
 
 
 Lakshmanan 
 BM 
 
 
 Greve 
 DN 
 
 
 West 
 WC 
 
 
 2008 
 Task and semantic relationship influence both the polarity and localization of hemodynamic modulation during lexicosemantic processing 
 Human Brain Mapping 
 29 
 544 
 561 
 17674356 
 
 
 
 
 
 
 Lamm 
 C 
 
 
 Zelazo 
 PD 
 
 
 Lewis 
 MD 
 
 
 2006 
 Neural correlates of cognitive control in childhood and adolescence: disentangling the contributions of age and executive function 
 Neuropsychologia 
 44 
 2139 
 2148 
 16310813 
 
 
 
 
 
 
 Lau 
 EF 
 
 
 Phillips 
 C 
 
 
 Poeppel 
 D 
 
 
 2008 
 A cortical network for semantics: (de)constructing the N400 
 Nature Review Neuroscience 
 9 
 920 
 933 
 
 
 
 
 
 
 Lee 
 SH 
 
 
 Chen 
 SY 
 
 
 Chou 
 TL 
 
 
 2009 
 Effect of vocabulary size on semantic processing of Chinese characters for fifth graders and adults 
 Formosa Journal of Mental Health 
 22  
 4 
 345 
 382 
 
 
 
 
 
 
 Leon-Carrion 
 J 
 
 
 Garcia-Orza 
 J 
 
 
 Perez-Santamaria 
 FJ 
 
 
 2004 
 Development of the inhibitory component of the executive functions in children and adolescents 
 International Journal of Neuroscience 
 114  
 10 
 1291 
 1311 
 15370187 
 
 
 
 
 
 
 Li 
 P 
 
 
 Yip 
 M 
 
 
 1998 
 Context effects and the processing of spoken homophones 
 Reading and Writing: An Interdisciplinary Journal 
 10 
 223 
 243 
 
 
 
 
 
 
 Liston 
 C 
 
 
 Watts 
 R 
 
 
 Tottenham 
 N 
 
 
 Davidson 
 MC 
 
 
 Niogi 
 S 
 
 
 Ulug 
 AM 
 
 
 Casey 
 BJ 
 
 
 2005 
 Frontostriatal microstructure modulates efficient recruitment of cognitive control 
 Cerebral Cortex 
 16 
 553 
 560 
 16033925 
 
 
 
 
 
 
 Liu 
 L 
 
 
 Deng 
 X 
 
 
 Peng 
 D 
 
 
 Cao 
 F 
 
 
 Ding 
 G 
 
 
 Jin 
 Z 
 
 
 Zeng 
 Y 
 
 
 Li 
 K 
 
 
 Zhu 
 L 
 
 
 Fan 
 N 
 
 
 Deng 
 Y 
 
 
 Bolger 
 DJ 
 
 
 Booth 
 JR 
 
 
 2009 
 Modality- and task-specific brain regions involved in Chinese lexical processing 
 Journal of Cognitive Neuroscience 
 21  
 8 
 1473 
 1487 
 18823229 
 
 
 
 
 
 
 Luna 
 B 
 
 
 Garver 
 KE 
 
 
 Urban 
 TA 
 
 
 Lazar 
 NA 
 
 
 Sweeney 
 JA 
 
 
 2004 
 Maturation of cognitive processes from late childhood to adulthood 
 Child Development 
 75  
 5 
 1357 
 1372 
 15369519 
 
 
 
 
 
 
 Marslen-Wilson 
 W 
 
 
 Zwitserlood 
 P 
 
 
 1989 
 Accessing spoken words: on the importance of word onset 
 Journal of Experimental Psychology: Human Perception and Performance 
 15 
 576 
 585 
 
 
 
 
 
 
 Martin 
 A 
 
 
 2007 
 The representation of object concepts in the brain 
 Annual Review of Psychology 
 58 
 25 
 45 
 
 
 
 
 
 
 Nagy 
 Z 
 
 
 Westerberg 
 H 
 
 
 Klingberg 
 T 
 
 
 2004 
 Maturation of white matter is associated with the development of cognitive functions during childhood 
 Journal of Cognitive Neuroscience 
 16 
 1227 
 1233 
 15453975 
 
 
 
 
 
 
 Naumer 
 MJ 
 
 
 Doehrmann 
 O 
 
 
 Müller 
 NG 
 
 
 Muckli 
 L 
 
 
 Kaiser 
 J 
 
 
 Hein 
 G 
 
 
 2009 
 Cortical plasticity of audio–visual object representations 
 Cerebral Cortex 
 19 
 1641 
 1653 
 19015373 
 
 
 
 
 
 
 Nelson 
 DL 
 
 
 McEvoy 
 CL 
 
 
 Schreiber 
 TA 
 
 
 1998 
 The University of South Florida word association, rhyme, and word fragment norms 
 
 http://www.usf.edu/FreeAssociation 
 
 
 
 
 
 
 
 Noppeney 
 U 
 
 
 Josephs 
 O 
 
 
 Hocking 
 J 
 
 
 Price 
 CJ 
 
 
 Friston 
 KJ 
 
 
 2007 
 The effect of prior visual information on recognition of speech and sounds 
 Cerebral Cortex 
 18  
 3 
 598 
 609 
 17617658 
 
 
 
 
 
 
 Paus 
 T 
 
 
 Zijdenbos 
 A 
 
 
 Worsley 
 K 
 
 
 Collins 
 DL 
 
 
 Blumenthal 
 J 
 
 
 Giedd 
 JN 
 
 
 Rapoport 
 JL 
 
 
 Evans 
 AC 
 
 
 1999 
 Structural maturation of neural pathways in children and adolescents: in vivo study 
 Science 
 283  
 5409 
 1908 
 1911 
 10082463 
 
 
 
 
 
 
 Paulesu 
 E 
 
 
 Frith 
 CD 
 
 
 Frackowiak 
 RSJ 
 
 
 1993 
 The neural correlates of the verbal component of working memory 
 Nature 
 362 
 342 
 345 
 8455719 
 
 
 
 
 
 
 Pexman 
 PM 
 
 
 Hargreaves 
 IS 
 
 
 Edwards 
 JD 
 
 
 Henry 
 LC 
 
 
 Goodyear 
 BG 
 
 
 2007 
 Neural correlates of concreteness in semantic categorization 
 Journal of Cognitive Neuroscience 
 19  
 8 
 1407 
 1419 
 17651011 
 
 
 
 
 
 
 Plaut 
 DC 
 
 
 McClelland 
 JL 
 
 
 Seidenberg 
 MS 
 
 
 Patterson 
 K 
 
 
 1996 
 Understanding normal and impaired word reading: Computational principles in quasi-regular domains 
 Psychological Review 
 103  
 1 
 56 
 115 
 8650300 
 
 
 
 
 
 
 Poldrack 
 RA 
 
 
 Wagner 
 AD 
 
 
 Prull 
 MW 
 
 
 Desmond 
 JE 
 
 
 Glover 
 GH 
 
 
 Gabrieli 
 JD 
 
 
 1999 
 Functional specialization for semantic and phonological processing in the left inferior prefrontal cortex 
 Neuroimage 
 10 
 15 
 35 
 10385578 
 
 
 
 
 
 
 Raposo 
 A 
 
 
 Moss 
 HE 
 
 
 Stamatakis 
 EA 
 
 
 Tyler 
 LK 
 
 
 2006 
 Repetition suppression and semantic enhancement: an investigation of the neural correlates of priming 
 Neuropsychologia 
 44  
 12 
 2284 
 2295 
 16806317 
 
 
 
 
 
 
 Reich 
 S 
 
 
 Chou 
 TL 
 
 
 Patterson 
 K 
 
 
 2003 
 Acquired dysgraphia in Chinese: further evidence on the link between phonology and orthography 
 Aphasiology 
 17 
 585 
 604 
 
 
 
 
 
 
 Shaw 
 P 
 
 
 Greenstein 
 D 
 
 
 Lerch 
 J 
 
 
 Clasen 
 L 
 
 
 Lenroot 
 R 
 
 
 Gogtay 
 N 
 
 
 Evans 
 A 
 
 
 Rapoport 
 J 
 
 
 Giedd 
 J 
 
 
 2006 
 Intellectual ability and cortical development in children and adolescents 
 Science 
 440  
 30 
 676 
 679 
 
 
 
 
 
 
 Snyder 
 HR 
 
 
 Feigenson 
 K 
 
 
 Thompson-Schill 
 SL 
 
 
 2007 
 Prefrontal cortical response to conflict during semantic and phonological tasks 
 Journal of Cognitive Neuroscience 
 19  
 5 
 761 
 775 
 17488203 
 
 
 
 
 
 
 Sowell 
 ER 
 
 
 Peterson 
 BS 
 
 
 Thompson 
 PM 
 
 
 Welcome 
 SE 
 
 
 Henkenius 
 AL 
 
 
 Toga 
 AW 
 
 
 2003 
 Mapping cortical change across the human life span 
 Nature Neuroscience 
 6  
 3 
 309 
 315 
 
 
 
 
 
 
 Sowell 
 ER 
 
 
 Thompson 
 PM 
 
 
 Tessner 
 KD 
 
 
 Toga 
 AW 
 
 
 2001 
 Mapping continued brain growth and gray matter density reduction in dorsal frontal cortex: inverse relationships during post-adolescent brain maturation 
 Journal of Neuroscience 
 21 
 8819 
 8829 
 11698594 
 
 
 
 
 
 
 Szaflarski 
 JP 
 
 
 Schmithorst 
 VJ 
 
 
 Altaye 
 M 
 
 
 Byars 
 AW 
 
 
 Ret 
 J 
 
 
 Plante 
 E 
 
 
 Holland 
 SK 
 
 
 2006 
 A longitudinal functional magnetic resonance imaging study of language development in children 5 to 11 years old 
 Annual of Neurology 
 59 
 796 
 807 
 
 
 
 
 
 
 Tamm 
 L 
 
 
 Menon 
 V 
 
 
 Reiss 
 AL 
 
 
 2002 
 Maturation of brain function associated with response inhibition 
 Journal of the American Academy of Child and Adolescent Psychiatry 
 41 
 1231 
 1238 
 12364845 
 
 
 
 
 
 
 Thompson-Schill 
 SL 
 
 
 Bedny 
 M 
 
 
 Goldberg 
 RF 
 
 
 2005 
 The frontal lobes and the regulation of mental activity 
 Current Opinion in Neurobiology 
 15 
 219 
 224 
 15831406 
 
 
 
 
 
 
 Thompson-Schill 
 SL 
 
 
 D’Esposito 
 M 
 
 
 Aguirre 
 GK 
 
 
 Farah 
 MJ 
 
 
 1997 
 Role of left inferior prefrontal cortex in retrieval of semantic knowledge: a reevaluation 
 Proceedings of the National Academy of Sciences USA 
 94 
 14792 
 14797 
 
 
 
 
 
 
 Thompson-Schill 
 SL 
 
 
 D’Esposito 
 M 
 
 
 Kan 
 IP 
 
 
 1999 
 Effects of repetition and competition on activity in left prefrontal cortex during word generation 
 Neuron 
 23 
 513 
 522 
 10433263 
 
 
 
 
 
 
 Whatmough 
 C 
 
 
 Arguin 
 M 
 
 
 Bub 
 D 
 
 
 1999 
 Cross-modal priming evidence for phonology-to-orthography activation in visual word recognition 
 Brain and Language 
 66 
 275 
 293 
 10190990 
 
 
 
 
 
 
 Williams 
 BR 
 
 
 Ponesse 
 JS 
 
 
 Schachar 
 RJ 
 
 
 Logan 
 GD 
 
 
 Tannock 
 R 
 
 
 1999 
 Development of inhibitory control across the life span 
 Developmental Psychology 
 35  
 1 
 205 
 213 
 9923475 
 
 
 
 
 
 
 Wu 
 JT 
 
 
 Liu 
 IM 
 
 
 1987 
 Exploring the Phonetic and Semantic Features of Chinese Words 
 Taiwan National Science Council 
 Technical Report NSC75-0301-H002-024 
 
 
 
 
 
 
 Wu 
 SN 
 
 
 Shu 
 H 
 
 
 Wang 
 Y 
 
 
 2004 
 The heterogeneity of Chinese developmental dyslexia 
 Psychological Development and Education 
 3 
 46 
 50 
 
 
 
 
 
 
 Fig. 1 
 
 Effects of association strength in the visual–visual semantic judgment task: (a) stronger association produced greater activation for related pairs in the posterior region of left inferior parietal lobule (IPL, BA 39); (b) weaker association produced greater activation for related pairs in the mid-ventral region of left inferior frontal gyrus (IFG, BA 45). Effects of association strength in the visual–auditory semantic judgment task: (c) stronger association produced greater activation for related pairs in the anterior region of left inferior parietal lobule (IPL, BA 40); (d) weaker association produced greater activation for related pairs in the mid-ventral region of left inferior frontal gyrus (IFG, BA 45). 
 
 
 
 
 Fig. 2 
 
 (a) Effects of age in the visual–visual semantic judgment task. Increasing age, partialled for accuracy, was correlated with greater activation in the mid-ventral region of left inferior frontal gyrus (IFG, BA 45) for related pairs compared to perceptual controls. (b) Effects of age in the visual–auditory semantic judgment task. Increasing age, partialled for accuracy, was correlated with greater activation in the mid-ventral region of left inferior frontal gyrus (IFG, BA 45) for related pairs compared to perceptual controls. 
 
 
 
 
 Fig. 3 
 
 Age differences in signal intensity for the visual–visual task and the visual–auditory task. Beta values were taken from the peak voxels of the mid-ventral region of left inferior frontal gyrus (BA 45) for the weaker association effect. 
 
 
 
 
 Table 1 
 
 Stimulus characteristics for first (1st) words and second (2nd) words in the related and unrelated conditions for written word frequency for adults ( Wu and Liu, 1987 ) and for written word familiarity for children. The numbers of homophones (logarithmic transformation) of the second word in the related and unrelated conditions are also presented ( Lee et al., 2009 ). Standard deviations are in parentheses. The correlations of word frequency and familiarity with association strength in the related condition are presented. The correlation of the number of homophones for the second words with association strength in the related condition is also presented. 
 
 
 
 
 
 Frequency
 
 Familiarity
 
 Homophones
 
 
 
 Related 
 Unrelated 
 Related 
 Unrelated 
 Related 
 Unrelated 
 
 
 
 
 1st word 
 167 (295) 
 237 (267) 
 6.0 (0.5) 
 6.1 (0.4) 
 
 
 
 
 2nd word 
 462 (751) 
 201 (174) 
 6.4 (0.3) 
 6.2 (0.4) 
 1.06 (0.4) 
 1.23 (0.4) 
 
 
 1st word correlation 
 −.01 
 
 −.04 
 
 
 
 
 
 2nd word correlation 
 −.02 
 
 .02 
 
 −.13 
 
 
 
 
 
 
 Table 2 
 
 Greater activation for related or unrelated pairs compared to perceptual controls, and for related compared to unrelated pairs in the visual–visual and the visual–auditory tasks. 
 
 
 
 
 Task 
 Condition 
 Regions 
 H 
 BA 
 z -Test 
 Voxels 
 
 x 
 
 
 y 
 
 
 z 
 
 
 
 
 
 Visual–visual 
 Related – perceptual 
 Inferior frontal gyrus 
 L 
 47 
 6.40 
 1471 
 −42 
 27 
 0 
 
 
 
 
 Inferior frontal gyrus 
 L 
 45 
 
 
 −42 
 18 
 9 
 
 
 
 
 Premotor 
 L 
 6 
 6.16 
 1006 
 −6 
 9 
 63 
 
 
 
 
 Globus pallidus 
 L 
 – 
 
 631 
 −12 
 6 
 0 
 
 
 
 
 Inferior frontal gyrus 
 R 
 47 
 4.49 
 97 
 36 
 18 
 −3 
 
 
 
 
 Middle temporal gyrus 
 L 
 21 
 4.43 
 137 
 −63 
 −48 
 0 
 
 
 
 
 Superior occipital gyrus 
 L 
 19 
 3.75 
 42 
 −18 
 −48 
 −3 
 
 
 
 Unrelated – perceptual 
 Inferior frontal gyrus 
 L 
 47 
 5.15 
 835 
 −42 
 27 
 0 
 
 
 
 
 Inferior frontal gyrus 
 L 
 45 
 
 
 −48 
 24 
 15 
 
 
 
 
 Medial frontal gyrus 
 L 
 9 
 
 
 −48 
 18 
 27 
 
 
 
 
 Premotor 
 L 
 6 
 4.39 
 132 
 −3 
 6 
 63 
 
 
 
 Related–unrelated 
 Superior frontal gyrus 
 L 
 8 
 4.47 
 642 
 −6 
 36 
 48 
 
 
 
 
 Inferior frontal gyrus 
 L 
 47 
 4.26 
 306 
 −54 
 27 
 −3 
 
 
 
 
 Inferior frontal gyrus 
 L 
 45 
 
 
 −54 
 24 
 12 
 
 
 
 
 Caudate 
 L 
 - 
 3.91 
 89 
 −12 
 9 
 9 
 
 
 
 
 Middle temporal gyrus 
 L 
 21 
 3.81 
 32 
 −63 
 −36 
 −6 
 
 
 Visual–auditory 
 Related – perceptual 
 Inferior frontal gyrus 
 L 
 47 
 5.42 
 649 
 −48 
 30 
 −3 
 
 
 
 
 Inferior frontal gyrus 
 L 
 45 
 
 
 −48 
 21 
 9 
 
 
 
 
 Superior frontal gyrus 
 L 
 8 
 5.19 
 636 
 −9 
 42 
 45 
 
 
 
 
 Middle temporal gyrus 
 L 
 21 
 4.51 
 87 
 −63 
 −24 
 0 
 
 
 
 
 Orbitofrontal gyrus 
 L 
 11 
 4.31 
 56 
 −3 
 30 
 −15 
 
 
 
 
 Anterior cingulate 
 L 
 24 
 3.94 
 80 
 −9 
 0 
 27 
 
 
 
 
 Globus pallidus 
 L 
 - 
 3.20 
 57 
 −15 
 0 
 −3 
 
 
 
 
 Inferior frontal gyrus 
 R 
 47 
 3.74 
 25 
 30 
 9 
 −18 
 
 
 
 Unrelated – perceptual 
 Inferior frontal gyrus 
 L 
 47 
 5.34 
 334 
 −48 
 27 
 0 
 
 
 
 
 Inferior frontal gyrus 
 L 
 45 
 
 
 −51 
 24 
 18 
 
 
 
 
 Superior frontal gyrus 
 L 
 8 
 4.23 
 92 
 −9 
 48 
 45 
 
 
 
 
 Posterior cingulate 
 R 
 31 
 3.90 
 42 
 18 
 −39 
 27 
 
 
 
 Related–unrelated 
 Medial frontal gyrus 
 L 
 9 
 5.00 
 692 
 −6 
 39 
 21 
 
 
 
 
 Globus pallidus 
 L 
 – 
 
 102 
 −12 
 6 
 0 
 
 
 
 
 Middle temporal gyrus 
 L 
 21 
 4.19 
 29 
 −63 
 −48 
 −6 
 
 
 
 
 Superior frontal gyrus 
 L 
 8 
 4.08 
 136 
 −18 
 45 
 42 
 
 
 
 
 Inferior frontal gyrus 
 L 
 45 
 3.04 
 16 
 −48 
 39 
 3 
 
 
 
 
 Paracentral lobule 
 R 
 7 
 4.33 
 87 
 6 
 −66 
 57 
 
 
 
 
 Middle temporal gyrus 
 R 
 21 
 4.25 
 22 
 60 
 −57 
 −6 
 
 
 
 
 Superior occipital gyrus 
 L 
 19 
 4.22 
 125 
 −36 
 −78 
 33 
 
 
 
 
 Inferior parietal lobule 
 L 
 39 
 
 
 −51 
 −72 
 21 
 
 
 
 
 
 Note : H: hemisphere, L: left, R: right, BA: Brodmann’s area. Coordinates of activation peak(s) within a region based on a  z -test are given in the MNI stereotactic space ( x ,  y ,  z ).  Voxels : number of voxels in cluster at FDR  p  < .05 corrected, only clusters greater than or equal to 10 are presented. 
 
 
 
 
 Table 3 
 
 Effects of semantic association strength for related pairs. Both greater activations for stronger association pairs and for weaker association pairs are shown. 
 
 
 
 
 Task 
 Modulation 
 Regions 
 H 
 BA 
 z-test 
 voxels 
 X 
 y 
 z 
 
 
 
 
 Visual–visual 
 Stronger association 
 Inferior parietal lobule 
 L 
 39 
 4.12 
 62 
 −51 
 −63 
 27 
 
 
 
 Weaker association 
 
 Inferior frontal gyrus 
 
 L 
 45 
 3.11 
 39 
 −42 
 24 
 18 
 
 
 Visual–auditory 
 Stronger association 
 Inferior parietal lobule 
 L 
 40 
 3.59 
 20 
 −45 
 −54 
 42 
 
 
 
 Weaker association 
 Inferior frontal gyrus 
 L 
 45 
 3.80 
 17 
 −42 
 21 
 18 
 
 
 Visual–auditory–Visual–visual 
 Weaker association 
 Inferior frontal gyrus 
 L 
 45 
 3.66 
 10 
 −39 
 18 
 21 
 
 
 
 
 
 Note : See  Table 2  note. Voxels: number of voxels in cluster at FDR  p  < .05, only clusters greater than or equal to 10 are presented. Regions surviving  p  < .005 uncorrected are indicated in bold. 
 
 
 
 
 Table 4 
 
 Increasing activation with age for related pairs compared to perceptual controls, partialing out accuracy (ACC) or reaction time (RT). 
 
 
 
 
 
 
 Regions 
 H 
 BA 
 z -Test 
 Voxels 
 
 x 
 
 
 y 
 
 
 z 
 
 
 
 
 
 Visual–visual 
 Partial for ACC 
 
 Inferior frontal gyrus 
 
 
 L 
 
 
 45 
 
 
 3.02 
 
 
 109 
 
 − 45 
 
 18 
 
 
 12 
 
 
 
 
 
 
 Middle temporal gyrus 
 
 
 L 
 
 
 21 
 
 
 3.07 
 
 
 162 
 
 − 60 
 − 51 
 
 0 
 
 
 
 
 
 
 Caudate 
 
 
 R 
 
 
 
 4.29 
 
 
 131 
 
 
 12 
 
 
 6 
 
 
 12 
 
 
 
 
 
 
 Superior frontal gyrus 
 
 
 L 
 
 
 8 
 
 
 3.90 
 
 
 77 
 
 − 3 
 
 48 
 
 
 48 
 
 
 
 
 
 
 Premotor 
 
 
 L 
 
 
 6 
 
 
 3.70 
 
 
 48 
 
 − 48 
 
 6 
 
 
 51 
 
 
 
 
 
 
 Orbitofrontal gyrus 
 
 
 L 
 
 
 10 
 
 
 3.17 
 
 
 18 
 
 − 36 
 
 45 
 
 
 3 
 
 
 
 
 
 
 Superior occipital gyrus 
 
 
 L 
 
 
 19 
 
 
 3.63 
 
 
 208 
 
 − 24 
 − 93 
 
 15 
 
 
 
 
 
 
 Superior occipital gyrus 
 
 
 R 
 
 
 19 
 
 
 3.69 
 
 
 11 
 
 
 51 
 
 − 78 
 − 9 
 
 
 
 Partial for RT 
 
 Inferior frontal gyrus 
 
 
 L 
 
 
 45 
 
 
 3.77 
 
 
 73 
 
 − 48 
 
 27 
 
 
 9 
 
 
 
 Visual–auditory 
 Partial for ACC 
 Inferior frontal gyrus 
 L 
 45 
 4.32 
 162 
 −48 
 27 
 12 
 
 
 
 
 Inferior frontal gyrus 
 L 
 47 
 
 
 −48 
 27 
 −3 
 
 
 
 Partial for RT 
 Inferior frontal gyrus 
 L 
 45 
 4.02 
 35 
 −48 
 6 
 18 
 
 
 
 
 
 Note : See  Table 2  note. Voxels: number of voxels in cluster at FDR  p  < .05, only clusters greater than or equal to 10 are presented. Regions surviving  p  < .005 uncorrected are indicated in bold. 
 
 
 
 
