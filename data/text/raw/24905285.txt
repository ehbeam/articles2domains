
 properties manuscript? 
 
 
 0020713 
 6083 
 Neuropsychologia 
 Neuropsychologia 
 
 Neuropsychologia 
 
 0028-3932 
 1873-3514 
 
 
 24905285 
 4322763 
 10.1016/j.neuropsychologia.2014.05.019 
 NIHMS603299 
 
 
 Article 
 
 
 
 Perceived Animacy Influences the Processing of Human-Like Surface Features in the Fusiform Gyrus 
 
 
 
 
 Shultz 
 Sarah 
 
 a 
 1 
 2 
 
 
 
 McCarthya 
 Gregory 
 
 a 
 
 
 a  Human Neuroscience Laboratory, Department of Psychology, Yale University, 2 Hillhouse Ave, New Haven, CT 06520-8205, USA 
 1  Marcus Autism Center, Children's Healthcare of Atlanta, Atlanta, GA 30329, USA 
 2  Division of Autism & Related Disabilities, Department of Pediatrics, Emory University School of Medicine, Atlanta, GA 30022, USA 
 
 Corresponding Author:  Gregory McCarthy P: 203-432-7435  Gregory.mccarthy@yale.edu  Department of Psychology Yale University 2 Hillhouse Ave New Haven, CT 06520-8205 
 
 
 28 
 8 
 2014 
 
 
 04 
 6 
 2014 
 
 
 7 
 2014 
 
 
 01 
 7 
 2015 
 
 60 
 115 
 120 
 
 
 This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law. 
 
 
 
 While decades of research have demonstrated that a region of the right fusiform gyrus (FG) responds selectively to faces, a second line of research suggests that the FG responds to a range of animacy cues, including biological motion and goal-directed actions, even in the absence of faces or other human-like surface features. These findings raise the question of whether the FG is indeed sensitive to faces or to the more abstract category of  animate  agents. The current study uses fMRI to examine whether the FG responds to all faces in a category-specific way or whether the FG is especially sensitive to the faces of animate agents. Animate agents are defined here as intentional agents with the capacity for rational goal-directed actions. Specifically, we examine how the FG responds to an entity that looks like an animate agent but that lacks the capacity for goal-directed, rational action. Region-of-interest analyses reveal that the FG activates more strongly to the animate compared with the inanimate entity, even though the surface features of both animate and inanimate entities were identical. These results suggest that the FG does not respond to all faces in a category-specific way, and is instead especially sensitive to whether an entity is animate. 
 
 
 animacy detection 
 face processing 
 goal-directed actions 
 fusiform 
 posterior superior temporal sulcus 
 fMRI 
 
 
 
 The human perceptual system is tuned to rapidly identify animate agents in the environment. This may be an adaptive mechanism to ensure in-depth processing and engagement with social partners, entities that have the capacity for thoughts, feelings, and intentional actions. Cues signaling animacy can be grouped into roughly three categories, which include (1) human-like surface features, such as faces and limbs ( Baron-Cohen, 1995 ;  Carey & Spelke, 1996 ;  Guajardo & Woodward, 2004 ); (2) biological motion, such as self-propelled motion ( Baron-Cohen, 1995 ;  Leslie, 1994 ,  1995 ;  Premack, 1990 ), non-rigid transformation ( Gibson, Owsley, & Johnston, 1978 ), and the ability to react contingently and reciprocally with other entities ( Premack, 1990 ); and (3) rational goal-directed actions - actions that are purposeful and efficient given the constraints of the surrounding environment ( Csibra, Bíró, Koós, & Gergely, 2003 ;  Csibra, Gergely, Bíró, Koós & Brockbank, 1999 ;  Gergely & Csibra, 2003 ). 
 While these cues typically co-occur in the natural world and are inherently linked (animate agents have a human form, move in biologically plausible ways, and engage in rational goal-directed behavior) they are often studied in isolation in experimental settings. Research examining the neural correlates of animacy perception has typically focused on localizing the processing of specific animacy cues presented in isolation, such as static faces or point-light displays of biological motion, to particular brain regions. Most notably, faces and biological motion have been localized to the right fusiform gyrus (FG) ( Puce, Allison, Gore, & McCarthy, 1995 ) and right posterior superior temporal sulcus (pSTS) ( Allison, Puce, & McCarthy, 2000 ), respectively. The FG has been found to respond more strongly to faces compared with scrambled faces and other complex objects ( Haxby et al., 1994 ;  Kanwisher, McDermott, & Chun, 1997 ;  Puce et al., 1995 ;  Sergent, Ohta, & Macdonald, 1992 ). The right pSTS is not only sensitive to biological motion but is also involved in reasoning about the intentions underlying actions ( Pelphrey, Morris, & McCarthy, 2004 ;  Pelphrey, Singerman, Allison, & McCarthy, 2003 ;  Shultz & McCarthy, 2012 ). For instance, this region exhibits increased activation when participants observe a human actor perform a reaching motion that is inconsistent with an implied goal or implausible given the structure of the surrounding environment, compared to actions that are consistent with an implied or plausible goal ( Pelphrey et al., 2004 ). 
 Despite the localization of particular functions, such as processing faces and intentions underlying biological motion, to the FG and pSTS, respectively, there is evidence that  both  brain regions are actually involved in processing both types of information. The clearest demonstration of the functional similarity between the FG and pSTS comes from a recent study that directly compared activation maps from two large data sets, designed to localize face-sensitive and biological motionsensitive regions of cortex ( Engell & McCarthy, 2013 ). This study revealed highly similar patterns of activation, including activation of the fusiform and the pSTS, in response to both classes of stimuli. In addition, both regions activate when animacy is conveyed via a range of cues, including human-like movements ( Gobbini et al. 2011 ), human-like interactions ( Schultz et al., 2003 ;  Gobbini et al. 2007 ;  Castelli et al., 2000 ), contextual cues ( Wheatley, Milleville, & Martin, 2007 ), and goal-directed actions ( Shultz & McCarthy, 2012 ). Critically, FG and pSTS activation in response to these cues can be elicited even in the absence of faces and other human-like surface features ( Shultz & McCarthy, 2012 ;  Wheatley, Milleville, & Martin, 2007 ;  Schultz et al., 2003 ;  Gobbini et al., 2007 ; Castelli, 2000) or biologically-plausible motion ( Shultz & McCarthy, 2012 ). The substantial overlap in the response profiles of the FG and pSTS to faces and biological motion and their sensitivity to a range of animacy cues raises questions about whether these regions actually respond to faces and biological motion in a category-specific way, or whether these regions may be sensitive to the more abstract category of animate agents. 
 One study has provided direct evidence indicating that the FG prioritizes the detection of  animate  faces over global facial form ( Looser, Guntupalli, & Wheatley, 2012 ). Multivariate pattern analysis revealed that while the configuration of a face was sufficient to activate the FG, this region was especially sensitive to faces perceived as ‘alive’ or animate. Specifically, the FG prioritized the detection of animate faces (real human and dog faces) compared to inanimate faces (life-like mannequin and toy dog faces). 
 In the present study we further examine whether the FG is especially sensitive to the faces of animate agents or whether the FG responds to all faces in a category-specific way. While previous work has examined this question by manipulating the animacy of a face via perceptual features (i.e. real life human face versus a life-like face) ( Looser et al., 2012 ;  Looser & Wheatley, 2010 ;  Wheatley, et al., 2011 ), we chose to manipulate a different cue for animacy – the ability to act in a way that is purposeful and rational given the constraints of the surrounding environment. Specifically, we examine how the FG responds when the actions of an entity suggest that they are inanimate,  despite  the presence of human-like facial features. If the FG responds to faces in a category-specific way then the FG should activate to an entity with facial features, regardless of whether that entity demonstrates the capacity for rational, goal-directed behavior. However, if the FG is especially sensitive to the faces of animate agents then the FG should respond more strongly to entities that engage in rational, goal-directed behavior. 
 
 Materials and Methods 
 
 2.1 Participants 
 Twenty participants (7 female, 13 male, average age = 25.2 years, all right-handed) with normal vision and no history of neurological or psychiatric illness participated in this study. All participants gave written and informed consent and the Yale Human Investigations Committee approved the protocol. 
 
 
 2.2 Stimuli 
 Stimuli consisted of movie clips of two computer-animated avatar characters. Both avatars had human-like surface features (faces and body limbs) and moved in biologically plausible ways. The key manipulation was whether the avatar performed purposeful and rational actions (characteristics diagnostic of a minded agent), referred to henceforth as the ‘rational’ avatar, or whether the avatar demonstrated an inability to behave rationally and purposefully (characteristics diagnostic of an inanimate entity), referred to henceforth as the ‘irrational’ avatar. Each avatar was shown in two scenarios for a total of 4 movie clips. In both scenarios, the implied goal of the rational and irrational avatars was the same but the avatars differed in their capacity for rational action. In the first scenario the rational avatar walked toward a brick wall, turned towards an opening in the wall, and walked through the opening. By contrast, the irrational avatar walked into the wall repeatedly without adjusting its trajectory (see  Figure 1a  for example still frames). In the second scenario, the rational avatar walked towards a cardboard box, bent down, and picked up the box. By contrast, the irrational avatar walked directly to the left of the box, bent down, and performed a lifting motion as though they were lifting up the box (see  Figure 1b  for example still frames). These scenarios were chosen to convey that the irrational avatar lacked a mind or the capacity to behave intentionally. Critically, the important distinction between the rational and irrational avatar is not simply that the irrational avatar failed to complete an implied goal but rather that the types of actions or errors that were made are not of the type that we would expect from an animate agent. For instance, if an animate agent attempted to pick up an object but missed, we might expect them to adjust their reach or simply stop making a lifting motion. Similarly, if an animate agent approached an obstacle in their path we might expect them to move around it, move the object, stop, or turn around. The actions of the irrational avatar (performing a lifting motion to completion even though they were not holding an object and repeatedly walking into a wall without changing their trajectory) were designed to be inconsistent with our expectations about how a minded agent should behave. 
 Behavioral ratings of the perceived animacy of the rational and irrational avatars obtained from an independent sample of adults confirmed that the rational avatar was perceived as more animate than the irrational avatar (Z=-4.39,  p <.001; please see  Supplemental Materials  for details). Further, eye-tracking data collected from the independent sample of adults revealed no difference in overall percent fixation on the rational and irrational avatar clips and no difference in percent fixation on the face of the rational and irrational avatar (F 1,15 =.029,  p =.87 and F 1,15 =1.5,  p =.24, respectively). Percent time spent fixating on the body of the rational compared with the irrational avatar was marginally significant (F 1,15 =4.0, p = .06; please see  Supplemental Materials  for additional details and for a discussion of these results). 
 
 
 2.3 Experimental Design 
 The four movies (2 per condition) were presented over the course of 2 runs. The movie depicting avatars walking towards the wall was 5 seconds long, while the movie depicting avatars walking towards to the box was 3 seconds long. The presentation of successive movies was separated by a randomly chosen 2, 4, or 6 second rest period. Movies were presented in pseudorandom order such that participants always viewed the ‘rational’ version of each scenario at least one time before viewing the ‘irrational’ version to ensure that the implied goal was clear. Importantly, the identity of the rational and irrational avatar was counterbalanced across participants. For half of the participants the female avatar was rational and the male avatar was irrational. For the other half of the participants the male avatar was rational and the female avatar was irrational. As such, any difference in brain activation to the rational and irrational avatars cannot be due to surface features alone. Sixteen movies per condition were played in each run. Participants were instructed to pay attention to the stimuli at all times. 
 A secondary aim of this study was to examine whether any differential brain response to the rational and irrational avatar movie clips persisted when participants later viewed static faces of these same avatars. To address this question, participants viewed the static faces of the avatars both before and after viewing the movie clips. Each face was presented 30 times for 1 second and was separated by a 2, 4, or 6 second rest period. We predicted no difference in brain response to the rational and irrational avatar static faces prior to viewing the movie clips. However, we predicted that brain regions involved in animacy detection, such as the FG, would respond more strongly to the rational compared with the irrational avatar static faces after viewing the movie clips. 
 
 
 2.4 Image Acquisition and Preprocessing 
 Brain images were acquired at the Magnetic Resonance Research Center at Yale University using a 3.0T TIM Trio Siemens scanner with a 12-channel head coil. Functional images were acquired using an echo planar pulse sequence (repetition time [TR] = 2 s, echo time [TE] = 25 ms, flip angle = 90°, matrix = 64 2 , field of view [FOV] = 224 mm, slice thickness = 3.5mm, 36 slices). Two sets of structural images were acquired for registration: coplanar images, acquired using a  T 1  Flash sequence (TR = 300 ms, TE = 2.47 ms, flip angle = 60°, FOV = 224 mm, matrix = 256 2 , slice thickness = 3.5mm, 36 slices); and high-resolution images acquired using a 3D MPRAGE sequence (TR = 2530, TE = 2.4 ms, flip angle = 9°, FOV = 256 mm, matrix = 256 2 , slice thickness = 1mm, 176 slices). 
 Analyses were performed using the FMRIB Software Library (FSL,  http://www.fmrib.ox.ac.uk/fsl ). All images were skull-stripped using FSL's brain extraction tool. The first 4 volumes (8 seconds) of each functional data set were discarded to diminish MR equilibration effects. Data were temporally realigned to correct for interleaved slice acquisition and spatially realigned to correct for head motion using FSL's MCFLIRT realignment tool. Images were spatially smoothed with a 5mm full-width-half-maximum isotropic Gaussian kernel. Each time series was high-pass filtered (0.01 Hz cutoff) to eliminate low-frequency drift. Functional images were registered to structural coplanar images, which were then registered to high-resolution anatomical images and then normalized to the Montreal Neurological Institute's MNI152 template. 
 
 
 2.5 fMRI Data Analysis 
 Whole-brain voxelwise regression analyses were performed using FSL's fMRI expert analysis tool (FEAT). Each condition within each preprocessed run was modeled with a boxcar function convolved with a single-gamma hemodynamic response function. The model included explanatory variables for the factor of interest: animacy (rational, irrational). 
 Group-level analyses were performed using a mixed-effects model with the random effects component of variance estimated using FSL's FLAME stage 1+2 procedure. For both first and higher level analyses, clusters of active voxels were identified using FSL's 2-stage procedure to correct for multiple comparisons. Voxels were first thresholded at an entry level of z = 2.3 and the significance of the resulting clusters were then evaluated at a corrected  P  < .05 using a Gaussian random field (GRF) approach. 
 
 
 2.6 Region of Interest Analyses 
 Additional analyses were conducted to study the time course of activation differences between the rational and irrational condition during the movie clips in an independently localized region of the FG. The region of interest (ROI) was defined in a two-stage process. First an anatomical region of interest was created for the right FG on the cortical surface of a standard brain, as in  Engell & McCarthy (2013) . Next, we used a probabilistic atlas for face perception, developed from a large-scale (n = 124) fMRI localizer task designed to isolate regions of functional selectivity for faces, to further constrain the ROI using functional criteria ( Engell & McCarthy, 2013 ). The probabilistic atlas represents, at each voxel, the percentage of participants who show a category-specific response to faces (defined by a z-score of ≥ 1.65 for the face localizer contrast). Within the anatomical ROI we selected all voxels with P (the probability that a participant shows a category-specific response to faces at that specific voxel) > .55, which yielded a cluster of 81 2×2×2 mm voxels (peak coordinates: x = 44, y = -48, z = -22). A P of .55 was chosen to maximize the spatial extent of the ROI corresponding to the FG without merging with more posterior ventral face areas corresponding to the occipital face area ( Gauthier et al., 2000 ). The mean signal-averaged time course for each condition (rational and irrational) was then calculated for the FG ROI for each participant and was statistically compared by conducting a paired-samples t-test on the peak percent signal change. 
 
 
 
 Results 
 
 3.1 Brain Activation During Viewing of the Movie Clips 
 The whole-brain contrast for rational > irrational revealed activation in the right precentral gyrus, bilateral postcentral gyrus and superior parietal lobule, bilateral lateral occipital cortex, bilateral occipital fusiform cortex, lingual gyrus, and temporal fusiform cortex (see  Figure 2 ). Active clusters in temporal fusiform cortex did not overlap with face-sensitive portions of fusiform cortex. Peak coordinates of significant clusters from the rational > irrational contrast are given in  Table 1 . 
 The whole-brain contrast for irrational > rational revealed an expansive cluster of activation in right temporoccipital cortex (see  Figure 3 ). This region extended dorsally to the supramarginal gyrus, and the posterior continuation and ascending limb of the pSTS and ventrally to the middle temporal gyrus and lateral occipital cortex. Activation was also observed in the left supramarginal gyrus, superior temporal sulcus, superior and middle temporal gyrus, and lateral occipital cortex. Peak coordinates of significant clusters from the irrational > rational contrast are given in  Table 2 . 
 Given our a priori prediction that the FG would respond more strongly to the rational compared to the irrational avatar, we examined the time course of the fMRI signal averaged for each voxel within the FG ROI for each condition. A paired-samples t-test conducted on peak percent signal change within the FG ROI revealed a significant main effect of condition ( t  (19)= 3.3,  P  < .01), indicating that the FG responded more strongly to the rational (animate) compared with the irrational (inanimate) avatar (see  Figure 4 ). 
 
 
 3.2 Brain Activation During Viewing of Static Faces 
 We did not expect to find any active clusters for any contrast of static faces seen prior to viewing the movie clips, given that the identity of faces as rational or irrational was not revealed during this portion of the experiment. Further, which face would later be conveyed as rational or irrational in the movie clips was counterbalanced across participants. Unexpectedly, the irrational > rational contrast revealed activation in bilateral precuneus cortex, a finding that we interpret as being a Type 1 error. 
 No significantly active clusters were observed for the rational > irrational contrast of static faces presented after the movie clips. Given our a priori prediction that the FG would respond more strongly to the rational compared to the irrational avatar, we examined the time course of the fMRI signal averaged for each voxel within the FG ROI for each condition. A paired-samples t-test conducted on peak percent signal change within the FG ROI revealed a significant main effect of condition (t (19)= -2.85,  P  < .05), indicating that the FG responded more strongly to the irrational (inanimate) compared with the rational (animate) static avatar face (see  Figure 5 ). 
 The inanimate > animate contrast revealed activation in the right frontal pole and middle frontal gyrus. No activation was observed in the pSTS or FG for either whole-brain contrast. 
 
 
 
 Conclusions 
 These results suggest that the FG and the pSTS do not respond to all faces or biological motion in a category-specific way, and are instead especially sensitive to whether an entity is animate. A region of interest analysis revealed that the FG responded more strongly to human-like stimuli whose actions were purposeful and rational given the constraints of the surrounding environment compared to humanlike stimuli that acted in an irrational, non-intentional manner. Consistent with previous studies, the pSTS showed the opposite pattern, responding more strongly to the avatar that behaved irrationally compared with the avatar that behaved rationally. 
 These findings are consistent with those reported by Looser et al. (2011) demonstrating that the FG prioritizes the processing of animate over inanimate entities. The present study corroborates and extends these findings by demonstrating that the FG activates more strongly to animate compared with inanimate entities, even when the surface features of both animate and inanimate faces are identical. Despite these consistencies, Looser et al. (2011) found increased sensitivity to animate faces in the FG when using multivariate pattern analysis but not when examining differences in average magnitude levels within an FG ROI using standard GLM. By contrast, the present study found a differential response to animate and inanimate entities using standard GLM region-of-interest analysis. This difference may have been partially driven by the way ROIs were defined. In Looser et al. (2011) the FG ROI included voxels that were more active for at least one class of faces (human, doll, real dog, or toy dog) compared with clocks, whereas the present study defined the FG ROI on the basis of a large-scale probabilistic atlas defined by a contrast of human faces versus scenes. Given that voxels within ventral temporal cortex ROIs may contain distinct but spatially proximate or even overlapping representations, different approaches for defining ROIs may yield different results (Looser et al., 2011). 
 The present results also suggest that the capacity for rational action plays a critical role in modulating activation in brain regions involved in detecting and reasoning about animate agents and their intentions. While perceptual cues alone, such as human-like surface features or biological motion, are sufficient to activate regions involved in animacy detection ( Shultz & McCarthy, 2012 ;  Engell & McCarthy, 2013 ), the current results indicate that FG activation to these cues is attenuated when accompanied by clear evidence that the entity lacks the capacity for rational action. By contrast, previous work has shown that the FG and pSTS activate in response to entities that engage in rational goal-directed actions, even when these entities clearly do not have human-like surface features or act in biomechanically impossible ways ( Shultz & McCarthy, 2012 ;  Gobbini et al., 2007 ;  Castelli et al., 2000 ;  Schultz et al., 2003 ;  Wheatley, Milleville, & Martin, 2007 ). Thus, while human-like surface features, biological motion, and rational goal-directed actions may all be sufficient to engage brain regions involved in animacy detection, the potential for rational action may be a  necessary  cue for strongly activating the FG. Prioritizing the capacity for rational action as a cue for animacy may confer an advantage, as rational actions are likely to be a more stable diagnostic marker of animacy compared to featural or motion cues which can be distorted, altered or perhaps even unfamiliar. 
 Like the FG, the pSTS also differentiated between the animate and inanimate avatar movie clips. However the pattern of differential activation was reversed with the pSTS responding more strongly to the irrational compared with the rational avatar. This result is consistent with previous research indicating that the pSTS activates more strongly to actions that are incongruent with an implied goal or implausible given the context within which the action occurs ( Brass, Schmitt, Spengler, & Gergely, 2007 ;  Pelphrey et al., 2004 ). While this is a well-replicated finding, questions remain regarding the mechanism underlying the increase in response to actions that violate expectations about how an entity should behave. One interpretation is that the human-like surface features of the avatar establish an expectation that the avatar is animate and should therefore behave rationally and intentionally. When these expectations are violated, the observer must revise or reconcile their expectations, a process which demands continued processing of the observed action sequence. While this may be a plausible explanation, it is important to note that the FG did not respond to these conflicting cues in the same manner. Rather, region of interest analyses indicated that the FG actually responded more strongly to the rational avatar whose surface features and actions provided converging evidence for animacy. What then, might account for the dissociation in the response of the FG and the pSTS? 
 The relationship between the response of the FG and the pSTS is interesting to consider in the context of a neural model for animacy detection recently proposed by our laboratory ( Shultz & McCarthy, 2012 ;  Shultz et al., 2014 ). The model posits that three processing streams are initially differentially sensitive to cues signaling animacy (human-like surface features, biological motion, and rational goal-directed action) but that information about animate agents is then shared across streams for further processing. As a consequence of such sharing, any one cue signaling animacy is sufficient to activate all nodes of the proposed network. According to the model, the FG is part of the processing stream that is specialized for detecting human-like surface features, while the pSTS is part of a processing stream for detecting biological motion and integrating information about underlying intentions. A third stream, involving parietal areas such as the supramarginal gyrus and superior parietal lobule, is posited to play a role in detecting intentions. 
 A key prediction of this model is that the directional flow of activation between these processing streams initially depends on the characteristics of the particular stimulus presented. In a recent study ( Shultz et al., 2014 ) we provided evidence for this key prediction using Dynamic Causal Modeling, a measure of effective connectivity. We demonstrated that viewing static faces activates the FG, which then drives activation in the pSTS. By contrast, viewing point-light displays of biological motion activates the pSTS, which then drives activation in the FG. Importantly, while the FG is initially differentially sensitive to faces and drives activation in the pSTS, its activity then becomes influenced by feedback from the pSTS. Similarly, while the pSTS is initially differentially sensitive to biological motion and drives activation in the FG, its activity then becomes influenced by feedback from the FG. Thus, although these regions are initially functionally selective for either faces or biological motion, this selectivity is transient as information is shared bidirectionally across processing streams. 
 Extending this model to the context of the current experiment offers a potential explanation for the differential response of the FG and pSTS to rational and irrational avatars. According to the model, viewing the face of the rational avatar may have initially driven activation in the FG. Activation in the pSTS, driven by both feedforward connections from the FG and by the presence of biological motion and goal-directed actions, may have fed back into the FG, resulting in greater FG activation. This hypothesized causal flow of activation may have been delayed or disrupted in the case of processing the irrational avatar. The unexpected actions of the irrational avatar may have required additional processing by the pSTS thereby disrupting or delaying feedback into the FG and resulting in less FG activation. Future studies using measures of effective connectivity are required to test these claims. 
 Finally, counter to our initial predictions, when static faces of the avatars were presented following the movie clips the FG responded more strongly to the irrational compared with the rational avatar. While this finding requires further replication, one possibility may be that the current pattern of results reflects neural adaptation or carry-over effects from the movie clips that differentially influenced the processing of the rational and irrational avatar static faces. For instance, the stronger response in the FG to the rational compared with the irrational avatar movie clips may reflect greater encoding of the rational avatar by the FG. The decreased response in the FG during subsequent viewing of the static face of the rational avatar may reflect adaptation to the rational avatar's face. By contrast, the increased response in the FG during subsequent viewing of the static face of the irrational avatar may reflect the lack of encoding of the irrational avatar by the FG during the movie clips. One implication of these findings is that the experience of viewing conflicting information about the animacy of an entity does not subsequently influence how that agent is processed when later viewed in the absence of conflicting cues. However, the findings during viewing of the static faces were not predicted and require further replication. 
 
 
 Supplementary Material 
 
 01 
 
 
 
 
 
 Acknowledgments 
 We thank William Walker for assistance in data collection. This work was supported by National Institute of Mental Health grant MH-05286 (GM), the Yale University FAS Imaging Fund, and a National Science Foundation Graduate Research Fellowship (SS). 
 
 
 
 This is a PDF file of an unedited manuscript that has been accepted for publication. As a service to our customers we are providing this early version of the manuscript. The manuscript will undergo copyediting, typesetting, and review of the resulting proof before it is published in its final citable form. Please note that during the production process errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain. 
 
 
 
 References 
 
 
 
 
 Allison 
 T 
 
 
 Puce 
 A 
 
 
 McCarthy 
 G 
 
 
 Social perception from visual cues: Role of the STS region. 
 Trends in Cognitive Sciences 
 2000 
 4 
 7 
 267 
 278 
 10859571 
 
 
 
 
 
 
 Baron-Cohen 
 S 
 
 
 Mindblindness: An essay on autism and theory of mind 
 1995 
 MIT Press 
 Cambridge (MA) 
 
 
 
 
 
 
 Brass 
 M 
 
 
 Schmitt 
 RM 
 
 
 Spengler 
 S 
 
 
 Gergely 
 G 
 
 
 Investigating action understanding: inferential processes versus action simulation. 
 Current Biology 
 2007 
 17 
 24 
 2117 
 2121 
 18083518 
 
 
 
 
 
 
 Carey 
 S 
 
 
 Spelke 
 E 
 
 
 Science and core knowledge. 
 Philosophy of Science 
 1996 
 63 
 4 
 515 
 533 
 
 
 
 
 
 
 Castelli 
 F 
 
 
 Happé 
 F 
 
 
 Frith 
 U 
 
 
 Frith 
 C 
 
 
 Movement and mind: A functional imaging study of perception and interpretation of complex intentional movement patterns. 
 NeuroImage 
 2000 
 12 
 314 
 325 
 10944414 
 
 
 
 
 
 
 Csibra 
 G 
 
 
 Bíró 
 S 
 
 
 Koós 
 O 
 
 
 Gergely 
 G 
 
 
 One-year-old infants use teleological representations of actions productively. 
 Cognitive Science 
 2003 
 27 
 1 
 111 
 133 
 
 
 
 
 
 
 Csibra 
 G 
 
 
 Gergely 
 G 
 
 
 Bíró 
 S 
 
 
 Koós 
 O 
 
 
 Brockbank 
 M 
 
 
 Goal attribution without agency cues: The perception of “pure reason” in infancy. 
 Cognition 
 1999 
 72 
 3 
 237 
 67 
 10519924 
 
 
 
 
 
 
 Engell 
 AD 
 
 
 McCarthy 
 G 
 
 
 Probabilistic atlases for face and biological motion perception: An analysis of their reliability and overlap. 
 NeuroImage 
 2013 
 74 
 0 
 140 
 151 
 23435213 
 
 
 
 
 
 
 Gauthier 
 I 
 
 
 Tarr 
 MJ 
 
 
 Moylan 
 J 
 
 
 Skudlarski 
 P 
 
 
 Gore 
 JC 
 
 
 Anderson 
 AW 
 
 
 The fusiform “face area” is part of a network that processes faces at the individual level. 
 Journal of Cognitive Neuroscience 
 2000 
 12 
 3 
 495 
 504 
 10931774 
 
 
 
 
 
 
 Gergely 
 G 
 
 
 Csibra 
 G 
 
 
 Teleological reasoning in infancy: The naïve theory of rational action. 
 Trends in Cognitive Sciences 
 2003 
 7 
 7 
 287 
 292 
 12860186 
 
 
 
 
 
 
 Gibson 
 EJ 
 
 
 Owsley 
 CJ 
 
 
 Johnston 
 J 
 
 
 Perception of invariants by five-month-old infants: Differentiation of two types of motion. 
 Developmental Psychology 
 1978 
 14 
 4 
 407 
 415 
 
 
 
 
 
 
 Gobbini 
 M 
 
 
 Koralek 
 AC 
 
 
 Bryan 
 RE 
 
 
 Montgomery 
 KJ 
 
 
 Haxby 
 J 
 
 
 Two takes on the social brain: A comparison of theory of mind tasks. 
 Journal of Cognitive Neuroscience 
 2007 
 19 
 11 
 1803 
 1814 
 17958483 
 
 
 
 
 
 
 Gobbini 
 M 
 
 
 Gentili 
 C 
 
 
 Ricciardi 
 E 
 
 
 Bellucci 
 C 
 
 
 Salvini 
 P 
 
 
 Laschi 
 C 
 
 
 Guazzelli 
 M 
 
 
 Pietrini 
 P 
 
 
 Distinct neural systems involved in agency and animacy detection. 
 Journal of Cognitive Neuroscience 
 2011 
 23 
 8 
 1911 
 1920 
 20849234 
 
 
 
 
 
 
 Guajardo 
 JJ 
 
 
 Woodward 
 AL 
 
 
 Is agency skin deep? Surface attributes influence infants’ sensitivity to goal-directed action. 
 Infancy 
 2004 
 6 
 3 
 361 
 384 
 
 
 
 
 
 
 Haxby 
 J 
 
 
 Horwitz 
 B 
 
 
 Ungerleider 
 LG 
 
 
 Maisog 
 JM 
 
 
 Pietrini 
 P 
 
 
 Grady 
 CL 
 
 
 The functional organization of human extrastriate cortex: a PET-rCBF study of selective attention to faces and locations. 
 Journal of Neuroscience 
 1994 
 14 
 11 
 6336 
 6353 
 7965040 
 
 
 
 
 
 
 Kanwisher 
 N 
 
 
 McDermott 
 J 
 
 
 Chun 
 MM 
 
 
 The fusiform face area: A module in human extrastriate cortex specialized for face perception. 
 Journal of Neuroscience 
 1997 
 17 
 11 
 4302 
 11 
 9151747 
 
 
 
 
 
 
 Leslie 
 A 
 
 
 
 
 Hirscfeld 
 L 
 
 
 Gelman 
 S 
 
 
 ToMM, ToBy, and agency: Core architecture and domain specificity. 
 Mapping the mind: Domain specificity in cognition and culture 
 1994 
 119 
 148 
 Cambridge University Press 
 New York 
 
 
 
 
 
 
 Leslie 
 A 
 
 
 
 
 Sperber 
 D 
 
 
 Premack 
 D 
 
 
 Premack 
 A 
 
 
 A theory of agency. 
 Causal cognition: A multidisciplinary debate 
 1995 
 121 
 141 
 Clarendon Press 
 Oxford 
 
 
 
 
 
 
 Looser 
 CE 
 
 
 Guntupalli 
 JS 
 
 
 Wheatley 
 T 
 
 
 Multivoxel patterns in facesensitive temporal regions reveal an encoding schema based on detecting life in a face. 
 Social Cognitive and Affective Neuroscience 
 2012 
 
 
 
 
 
 
 Looser 
 CE 
 
 
 Wheatley 
 T 
 
 
 The tipping point of animacy how, when, and where we perceive life in a face. 
 Psychological Science 
 2010 
 21 
 12 
 1854 
 1862 
 21097720 
 
 
 
 
 
 
 Pelphrey 
 K 
 
 
 Morris 
 JP 
 
 
 McCarthy 
 G 
 
 
 Grasping the intentions of others: the perceived intentionality of an action influences activity in the superior temporal sulcus during social perception. 
 Journal of Cognitive Neuroscience 
 2004 
 16 
 10 
 1706 
 1716 
 15701223 
 
 
 
 
 
 
 Pelphrey 
 K 
 
 
 Singerman 
 JD 
 
 
 Allison 
 T 
 
 
 McCarthy 
 G 
 
 
 Brain activation evoked by perception of gaze shifts: the influence of context. 
 Neuropsychologia 
 2003 
 41 
 2 
 156 
 170 
 12459214 
 
 
 
 
 
 
 Premack 
 D 
 
 
 The infant's theory of self-propelled objects. 
 Cognition 
 1990 
 36 
 1 
 1 
 16 
 2383967 
 
 
 
 
 
 
 Puce 
 A 
 
 
 Allison 
 T 
 
 
 Gore 
 JC 
 
 
 McCarthy 
 G 
 
 
 Face-sensitive regions in human extrastriate cortex studied by functional MRI. 
 Journal of Neurophysiology 
 1995 
 74 
 3 
 1192 
 1199 
 7500143 
 
 
 
 
 
 
 Sergent 
 J 
 
 
 Ohta 
 S 
 
 
 Macdonald 
 B 
 
 
 Functional neuroanatomy of face and object processing A positron emission tomography study. 
 Brain 
 1992 
 115 
 1 
 15 
 36 
 1559150 
 
 
 
 
 
 
 Schultz 
 RT 
 
 
 Grelotti 
 DJ 
 
 
 Klin 
 A 
 
 
 Kleinman 
 J 
 
 
 Van der Gaag 
 C 
 
 
 Marois 
 R 
 
 
 Skudlarski 
 P 
 
 
 The role of the fusiform face area in social cognition: Implications for the pathobiology of autism. 
 Philosophical Transactions of the Royal Society Biological Sciences 
 2003 
 358 
 415 
 427 
 12639338 
 
 
 
 
 
 
 Shultz 
 S 
 
 
 McCarthy 
 G 
 
 
 Goal-directed actions activate the face-sensitive posterior superior temporal sulcus and fusiform gyrus in the absence of human-like perceptual cues. 
 Cerebral Cortex 
 2012 
 22 
 5 
 1098 
 1106 
 21768227 
 
 
 
 
 
 
 Shultz 
 S 
 
 
 van den Honert 
 R 
 
 
 Engell 
 AD 
 
 
 McCarthy 
 G 
 
 
 Stimulus-induced reversal of information flow through a cortical network for animacy perception. 
 Social Cognitive and Affective Neuroscience 
 2014 
 doi: 10.1093/scan/nsu028 
 
 
 
 
 
 
 Wheatley 
 T 
 
 
 Milleville 
 SC 
 
 
 Martin 
 A 
 
 
 Understanding animate agents: Distinct roles for the social network and mirror system. 
 Psychological Science 
 2007 
 18 
 469 
 474 
 17576256 
 
 
 
 
 
 
 Wheatley 
 T 
 
 
 Weinberg 
 A 
 
 
 Looser 
 C 
 
 
 Moran 
 T 
 
 
 Hajcak 
 G 
 
 
 Mind perception: Real but not artificial faces sustain neural activity beyond the N170/VPP. 
 PloS one 
 2011 
 6 
 3 
 e17960 
 doi:10.1371/journal.pone.0017960 
 21483856 
 
 
 
 
 
 
 
 Highlights 
 
 
 
 - FG and pSTS do not show a category-specific response to faces or biological motion 
 
 
 - ROI analysis reveals increased FG activation to entities that look  and  act animate 
 
 
 - The pSTS shows the reverse pattern, activating more to conflicting animacy cues 
 
 
 
 
 Figure 1 
 
 Example still frames from movie clips 
 (A) The rational character (on left) walked towards the wall, turned towards the opening, and continued walking. The irrational character (on right) repeatedly walked into the wall without adjusting his motion trajectory. (B) The rational character (on left) walked towards the box, bent down, and picked it up. The irrational character (on right) walked to the left of the box, bent down, and performed a lifting motion as though they were lifting the box. The identity of the rational and irrational characters was counterbalanced across participants. 
 
 
 
 
 Figure 2 
 
 Activation map for the Rational versus Irrational contrast 
 Activation is displayed on a cortical surface representation. The color ranges from  z  = 2.3 to  z  = 5.0. 
 
 
 
 
 Figure 3 
 
 Activation map for the Irrational versus Rational contrast 
 Activation is displayed on a cortical surface representation. The color ranges from  z  = 2.3 to  z  = 4.1. 
 
 
 
 
 Figure 4 
 
 ROI analysis results for the FG: percent signal change during movie clips 
 Percent signal change averaged across voxels in the independently identified FG ROI (pictured in top right) for the rational (blue) and irrational (red) conditions. There is a significant difference in the peak percent signal change in response to the rational (animate) compared with the irrational (inanimate) condition. Movie presentation begins at 0s. 
 
 
 
 
 Figure 5 
 
 ROI analysis results for the FG: percent signal change during static presentation of faces shown after the movie clips 
 Percent signal change averaged across voxels in the independently identified FG ROI (pictured in top right) for the rational (blue) and irrational (red) conditions. There is a significant difference in the peak percent signal change in response to the rational (animate) compared with the irrational (inanimate) condition. Stimulus presentation begins at 0s. 
 
 
 
 
 Table 1 
 
 Peak Coordinates (in MNI space) from the Rational versus Irrational contrast. 
 
 
 
 
 Region 
 Coordinates (mm) 
 
 
 x 
 y 
 z 
 
 
 
 
 Bilateral lateral occipital cortex (extending to bilateral superior parietal lobule and bilateral temporal occipital cortex) 
 22 
 −86 
 32 
 
 
 Right precentral gyrus 
 36 
 −6 
 54 
 
 
 Right supramarginal gyrus 
 56 
 −22 
 36 
 
 
 
 
 
 Table 2 
 
 Peak Coordinates (in MNI space) from the Irrational versus Rational contrast. 
 
 
 
 
 Region 
 Coordinates (mm) 
 
 
 x 
 y 
 z 
 
 
 
 
 Right pSTS (extending to right middle temporal gyrus) 
 60 
 −38 
 20 
 
 
 Left supramarginal gyrus (extending to left STS) 
 −58 
 −50 
 26 
 
 
 
 
 
