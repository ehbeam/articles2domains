
 properties manuscript? 
 
 
 9215515 
 20498 
 Neuroimage 
 Neuroimage 
 
 NeuroImage 
 
 1053-8119 
 1095-9572 
 
 
 24099847 
 3849327 
 10.1016/j.neuroimage.2013.09.064 
 NIHMS530979 
 
 
 Article 
 
 
 
 Distinct brain activity in processing negative pictures of animals and objects --- the role of human contexts 
 
 
 
 
 Cao 
 Zhijun 
 
 a 
 
 
 
 Zhao 
 Yanbing 
 
 a 
 
 
 
 Tan 
 Tengteng 
 
 a 
 
 
 
 Chen 
 Gang 
 
 b 
 
 
 
 Ning 
 Xueling 
 
 a 
 
 
 
 Zhan 
 Lexia 
 
 a 
 
 
 
 Yang 
 Jiongjiong 
 
 a 
 
 
 a Department of Psychology, Peking University, Beijing, 100871, China 
 b Scientific and Statistical Computing Core, NIMH/NIH/DHHS, 9000 Rockville Pike, Bethesda, MD 20892, USA 
 
 Corresponding author:  Jiongjiong Yang, Ph.D., Department of Psychology, Peking University, Beijing 100871, P.R. China. Telephone: 86-10-62768016.  yangjj@pku.edu.cn. 
 
 
 18 
 11 
 2013 
 
 
 04 
 10 
 2013 
 
 
 1 
 2014 
 
 
 01 
 1 
 2015 
 
 84 
 10.1016/j.neuroimage.2013.09.064 
 
 
 This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law. 
 
 
 
 Previous studies have shown that the amygdala is important in processing not only animate entities but also social information. It remains to be determined to what extent the factors of category and social context interact to modulate the activities of the amygdala and cortical regions. In this study, pictures depicting animals and inanimate objects in negative and neutral levels were presented. The contexts of the pictures differed in whether they included human/human parts. The factors of valence, arousal, familiarity and complexity of pictures were controlled across categories. The results showed that the amygdala activity was modulated by category and contextual information. Under the nonhuman context condition, the amygdala responded more to animals than objects for both negative and neutral pictures. In contrast, under the human context condition, the amygdala showed stronger activity for negative objects than animals. In addition to cortical regions related to object action, functional and effective connectivity analyses showed that the anterior prefrontal cortex interacted with the amygdala more for negative objects (vs. animals) in the human context condition, by a top-down modulation of the anterior prefrontal cortex to the amygdala. These results highlighted the effects of category and human contexts on modulating brain activity in emotional processing. 
 
 
 Stimulus category 
 emotion 
 context 
 amygdala 
 prefrontal cortex 
 
 
 
 Fogarty International Center : FIC 
 R01 TW007897 || TW 
 
 
 
 
 
 Introduction 
 In our daily lives we may fear different kinds of things, e.g., snakes, plane crashes, or blood. Some people develop as phobia to excessively fear certain classes of objects or contexts. Among the specific phobias, animal phobia has the highest prevalence ( Damsa et al., 2009 ;  Pull, 2008 ), but its neural mechanisms remain unclear. One influential hypothesis, the preparedness theory, posits that fear of snakes and spiders may be associated with prepared networks because ancient humans faced attacks from these animals ( Ohman and Mineka, 2001 ;  Seligman, 1970 ). Compared to ontogenetic fear stimuli (e.g., guns), phylogenetic fear stimuli (e.g., snakes) are more attended to (e.g.,  New et al., 2007 ;  Ohman et al., 2001a ;  Ohman et al., 2001b ), and lead to stronger physiological responses (e.g.,  Cook et al., 1986 ;  Hugdahl and Karker, 1981 ). 
 Specifically the preparedness theory proposes that the enhanced response to phylogenetic fear stimuli is associated with activity in the amygdala. This result is supported by the evidence that the amygdala is more responsive to animate stimuli compared to inanimate objects, in addition to being extensively involved in processing threatening stimuli. In a previous study the neurons in the right amygdala were more responsive to animal pictures, which was independent of emotional valence and arousal ( Mormann et al., 2011 ). The medial temporal region, including the amygdala, was preferentially responsive to personally relevant images (vs. unfamiliar people) ( Viskontas et al., 2009 ). The animate advantage is also shown in fMRI studies. In one study,  Yang et al. (2012a)  compared brain activation in American participants for faces, nonhuman animals and inanimate objects in negative, positive and neutral levels. The results demonstrated that activation in the right amygdala was the strongest for human faces, less strong for animals, and weakest for inanimate objects. This pattern was clear for negative and neutral pictures and suggested that the amygdala is more involved in processing animate (vs. inanimate) entities. 
 Various studies have also revealed that the amygdala is important for processing social information (e.g.,  Norris et al., 2004 ;  Sakaki et al., 2012 ;  Wheatley et al., 2007 . For reviews, see  Adolphs, 2010 ;  Frith and Frith, 2012 ). In the  Wheatley et al. (2007)  study, subjects viewed moving shapes in two different backgrounds biased towards animate or inanimate interpretations. Because the shapes were the same, the interpretation was determined by the contextual background. The results showed that animate interpretation significantly activated the amygdala, insula, medial prefrontal cortex (mPFC) and posterior cingulate cortex (PCC) relative to inanimate interpretation.  Sakaki et al. (2012)  divided pictures into survival-related (e.g., threats, food) and social life-related categories (e.g., trust, friendship) with the two types of pictures matched in their valence and arousal levels. The results showed that the left amygdala and the left mPFC were activated for both survival- and social-related pictures. The amygdala also had addictive effects when pictures were negative and included social contents (i.e., pictures containing human information) ( Norris et al., 2004 ). 
 Althougth the factors of emotion, category and context are important for amygdala activation, to what extent they interact to influence the activation of the amygdala and other brain regions is unclear. Some studies found comparable emotional responses to living and nonliving entities under some conditions. For example, pointed guns and pointed snakes had comparable resistance to extinction ( Hugdahl and Johnsen, 1989 ) because guns with sounds are more likely to be associated with threatening situations. Indeed, when seeing a gun handled by a human hand, one likely finds the gun more threatening than a gun on the table and as threatening as a snake biting a man. A recent eye-tracking study showed that, although animal pictures attract more attention than inanimate objects ( New et al., 2007 ), they had comparable numbers of gaze fixations and gaze durations when human contexts were included in both types of pictures ( Yang et al., 2012b ). This result suggested that contextual information is important for understanding how people react to negative inanimate objects. Processing pictures with human contextual information may critically depend on that context and is associated with top-down modulation and executive control of social information ( Frith and Frith, 2012 ). Neural recordings of rats found that the prefrontal cortex encoded contextual information to form rich contextual representations and alter the interpretations or meanings of stimuli ( Hyman et al., 2012 ). Thus, the amygdala and the prefrontal cortex possibly interact to process emotional pictures with human contexts, but more evidence is needed to confirm the prediction. 
 The question addressed in this study was to explore the extent to which the activities of the amygdala and cortical regions were modulated by contextual information when subjects processed animals and objects in different emotional levels. In a pilot experiment ( Supplementary Material ), we adopted the design of  Yang et al. (2012a) ; Chinese subjects viewed pictures of facial expressions, animals and manipulable objects in different emotional levels (i.e., negative, neutral and positive). In this study, we further included pictures with human or human body information as contexts for nonhuman animals and inanimate objects in negative and neutral dimensions. To dissociate the factors of emotion and category, we matched valence and arousal levels across categories and controlled for complexity and familiarity levels. We hypothesized that factors of emotion, category and context interact to influence the amygdala activation (e.g., Yang et al., 2002b;  Hayman et al., 2012 ). We predicted that the amygdala activation was stronger for negative (vs. neutral) pictures, and stronger for animals than objects, as shown in previous studies. In addition, the category effect is expected to interact with that of emotion and context. For pictures without human contexts, nonhuman animals elicit stronger activation in the amygdala than inanimate objects. For the pictures with human contexts, the animate advantage in negative dimensions may attenuate or disappear in the amygdala due to top-down processing of the prefrontal cortex. 
 
 
 Materials and Methods 
 
 Subjects 
 Sixty healthy, right-handed subjects (28 males) participated in the study, with the mean age 22.54 ± 2.75 yrs. Of these subjects, 21 participated in emotional rating (10 male), 18 participated in familiarity and complexity rating (7 males), and the other 21 subjects participated in the fMRI experiment (11 males). All subjects were native Chinese speakers, and gave written informed consent in accordance with procedures and protocols approved by the Institutional Review Board of the Department of Psychology, Peking University. 
 
 
 Stimuli 
 The stimuli setup was the same as  Yang et al. (2012b) . Three within-subject factors were included in the study with a 2×2×2 structure: context (with or without human contexts), emotion (negative, neutral) and category (nonhuman animals, inanimate objects). The factorial combination of the three factors made up eight experimental conditions. The stimuli in the fMRI experiment consisted of 240 colorful, nameable experimental pictures (30 per condition) with a resolution of 640*480 pixels. Each of the 30 concepts was depicted as different pictures in contexts with and without human (or human parts). Low-level visual features, stimulus saliency, picture size, position of focal object and context were also analyzed and matched across categories ( Yang et al., 2012b ). Both small and large sizes of animals and inanimate objects were included to match their actual size. The orientation of the pictures was also matched across categories. 
 
 
 fMRI procedure 
 Pictures were clustered into blocks by context, emotion and category, with each of the 2×2×2 conditions having 2 blocks. In each block, there were 19 pictures (15 different items and 4 repeats). Each picture was presented for 1 s, followed by a fixation for 500ms, which yielded a duration of 28.5 s for each block. Subjects were asked to pay attention to all the stimuli, and to perform a repetition detection task. The 16 picture blocks and 16 scrambled blocks were pseudo-randomly assigned to 4 runs; the picture conditions, concepts and backgrounds were balanced across runs. The picture and scrambled blocks were interleaved in each run. Because four additional TRs (two before the first block and two after the last block) were inserted for each run, each run lasted 240 sec, and the entire experiment lasted about 30 min. The orders of the blocks and runs were counterbalanced across subjects. 
 
 
 MRI acquisition 
 MRI data were collected on a Siemens Trio 3T scanner (Magnetom Trio). Functional data were collected using a gradient echo, echo-planar imaging (EPI) sequence (TR = 3s, TE = 40ms, flip angle = 90°, FOV = 24cm, matrix = 96×96, slice = 34 and resolution = 2.5×2.5×3 mm 3 ), and anatomical data were acquired using a high-resolution MP-RAGE sequence (TR = 7.6ms, flip angle = 6°, FOV = 22cm, matrix = 224×224, resolution = 1×1×1.2 mm 3 ) after functional scanning. 
 
 
 MRI statistical analysis 
 AFNI was used for pre-processing imaging data and statistical analysis ( http://afni.nimh.nih.gov ). The first three EPI volumes in each run were discarded due to the issue of magnetization equilibrium. The remaining volumes were registered, smoothed with an RMS width of 3mm, and scaled to a mean of 100. Multiple regression analysis was performed to calculate the response to each condition compared with the scrambled baseline. The model included eight regressors of interest, each of which was created by the convolution of a gamma variate for each condition, six regressors of non-interest (motion parameters), and second-order polynomials for slow drift. Anatomical images and the volumes of effect estimates from the regression analysis were then warped into the standard stereotaxic space of the  Talairach and Tournoux (1988)  atlas. 
 For group analysis, a voxel-wise four-way repeated-measures ANOVA was performed with context, emotion and category as three within-subjects factors and subjects as between-subjects factor (voxel-wise  p  < 0.01, two-tailed). Monte Carlo simulations were used to correct for multiple comparisons at a corrected  p -value of 0.05 in cortical regions (number of voxels = 13, volume = 244 mm 3 ) and the amygdala (SVC, number of voxels = 4, volume = 75 mm 3 ). The amygdala for each subject was manually drawn and averaged as the anatomical mask to confine the activation located within the amygdala. To further determine the relations between the amygdala and prefrontal cortex, the psychophysiological interaction analysis (PPI,  Friston et al., 1997 ), the ROI analysis, and the dynamic causal modeling (DCM,  Friston et al., 2003 ; SPM8,  http://www.fil.ion.ucl.ac.uk ) were performed. For the PPI analysis, the seed regions were created as a 5 mm-radius sphere centered on the peak voxel. Then the average time series from the seed region was extracted from the dataset with baseline, slow drift and head motion removed. A correlational map for each subject was produced between the time course from the seeds and rest of the brain. To combine results across subjects, the correlation coefficients were converted to  z  scores and analyzed using a one-sample  t -test ( p  < 0.05, corrected, two-tailed). For the ROI analysis, we selected regions of the amygdala and the anterior prefrontal cortex that were activated in each category contrast, extracted the time series of that condition from each subject and averaged the series across subjects. 
 For the DCM, we used SPM8 to perform the preprocessing and deconvolution, then selected the peak location of the prefrontal cortex (−45, 32, 7) and the amygdala (27, −1, −20) from the group level contrast and created the ROIs as a 4 mm-radius sphere for each peak. The first eigenvariate across those voxels was extracted. The DCM models were analyzed for negative objects and animals under the human context condition separately. With the assumptions that there were intrinsic bidirectional connections between the aPFC to the amygdala ( Volman et al., 2013 ) and category modulation for the bidirectional connections, we estimated the parameters for each model and divided the possible models into three families for negative animals and objects separately ( Supplementary Material, Figure S3 ). These models and families were common in their self-connection and intrinsic connections of the aPFC and the amygdala. The models differed in category modulation to the connection of aPFC --> amygdala or amygdala --> aPFC, and the families differed in where the input came from. According to the results of the Bayesian model selection (BMS) in a random-effects approach, we identified the family that was most likely to have generated the data across subjects. Then, we performed the Bayesian model averaging (BMA) on the winning family for each subject ( Penny et al., 2010 ). This procedure computed weighted means of each model parameter in the winning family, in which the weighting was determined by the posterior probability of each model. In addition, we performed the BMA on each model within the winning family for each subject. The mean parameters were averaged across subjects and t-test was performed to estimate the modulatory effect (p < 0.05, two-tailed). 
 
 
 
 Results 
 
 Rating results 
 Analyses of the rating data confirmed that the object categories were equated for valence and arousal ( Table 1 ). Pictures in animals and objects were rated in comparable scores (F(1,20) = 0.09, p = 0.76 for valence, and F(1,20) = 3.44, p = 0.08 for arousal). As designed, negative pictures were more negative and more arousal than neutral pictures (F(1,20) = 230.73, p < 0.001, and F(1,20) = 99.26, p < 0.001). The interactions related to category were not significant (all p values > 0.05). For the familiarity rating, subjects evaluated how often they saw or thought of the focal object (i.e., an animal or object) in their daily life (1 = least familiar; 7 = most familiar). The results showed that category effect was not significant (F(1,17) = 1.66, p = 0.22). Neutral pictures were more familiar than negative pictures (F(1,17) = 17.65, p < 0.001), and pictures without human contexts were more familiar than those with human contexts (F(1,17) = 12.09, p < 0.003). There were no significant category-related effects (p’s > 0.20). For the complexity rating, subjects rated the degree of details in a picture and the degree of changes on its contours (1 = least complex; 7 = most complex). Animal pictures were more complex than objects (F(1,17) = 39.15, p < 0.001). Negative pictures were more complex than neutral pictures (F(1,17) = 4.89, p < 0.05). The interactions related to category were not significant (p’s > 0.30). 
 
 
 Behavioral results 
 During scanning, subjects were highly accurate when performing the repetition detection task (0.94 ± 0.06). Analyses of the accuracy and reaction time data failed to reveal any effects of category, emotion, or their interaction (all F’s < 1.0, p’s > 0.20). 
 
 
 ANOVA results 
 
 Main effects of emotion and context 
 Many brain regions showed significant effects of emotion and context ( Table 2 ). Among them, there was stronger activation in the bilateral amygdala (−21, −9, −9, t(20) = 6.42, p < 0.001 on the left and 21, −4, −9, t(20) = 5.25, p < 0.001 on the right) for negative pictures than neutral pictures ( Figure 2A ). For the context difference, the bilateral amygdala (−19, −11, −6, t(20) = 6.01, p < 0.001 on the left and 21, −6, −6, t(20) = 6.67, p < 0.001 on the right) was also more responsive to pictures with human contexts than those without human contexts. This result was consistent with previous findings that the amygdala is involved in processing both emotional and social information ( Adolphs, 2010 ;  Frith and Frith, 2012 ;  Zald, 2003 ). 
 
 
 Main effect of category 
 There was significant category effect on the left (−21, −4, −6, t(20) = 3.78, p < 0.002) and right (26, 6, −9, t(20) = 4.34, p < 0.001 and 19. −1, −16, t(20) = 3.03, p < 0.01) amygdala even when the activation was constrained by the anatomical amygdala mask. The animal pictures elicited stronger activation in the amygdala than object pictures ( Figure 2B ). Similar findings were shown in  Yang et al. (2012a)  and our pilot study with Chinese participants ( Supplementary Material, Figure S1 ). Note that the effects of category, emotion and context were overlapped in the amygdala ( Figure S2 ). The category effect was smaller than and included in emotional and contextual effects, and the effects of emotion and context were partly overlapped. 
 Category-related differences were also found in animate and inanimate networks, including posterior regions of ventral and lateral temporal lobes and in regions of the parietal and frontal cortices ( Figure 3A ). Nonhuman animals elicited stronger activation than inanimate objects in the bilateral lateral fusiform gyrus, right superior temporal sulcus (STS), occipital cortex, posterior cingulated cortex (PCC), insula and the right thalamus. In contrast, inanimate objects elicited stronger activation in the left medial fusiform gyrus, left middle temporal gyrus (MTG), left parietal cortex, bilateral anterior prefrontal cortex (aPFC) and the middle prefrontal cortex. 
 
 
 Interactions among factors 
 A noteworthy result is that the amygdala activation was modulated by the interaction of the three factors ( Table 3 ,  Figure 2C ). There were significant interactions in the amygdala for category by emotion (−31, −6, −11, F(1,20) = 18.75, p < 0.001), category by context (−26, −1, −13, F(1,20) = 14.04, p < 0.001), emotion by context (−21, −6, −4, F(1,20) = 14.58, p < 0.001), and the 3-way interaction (−19, 1, −16, F(1,20) = 6.01, p < 0.05). For the interaction of emotion by context, the emotional effect in the amygdala was obvious for pictures with human contexts (vs. without human context). The emotion effect was significant in the right for animals and mainly in the left for objects, suggesting that the left and right amygdala may be involved in processing different aspects of information ( Glascher et al., 2003 ;  Hariri et al., 2002 ). 
 The interaction was also manifested in the category effect ( Figure 4A ). For the interaction of emotion by category, the category effect was significant in the right (19, −1, −14, t(20) = 3.05, p < 0.01) for the negative pictures and in the left (−31, −6, −14, t(20) = 5.05, p < 0.001) for the neutral pictures, both showing animate advantage. The amygdala showed increased activation (animals > objects) (left: −26, 1, −21, t(20) = 2.51, p < 0.03; right: 21, 4, −21, t(20) = 3.05, p < 0.01) when the contexts did not include human information, but showed opposite patterns (animals < objects) (left: −29, −11, −11, t(20) = 3.05, p < 0.01; right: 21, 1, −14, t(20) = 3.61, p < 0.002) for the human-context pictures. 
 The simple category effects showed similar results ( Figure 4B ). When the context did not include human information, nonhuman animals elicited stronger activation than inanimate objects for both the negative (19, −1, −14, t(20) = 3.24, p < 0.005) and neutral conditions (−19, −6, −14, t(20) = 3.94, p < 0.001). However, when the context included human information, the animate advantage only occurred for neutral pictures (−19, −4, −9, t(20) = 2.65, p < 0.02). For negative pictures with human contexts, the amygdala elicited stronger activation for inanimate objects than nonhuman animals (26, −1, −24, t(20) = 2.83, p < 0.02). 
 The animate and inanimate networks were manifested in both negative and neutral pictures. In particular, for pictures with human contexts ( Figures 3B, 3C ), negative animals elicited stronger activation in the right STS (46, −66, 21, t(20) = 3.92, p < 0.001), PCC (−11, −39, 44, t(20) = 5.06, p < 0.001), precuneus (−14, −59, 56, t(20) = 4.67, p < 0.001) and the inferior PFC (59, 6, 29, t(20) = 5.62, p < 0.001) than negative objects, and negative objects elicited stronger activation in the left MTG (−49, −44, −6, t(20) = 4.42, p < 0.001), left premotor cortex (PMC, −39, 1, 29, t(20) = 5.05, p < 0.001) and left parietal cortex (−39, −34, 39, t(20) = 3.71, p < 0.002 and −41, −44, 46, t(20) = 3.37, p < 0.005) than negative animals. In addition to these regions, the aPFC (−46, 46, 1, t(20) = 5.51, p < 0.001 on the left and 39, 46, −9, t(20) = 5.35, p < 0.001 on the right) also showed stronger activation for negative objects than animals. 
 In addition to the cortical regions that are widely reported in the literature ( Martin, 2007 ), we found that the bilateral aPFC (−39, 46, −4, t(20) = −3.37, p < 0.005) showed significant activation for objects vs. animals ( Table 2 ). However, for simple contrasts, the aPFC manifested different patterns ( Figure 5A ). The aPFC was more strongly activated for negative inanimate objects (vs. animals) when the negative pictures included human contexts, but it was more strongly activated for nonhuman animals vs. objects in the other three contrasts. 
 Previous studies have found that the mPFC is highly associated with emotional processing and regulation ( Ochsner and Gross, 2005 ;  Quirk and Beer, 2006 ;  Roy et al., 2012 ). Our study showed similar results, and more specifically, the mPFC activity was significant for negative pictures (vs. neutral) (−5, 44, −4, t(20) = 3.53, p < 0.005) and pictures with human contexts (vs. those without human contexts) (5, 46, −11, t(20) = 3.45, p < 0.005). There was also stronger activation in the mPFC for animals vs. objects (−4, 51, −1, t(20) = 4.36, p < 0.001) and the bilateral aPFC for objects vs. animals. However, in regard to the category effect in human condition, there was only significant activation in the bilateral aPFC for negative objects (vs. animals). 
 
 
 PPI and ROI Results 
 To determine the network differences for negative objects (weapons) and negative animals, we performed the PPI analysis to find regions that were significantly correlated with the left aPFC (−46, 46, 1, t(20) = −5.51, p < 0.001), which were selected as seed regions from the category contrast of negative pictures in the human-context condition (objects vs. animals). The results showed that the activity of the right amygdala was positively correlated with the activity of the left aPFC in the human-context condition ( Figure 5B ). It suggested that when human contexts are included in the context, the left aPFC is more activated for negative objects and modulates the amygdala activation by top-down processing. 
 We also performed the correlation analysis between ROI regions of the amygdala and aPFC. The results showed that for negative pictures with human contexts, the left aPFC was significantly correlated with activation in the right amygdala (r = 0.48, p < 0.04) ( Figure 5C ). For neutral pictures with human contexts, the left aPFC (−31, 56, −1, t(20) = −6.10, p < 0.001) was significantly correlated with activation in the left amygdala (r = 0.46, p < 0.04). There were no significant correlations between the aPFC and amygdala for pictures without human contexts (r < 0.15, p’s > 0.5). These results suggested that the prefrontal cortex modulates the amygdala activation with respect to whether the context includes a human factor. 
 
 
 DCM Results 
 Based on the PPI and ROI results, the connection between the aPFC and the amygdala was modulated by stimulus category. The DCM results further suggested a connection from the aPFC to the amygdala.  Figure S3  showed that the most suitable models were those in Family C, in which the input projection was connected to the aPFC, suggesting a possible top-down modulation originated from the aPFC. In addition, negative objects had strong influence on modulating the top-down connections. The modulatory strength of the aPFC --> amygdala connection was significant for negative objects (t(20) = 2.67, p < 0.02), but not for negative animals (t(20) = 1.23, p = 0.23) ( Table 4 ). In contrast, stimulus category had small modulatory effects on the amygdala --> aPFC. The modulatory strength of the amygdala --> aPFC connection was not significant for negative objects (t(20) = 0.42, p = 0.68) or negative animals (t(20) = 1.55, p = 0.64). The results for each model within the winning family also showed that there was significant modulatory effect of negative objects for the aPFC --> amygdala connection ( Supplementary results, Table S1 ). 
 
 
 
 
 Discussion 
 The objective of this study was to explore the extent to which the amygdala activation was modulated by category and contextual information when subjects processed animals and objects in different emotional levels. We had three main findings. First, the amygdala responded more to animals than objects when the contexts did not include human information. Second, the amygdala activity was modulated by contextual information of the pictures. When pictures included human contexts, the amygdala activation was stronger for negative objects than animals. Third, in addition to regions related to object action, the aPFC was more activated for negative objects (vs. animals) with human contexts, and modulate the amygdala activation. The results suggested that contextual information and category interact to influence the amygdala and cortical activations in emotional processing. 
 
 Category effect in the amygdala with non-human contexts 
 The results showed that, when the context did not include human information, the amygdala was more responsive to animals than objects. This was consistent with previous studies that used neural recordings and fMRI techniques. Some neurons in the amygdala preferred animal pictures ( Mormann et al., 2011 ), and others preferred human faces ( Viskontas et al., 2009 ). The amygdala is activated in processing visual information about animate geometric shapes ( Castelli et al., 2000 ,  Martin and Weisberg, 2003 ), biological motions ( Bonda et al., 1996 ) and animate pictures ( Yang et al., 2012a ). 
 One of the common characteristics of faces and animals is their animacy. Both categories can be agents that initiate goal-directed self-movements ( Rakison and Dubois, 2001 ), and both can interact with humans for social interactions, whereas man-made objects can only be acted on by agent manipulations. Because faces and animals can initiate threatening actions, paying more attention to them ( Lipp et al., 2004 ;  New et al., 2007 ;  Yang et al., 2012b ) and identifying animate entities/agents are important for human survival ( Heberlein and Adolphs, 2004 ,  New et al., 2007 ). Similar mechanisms may apply to neutral animate stimuli because they are potentially threatening to humans. For example, the social meaning of neutral faces is ambiguous, and faces may even be untrustworthy, which evokes stronger amygdala activation (Fitzgerald et al, 2005;  Wright and Liu, 2006 ). Neutral animals are less threatening than fearful animals, but they still have higher potential to be predators than tools ( Purkis and Lipp, 2007 ). Taken together, the amygdala may have a broader role in detecting and appraising any potential biological sign of threat ( Adolphs, 2010 ;  Davis and Whalen, 2001 ;  Sander, 2003 ;  Whalen, 1998 ). 
 An interesting part of the results was that the Chinese subjects manifested different characteristics than did their American counterparts. The animate advantage in the amygdala between animals and objects was smaller than that in  Yang et al. (2012a) , although not compared directly. This result occurred because negative objects showed strong activation in the amygdala, and positive objects (toys) did not show enhanced activation in the amygdala (vs. other objects) ( Supplementary Results ). Studies have suggested that the two populations adopt different strategies to process scenes. Chinese participants were more likely to attend to the context and background of the pictures, whereas Americans paid more attention to the objects ( Chua et al., 2005 ). Our rating results confirmed that Chinese subjects thought more of social interaction when they viewed the negative objects ( Supplementary Results ), suggesting a mechanism of automatic generating social inferences when viewing objects. In general it was consistent with the results that contextual information with humans significantly increased the amygdala activation for negative objects. It also suggested that cultural factor should be considered in emotional processing, especially when pictorial stimuli were used. 
 
 
 Category effect in the amygdala with human contexts 
 The novel finding of our study was that there was stronger activation in the right amygdala for negative objects than animals with human contexts and positive connectivity from the left aPFC to the right amygdala in this condition. The results were obtained when various factors were controlled, and the levels of valence, arousal and familiarity for negative animals and objects with humans included in the contexts were comparable. Although animals were generally more complex than objects, there were no significant interactions among factors, which was different from the pattern in the amygdala response. It suggested that the increased amygdala activation for negative objects vs. animals with human contexts is not due to the difference in affective and perceptual features across categories. But rather, the fMRI result may reflect the interaction between the object and its context in processing pictures. 
 When human-related information is included in the picture, subjects can use the context to make inferences about the intentions of conspecifics ( Adolphs, 2010 ;  Frith and Frith, 2012 ) and how serious the situations are to them. In modern society, human beings face many disasters related to threatening inanimate objects (e.g., car accidents and wars) that more frequently occur than events related to threatening animals (e.g., snakes biting people). Previous studies also found comparable emotional responses to living and nonliving things under some conditions (e.g.,  Blanchette, 2006 ;  Brosch and Sharma, 2005 ;  Hugdahl and Johnsen, 1989 ;  Yang et al., 2012b ). Our results showed that the increased response to threatening objects is associated with the amygdala activation. Neuroimaging studies have suggested that the amygdala is important for processing social information (e.g.,  Martin and Weisberg, 2003 ;  Norris et al., 2004 ;  Sakaki et al., 2012 ;  Wheatley et al., 2007 ). It suggested that, although animate advantage is a general rule for the amygdala response, the amygdala responds more to negative pictures with human context in deliberating their salient meanings to human beings. 
 We also found that the amygdala activation was significantly correlated with the aPFC activation for negative pictures with human contexts. In addition, the DCM attempts to infer the dynamics of the underlying neuronal systems from the observed fMRI signal ( Friston et al., 2003 ), and the results showed that there were strong aPFC --> amygdala connection. The aPFC is located in the anterior part of the prefrontal cortex and has strong connections with other parts of the prefrontal cortex (e.g., dorsal and medial PFC) and other brain regions. While the mPFC is highly associated with emotional processing and regulation ( Bishop, 2007 ;  Ochsner and Gross, 2005 ;  Quirk and Beer, 2006 ;  Roy et al., 2012 ), the aPFC is involved in semantic encoding and memory retrieval process ( Simons and Spiers, 2003 ). Our study showed that there was significant activation in the bilateral aPFC for objects (vs. animals) and negative pictures with human contexts. The amygdala-prefrontal circuitry has been shown to be responsible for attentional capture to threatening stimuli and interpretation of emotionally ambigious stimuli. Stronger activation in the prefrontal cortex led to reduced activation in the amygdala (e.g.,  Bishop, 2007 ;  Quick & Beer, 2006 ;  Wager et al., 2008 ). On the other hand, the PFC subregions, especially the ventral and anterior parts, are involved in generating emotional responses ( Etkin et al., 2011 ) and increasing emotional responses ( Ochsner et al., 2005 ). The PFC is also responsible for processing contextual information ( Hyman et al., 2012 ). It is possible that the PFC activity is task-based and different subregions of the PFC play different roles in emotional processing. We hypothesized that the role of the aPFC is to integrate information from affective features with social cues and to evaluate its social meaning based on long-term memory. The stronger activation of the aPFC for negative objects (vs. animals) indicated the significance of social situation for processing scenes of negative objects. The aPFC is therefore associated with top-down modulation and executive control of social information that is processed in the amygdala. 
 
 
 Category representation for negative pictures in cortical regions 
 Converging evidence from neuropsychological and functional brain imaging investigations suggest that different object categories, such as animate, biological objects (e.g., four-legged animals) and man-made manipulable objects (e.g., tools) are represented in distinct neural networks in the brain ( Mahon and Caramazza, 2009 ;  Martin, 2007 ). The network for different categories was consistent with the analysis of the main effect of category in the study. Then the following question should be addressed. In the human context condition, are negative animals and objects represented differently in the cortical region? Our results showed that the two types of pictures were indeed represented in the animate and inanimate networks. Negative animals elicited stronger activation in the right STS, PCC, precuneus and inferior PF than negative objects. Both the PCC and STS are involved in the social network and were activated in previous studies (e.g.,  Norris et al., 2004 ;  Sakaki et al., 2012 ;  Wheatley et al., 2007 ). The STS is important for inferred intentions of social cues ( Nummenmaa and Calder, 2009 ), and the PCC is related to interpreting the meaning of other people’s actions ( Adolps, 2010 ). In addition to the left aPFC, negative objects elicited stronger activation in the left MTG, left PMC and left parietal cortex than negative animals. These regions are associated with action representation ( Chao and Martin, 2000 ;  Martin, 2007 ;  Yang et al., 2012a ) and are consistently reported in many studies. The fear of negative animals and objects thus relies on different cortical mechanisms, regardless of their contexts. 
 
 
 Theoretical Implications and fear processing 
 The amygdala is a complex collection of 13 nuclei in primates. Numerous studies have shown its important role in processing emotionally and socially relevant information. There are some theories that account for the amygdala activation. For example, the amygdala may be more responsible for processing negative stimuli ( Amaral, 2003 ), emotional stimuli ( Zald, 2003 ), phylogenetic fear stimuli ( Ohman and Mineka, 2001 ), vigilance and ambiguity resolution ( Davis and Whalen, 2001 ), or salient and relevance detection ( Adolphs, 2010 ;  Sander, 2003 ). In general, these theories are not necessarily contradictory to each other. The core role of the amygdala may be responsible for detecting and evaluating the meaning and consequences of a relevant external event, especially when uncertain and ambiguous interpretation occurs ( Adolphs, 2010 ). Because biological or animate stimuli are more related to human beings and initiate threatening actions, they are more attended to than other types of stimuli in activating the amygdala. The amygdala is therefore a part of the animate network. However, negative objects in a human-related context also contain the information of potential threats and danger to humans ( Coelho and Purkis, 2009 ). Thus, responding to these objects with appropriate action is important. The amygdala may be preferentially activated in this situation, partly through the modulation of the prefrontal cortex. 
 The theoretical significance of our study was that it highlighted the interaction of category and contextual information in modulating amygdala activation in emotional processing. Particularly, in regard to fearful stimuli, evolutionary features (i.e., phylogenetic and ontogenetic fear) undoubtedly modulate the amygdala activation, but its activation level is also modulated by a stimulus’s contextual information. Clarifying the role of the amygdala is important for understanding the neural mechanisms of various emotional disorders, such as animal phobias and posttraumatic stress disorder (PTSD). PTSD is characteristic of the overwhelming terror resulting from certain trauma, especially in people who underwent life-threatening events ( McNally, 2006 ). This result explains why animal phobia has the highest prevalence among specific phobias ( Damsa et al., 2009 ;  Pull, 2008 ). In addition, PTSD patients are not possibly afraid of object itself, but the scene that object is located in a certain situation. The fear of ontogenetic stimuli may rely on human contexts. 
 
 
 Limitation 
 Our study has some limitations. First, the rating results were obtained from subjects who were not scanned although the two groups of subjects were matched in their age and gender. Second, the difference between negative and neutral pictures could arise from both valence and arousal. In general negative animals and objects are more aroused than neutral pictures, so by our design it is hard to tease apart the two effects, although this co-effect should not influence the category effect because the valence and arousal levels were optimally matched across categories. Further studies could control the arousal rating as covariate in the analysis when the same group of subjects were rated and scanned. Third, although aPFC --> amygdala connection was identified as significant in the DCM, caution should be taken due to the limitations of the design. For example, functional data with a shorter (vs. longer) TR and continuous acquisition (vs. interleaved) are recommended for DCM ( Stephan et al., 2010 ), but our data were acquired with relatively long TR (3 s) and interleaved slice sequence. Fourth, a picture includes human parts only reflects parts of social interaction. In this study, because we used animal and object pictures as stimuli, we selected pictures that human interacted with animals and inanimate objects (e.g., a hand grasps a gun). It would be interesting to use dynamic motion pictures as stimuli in future studies to induce more realistic social situation related to animals and objects. 
 
 
 Conclusion 
 In conclusion, our study showed that animate pictures elicited stronger activation in the amygdala than did inanimate objects whether the pictures were negative or neutral. However, when human information was included in the context, negative objects elicited stronger activation in the right amygdala than negative animals, and the amygdala activation was modulated by the activation in the left aPFC for negative objects. The results highlighted the role of stimulus category and contextual information in modulating the amygdala and cortical activation in emotional processing. 
 
 
 
 Supplementary Material 
 
 01 
 
 
 
 
 
 
 This is a PDF file of an unedited manuscript that has been accepted for publication. As a service to our customers we are providing this early version of the manuscript. The manuscript will undergo copyediting, typesetting, and review of the resulting proof before it is published in its final citable form. Please note that during the production process errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain. 
 
 
 Conflict of Interest:  None declared. 
 
 
 
 
 Funding 
 
 This research was supported by grants from the National Science Foundation of China (31171078,  J. Yang, 2012 ), and the Global Research Initiative Program, National Institutes of Health, USA (R01TW007897, J. Yang, 2008). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. 
 
 
 References 
 
 
 
 
 Adolphs 
 R 
 
 
 Cognitive neuroscience of human social behaviour 
 Nat. Rev. Neurosci 
 2003 
 4 
 165 
 178 
 12612630 
 
 
 
 
 
 
 Adolphs 
 R 
 
 
 What does the amygdala contribute to social cognition? 
 Ann. N. Y. Acad. Sci 
 2010 
 1191 
 42 
 61 
 20392275 
 
 
 
 
 
 
 Amaral 
 DG 
 
 
 The amygdala, social behavior, and danger detection 
 Emotions 
 2003 
 337 
 347 
 Inside Out 
 
 
 
 
 
 
 Bishop 
 SJ 
 
 
 Neurocognitive mechanisms of anxiety: an integrative account 
 Trends in Cognitive Sciences 
 2007 
 11 
 307 
 316 
 17553730 
 
 
 
 
 
 
 Blanchette 
 I 
 
 
 Snakes, spiders, guns, and syringes: How specific are evolutionary constraints on the detection of threatening stimuli? 
 Q. J. Exp. Psychol 
 2006 
 59 
 1484 
 1504 
 
 
 
 
 
 
 Bonda 
 E 
 
 
 Petrides 
 M 
 
 
 Ostry 
 D 
 
 
 Evans 
 A 
 
 
 Specific involvement of human parietal systems and the amygdala in the perception of biological motion 
 Neurosci 
 1996 
 16 
 3737 
 3744 
 
 
 
 
 
 
 Brosch 
 T 
 
 
 Sharma 
 D 
 
 
 The role of fear-relevant stimuli in visual search: A comparison of phylogenetic and ontogenetic stimuli 
 Emotion 
 2005 
 5 
 360 
 364 
 16187872 
 
 
 
 
 
 
 Castelli 
 F 
 
 
 Happe 
 F 
 
 
 Frith 
 U 
 
 
 Frith 
 C 
 
 
 Movement and mind: A functional imaging study of perception and interpretation of complex intentional movement patterns 
 Neuroimage 
 2000 
 12 
 314 
 325 
 10944414 
 
 
 
 
 
 
 Chao 
 LL 
 
 
 Martin 
 A 
 
 
 Representation of manipulable man-made objects in the dorsal stream 
 Neuroimage 
 2000 
 12 
 478 
 484 
 10988041 
 
 
 
 
 
 
 Chua 
 HF 
 
 
 Boland 
 JE 
 
 
 Nisbett 
 RE 
 
 
 Cultural variation in eye movements during scene perception 
 Proc. Nat. Acad. Sci. U.S.A 
 2005 
 102 
 12629 
 12633 
 
 
 
 
 
 
 Coelho 
 CM 
 
 
 Purkis 
 H 
 
 
 The Origins of Specific Phobias: Influential Theories and Current Perspectives 
 Rev. Gen. Psychol 
 2009 
 13 
 335 
 348 
 
 
 
 
 
 
 Cook 
 EW 
 
 
 Hodes 
 RL 
 
 
 Lang 
 PJ 
 
 
 Preparedness and phobia - effects of stimulus content on human visceral conditioning 
 J. Abn. Psychol 
 1986 
 95 
 195 
 207 
 
 
 
 
 
 
 Damsa 
 C 
 
 
 Kosel 
 M 
 
 
 Moussally 
 J 
 
 
 Current status of brain imaging in anxiety disorders 
 Curr. Opin. Psychiatr 
 2009 
 22 
 96 
 110 
 
 
 
 
 
 
 Davis 
 M 
 
 
 Whalen 
 PJ 
 
 
 The amygdala: vigilance and emotion 
 Mol. Psychiatr 
 2001 
 6 
 13 
 34 
 
 
 
 
 
 
 Etkin 
 A 
 
 
 Egner 
 T 
 
 
 Kalisch 
 R 
 
 
 Emotional processing in anterior cingulate and medial prefrontal cortex 
 Trends in Cognitive Sciences 
 2011 
 15 
 85 
 93 
 21167765 
 
 
 
 
 
 
 Fitzgerald 
 DA 
 
 
 Angstadt 
 M 
 
 
 Jelsone 
 LM 
 
 
 Nathan 
 PJ 
 
 
 Phan 
 KL 
 
 
 Beyond threat: Amygdala reactivity across multiple expressions of facial affect 
 Neuroimage 
 2006 
 30 
 1441 
 1448 
 16368249 
 
 
 
 
 
 
 Friston 
 KJ 
 
 
 Buechel 
 C 
 
 
 Fink 
 GR 
 
 
 Morris 
 J 
 
 
 Rolls 
 E 
 
 
 Dolan 
 RJ 
 
 
 Psychophysiological and modulatory interactions in neuroimaging 
 Neuroimage 
 1997 
 6 
 218 
 229 
 9344826 
 
 
 
 
 
 
 Friston 
 KJ 
 
 
 Harrison 
 L 
 
 
 Penny 
 W 
 
 
 Dynamic causal modelling 
 Neuroimage 
 2003 
 19 
 1273 
 1302 
 12948688 
 
 
 
 
 
 
 Frith 
 CD 
 
 
 Frith 
 U 
 
 
 Mechanisms of Social Cognition 
 Annu. Rev. Psychol 
 2012 
 63 
 287 
 313 
 21838544 
 
 
 
 
 
 
 Glascher 
 J 
 
 
 Adolphs 
 R 
 
 
 Processing of the arousal of subliminal and supraliminal emotional stimuli by the human amygdala 
 J. Neurosci 
 2003 
 23 
 10274 
 10282 
 14614086 
 
 
 
 
 
 
 Hariri 
 AR 
 
 
 Tessitore 
 A 
 
 
 Mattay 
 VS 
 
 
 Fera 
 F 
 
 
 Weinberger 
 DR 
 
 
 The amygdala response to emotional stimuli: A comparison of faces and scenes 
 Neuroimage 
 2002 
 17 
 317 
 323 
 12482086 
 
 
 
 
 
 
 Heberlein 
 AS 
 
 
 Adolphs 
 R 
 
 
 Impaired spontaneous anthropomorphizing despite intact perception and social knowledge 
 Proc. Nat. Acad. Sci. U.S.A 
 2004 
 101 
 7487 
 7491 
 
 
 
 
 
 
 Hugdahl 
 K 
 
 
 Johnsen 
 BH 
 
 
 Preparedness and electrodermal fear-conditioning -ontogenetic vs phylogenetic explanations 
 Behav. Res. Ther 
 1989 
 27 
 269 
 278 
 2730508 
 
 
 
 
 
 
 Hugdahl 
 K 
 
 
 Karker 
 AC 
 
 
 Biological vs experimental factors In phobic conditioning 
 Behav. Res. Ther 
 1981 
 19 
 109 
 115 
 7271686 
 
 
 
 
 
 
 Hyman 
 JM 
 
 
 Ma 
 LY 
 
 
 Balaguer-Ballester 
 E 
 
 
 Durstewitz 
 D 
 
 
 Seamans 
 JK 
 
 
 Contextual encoding by ensembles of medial prefrontal cortex neurons 
 Proc. Nat. Acad. Sci. U.S.A 
 2012 
 109 
 5086 
 5091 
 
 
 
 
 
 
 Lipp 
 OV 
 
 
 Derakshan 
 N 
 
 
 Waters 
 AM 
 
 
 Logies 
 S 
 
 
 Snakes and cats in the flower bed: Fast detection is not specific to pictures of fear-relevant animals 
 Emotion 
 2004 
 4 
 233 
 250 
 15456393 
 
 
 
 
 
 
 Mahon 
 BZ 
 
 
 Caramazza 
 A 
 
 
 Concepts and Categories: A Cognitive Neuropsychological Perspective 
 Annual Review of Psychology 
 2009 
 27 
 51 
 
 
 
 
 
 
 Martin 
 A 
 
 
 The representation of object concepts in the brain 
 Annu. Rev. Psychol 
 2007 
 58 
 25 
 45 
 16968210 
 
 
 
 
 
 
 Martin 
 A 
 
 
 Weisberg 
 J 
 
 
 Neural foundations for understanding social and mechanical concepts 
 Cogn. Neuropsychol 
 2003 
 20 
 575 
 587 
 16648880 
 
 
 
 
 
 
 McNally 
 RJ 
 
 
 Cognitive abnormalities in post-traumatic stress disorder 
 Trends Cogn. Sci 
 2006 
 10 
 271 
 277 
 16697695 
 
 
 
 
 
 
 Mormann 
 F 
 
 
 Dubois 
 J 
 
 
 Kornblith 
 S 
 
 
 Milosavljevic 
 M 
 
 
 Cerf 
 M 
 
 
 Ison 
 M 
 
 
 Tsuchiya 
 N 
 
 
 Kraskov 
 A 
 
 
 Quiroga 
 RQ 
 
 
 Adolphs 
 R 
 
 
 Fried 
 I 
 
 
 Koch 
 C 
 
 
 A category-specific response to animals in the right human amygdala 
 Nat. Neurosci 
 2011 
 14 
 1247 
 1249 
 21874014 
 
 
 
 
 
 
 New 
 J 
 
 
 Cosmides 
 L 
 
 
 Tooby 
 J 
 
 
 Category-specific attention for animals reflects ancestral priorities, not expertise 
 Proc. Nat. Acad. Sci. U.S.A 
 2007 
 104 
 16598 
 16603 
 
 
 
 
 
 
 Norris 
 CJ 
 
 
 Chrn 
 EE 
 
 
 Zhu 
 DC 
 
 
 Small 
 SL 
 
 
 Cacioppo 
 JT 
 
 
 The interaction of social and emotional processes in the brain 
 J. Cogn. Neurosci 
 2004 
 16 
 1818 
 1829 
 15701231 
 
 
 
 
 
 
 Nummenmaa 
 L 
 
 
 Calder 
 AJ 
 
 
 Neural mechanisms of social attention 
 Trends. Cogn. Sci 
 2009 
 13 
 135 
 143 
 19223221 
 
 
 
 
 
 
 Ochsner 
 KN 
 
 
 Gross 
 JJ 
 
 
 The cognitive control of emotion 
 Trends. Cogn. Sci 
 2005 
 9 
 242 
 249 
 15866151 
 
 
 
 
 
 
 Ochsner 
 KN 
 
 
 Gross 
 JJ 
 
 
 The cognitive control of emotion 
 Trends in Cognitive Sciences 
 2005 
 9 
 242 
 249 
 15866151 
 
 
 
 
 
 
 Ohman 
 A 
 
 
 Flykt 
 A 
 
 
 Esteves 
 F 
 
 
 Emotion drives attention: Detecting the snake in the grass 
 J. Exp. Psychol. Gen 
 2001a 
 130 
 466 
 478 
 11561921 
 
 
 
 
 
 
 Ohman 
 A 
 
 
 Lundqvist 
 D 
 
 
 Esteves 
 F 
 
 
 The face in the crowd revisited: A threat advantage with schematic stimuli 
 J. Person. Soc. Psychol 
 2001b 
 80 
 381 
 396 
 
 
 
 
 
 
 Ohman 
 A 
 
 
 Mineka 
 S 
 
 
 Fears, phobias, and preparedness: Toward an evolved module of fear and fear learning 
 Psychol. Rev 
 2001 
 108 
 483 
 522 
 11488376 
 
 
 
 
 
 
 Penny 
 WD 
 
 
 Stephan 
 KE 
 
 
 Daunizeau 
 J 
 
 
 Rosa 
 MJ 
 
 
 Friston 
 KJ 
 
 
 Schofield 
 TM 
 
 
 Leff 
 AP 
 
 
 Comparing Families of Dynamic Causal Models 
 Plos Computational Biology 
 2010 
 6 
 
 
 
 
 
 
 Pull 
 CB 
 
 
 Recent trends in the study of specific phobias 
 Curr. Opin. Psychiatr 
 2008 
 21 
 43 
 50 
 
 
 
 
 
 
 Purkis 
 HM 
 
 
 Lipp 
 OV 
 
 
 Automatic attention does not equal automatic fear: Preferential attention without implicit valence 
 Emotion 
 2007 
 7 
 314 
 323 
 17516810 
 
 
 
 
 
 
 Quirk 
 GJ 
 
 
 Beer 
 JS 
 
 
 Prefrontal involvement in the regulation of emotion: convergence of rat and human studies 
 Curr. Opin. Neurobiol 
 2006 
 16 
 723 
 727 
 17084617 
 
 
 
 
 
 
 Rakison 
 DH 
 
 
 Poulin-Dubois 
 D 
 
 
 Developmental origin of the animate-inanimate distinction 
 Psychol. Bull 
 2001 
 127 
 209 
 228 
 11316011 
 
 
 
 
 
 
 Roy 
 M 
 
 
 Shohamy 
 D 
 
 
 Wager 
 TD 
 
 
 Ventromedial prefrontal-subcortical systems and the generation of affective meaning 
 Trends Cogn. Sci 
 2012 
 16 
 147 
 156 
 22310704 
 
 
 
 
 
 
 Sakaki 
 M 
 
 
 Niki 
 K 
 
 
 Mather 
 M 
 
 
 Beyond arousal and valence: The importance of the biological versus social relevance of emotional stimuli 
 Cogn. Affect. Behav. Neurosci 
 2012 
 12 
 115 
 139 
 21964552 
 
 
 
 
 
 
 Sander 
 D 
 
 
 Grafman 
 J 
 
 
 Zalla 
 T 
 
 
 The human amygdala: an evolved system for relevance detection 
 Rev. Neurosci 
 2003 
 14 
 303 
 316 
 14640318 
 
 
 
 
 
 
 Seligman 
 ME 
 
 
 On general of laws of learning 
 Psychol. Rev 
 1970 
 77 
 406 
 418 
 
 
 
 
 
 
 Simons 
 JS 
 
 
 Spiers 
 HJ 
 
 
 Prefrontal and medial temporal lobe interactions in long-term memory 
 Nat. Rev. Neurosci 
 2003 
 4 
 637 
 648 
 12894239 
 
 
 
 
 
 
 Stephan 
 KE 
 
 
 Penny 
 WD 
 
 
 Moran 
 RJ 
 
 
 den Ouden 
 HEM 
 
 
 Daunizeau 
 J 
 
 
 Friston 
 KJ 
 
 
 Ten simple rules for dynamic causal modeling 
 Neuroimage 
 2010 
 49 
 3099 
 3109 
 19914382 
 
 
 
 
 
 
 Talairach 
 J 
 
 
 Tournoux 
 P 
 
 
 Co-planar stereotaxic atlas of the human brain. 3-dimensional proportional system: An approach to cerebral imaging 
 1988 
 New York 
 Thieme 
 
 
 
 
 
 
 Viskontas 
 IV 
 
 
 Quiroga 
 RQ 
 
 
 Fried 
 I 
 
 
 Human medial temporal lobe neurons respond preferentially to personally relevant images 
 Proc. Nat. Acad. Sci. U.S.A 
 2009 
 106 
 21329 
 21334 
 
 
 
 
 
 
 Volman 
 I 
 
 
 Verhagen 
 L 
 
 
 den Ouden 
 HEM 
 
 
 Fernandez 
 G 
 
 
 Rijpkema 
 M 
 
 
 Franke 
 B 
 
 
 Toni 
 I 
 
 
 Roelofs 
 K 
 
 
 Reduced serotonin transporter availability decreases prefrontal control of the amygdala 
 The Journal of neuroscience : the official journal of the Society for Neuroscience 
 2013 
 33 
 8974 
 8979 
 23699508 
 
 
 
 
 
 
 Wager 
 TD 
 
 
 Davidson 
 ML 
 
 
 Hughes 
 BL 
 
 
 Lindquist 
 MA 
 
 
 Ochsner 
 KN 
 
 
 Prefrontal-subcortical pathways mediating successful emotion regulation 
 Neuron 
 2008 
 59 
 1037 
 1050 
 18817740 
 
 
 
 
 
 
 Whalen 
 PJ 
 
 
 Fear, vigilance, and ambiguity: Initial neuroimaging studies of the human amygdala 
 Curr. Dir. Psychol. Sci 
 1998 
 7 
 177 
 188 
 
 
 
 
 
 
 Wheatley 
 T 
 
 
 Milleville 
 SC 
 
 
 Martin 
 A 
 
 
 Understanding animate agents - Distinct roles for the social network and mirror system 
 Psychol. Sci 
 2007 
 18 
 469 
 474 
 17576256 
 
 
 
 
 
 
 Wright 
 P 
 
 
 Liu 
 YJ 
 
 
 Neutral faces activate the amygdala during identity matching 
 Neuroimage 
 2006 
 29 
 628 
 636 
 16143545 
 
 
 
 
 
 
 Yang 
 JJ 
 
 
 Bellgowan 
 PSF 
 
 
 Martin 
 A 
 
 
 Threat, domain specificity and the human amygdala 
 Neuropsychologia 
 2012a 
 50 
 2566 
 2572 
 22820342 
 
 
 
 
 
 
 Yang 
 JJ 
 
 
 Wang 
 AB 
 
 
 Yan 
 M 
 
 
 Zhu 
 ZJ 
 
 
 Chen 
 C 
 
 
 Wang 
 YZ 
 
 
 Distinct processing for pictures with animals and objects: evidence from eye movements 
 Emotion 
 2012b 
 12 
 540 
 551 
 22251055 
 
 
 
 
 
 
 Zald 
 DH 
 
 
 The human amygdala and the emotional evaluation of sensory stimuli 
 Brain Res. Rev 
 2003 
 41 
 88 
 123 
 12505650 
 
 
 
 
 
 
 Figure 1 
 
 Stimulus example. Cited from  Yang et al. (2012b) . 
 
 
 
 
 Figure 2 
 
 Main effects and interactions in the amygdala. There were significant main effects of emotion, context (A) and category in the amygdala (B). The amygdala also showed significant interactions of category by emotion, category by context, emotion by context and 3-way interactions (C). 
 
 
 
 
 Figure 3 
 
 Category effect in cortical regions. The animate network and inanimate network were shown in distinct cortical regions for the main effect (A) and for negative (B) and neutral (C) pictures with human contexts. 
 
 
 
 
 Figure 4 
 
 Category effect in the amygdala for the interactions. The amygdala were activated differentially for negative and neutral pictures, pictures with and without human context (A). For the simple effect, category effects in the amygdala were shown in human-negative (H-negative), human-neutral (H-neutral), nonhuman-negative (NH-negative), and nonhuman-neutral (NH-neutral) conditions (B). Note that different from other condition, in the H-negative condition, the animals showed decreased activation than objects in the amygdala. 
 
 
 
 
 Figure 5 
 
 The aPFC activation. The aPFC showed stronger activation for negative objects than animals in the human context condition but not in other conditions (A). In addition, the activity of the left aPFC (object > animal) was positively correlated with the activity of the right amygdala in the human-negative condition, from the PPI analysis (B) and the ROI analysis (C). 
 
 
 
 
 Table 1 
 
 Rating results in different conditions. 
 
 
 
 
 
 
 Human context 
 Nonhuman context 
 
 
 
 
 Negative 
 Neutral 
 Negative 
 Neutral 
 
 
 
 
 
 
 Animal 
 Object 
 Animal 
 Object 
 Animal 
 Object 
 Animal 
 Object 
 
 
 Valence 
 Mean 
 3.08 
 2.95 
 4.84 
 4.75 
 3.65 
 3.82 
 5.10 
 4.94 
 
 
 
 SD 
 0.79 
 0.53 
 1.02 
 0.41 
 1.01 
 0.79 
 1.19 
 0.37 
 
 
 Arousal 
 Mean 
 6.61 
 6.43 
 4.51 
 4.22 
 5.89 
 5.56 
 4.02 
 3.82 
 
 
 
 SD 
 1.20 
 1.35 
 1.24 
 1.39 
 1.19 
 1.18 
 1.31 
 1.48 
 
 
 Familiarity 
 Mean 
 3.43 
 3.71 
 4.15 
 4.39 
 3.59 
 3.72 
 4.29 
 4.55 
 
 
 
 SD 
 1.41 
 1.33 
 1.51 
 0.74 
 1.39 
 1.29 
 1.54 
 0.75 
 
 
 Complexity 
 Mean 
 4.95 
 3.76 
 4.82 
 3.81 
 5.04 
 3.86 
 4.84 
 3.69 
 
 
 
 SD 
 0.87 
 0.88 
 0.89 
 0.86 
 0.86 
 0.97 
 0.85 
 0.87 
 
 
 
 
 
 Table 2 
 
 Main effects of category, emotion and context. 
 
 
 
 
 Area 
 
 Region 
 t-value 
 x 
 y 
 z 
 
 
 
 
 Category effect 
 
 
 
 
 
 
 
 
 Animal > Object 
 
 
 
 
 
 
 
 
 frontal 
 L 
 PCC 
 6.57 
 −6 
 −44 
 44 
 
 
 frontal 
 L 
 Fusiform gyrus 
 4.51 
 −44 
 −51 
 −19 
 
 
 frontal 
 R 
 PCC 
 3.52 
 14 
 −46 
 61 
 
 
 frontal 
 L 
 Insula 
 4.24 
 −39 
 14 
 16 
 
 
 frontal 
 L 
 Cingulated cortex 
 3.47 
 −6 
 −11 
 41 
 
 
 temporal 
 R 
 Fusiform gyrus/STS 
 8.49 
 41 
 −69 
 −1 
 
 
 occipital 
 L 
 Occipital cortex 
 5.78 
 −41 
 −74 
 −16 
 
 
 occipital 
 R 
 Occipital cortex 
 5.00 
 29 
 −84 
 −4 
 
 
 subcortical 
 R 
 Thalamus 
 3.85 
 4 
 −14 
 9 
 
 
 subcortical 
 L 
 Hippocampus/amygdala 
 3.63 
 −21 
 −16 
 −14 
 
 
 Animal < Object 
 
 
 
 
 
 
 
 
 frontal 
 R 
 aPFC 
 −3.73 
 41 
 46 
 −9 
 
 
 frontal 
 L 
 Middle prefrontal cortex 
 −2.81 
 −26 
 −51 
 −14 
 
 
 frontal 
 R 
 Middle prefrontal cortex 
 −3.57 
 26 
 −41 
 −6 
 
 
 frontal 
 L 
 aPFC 
 −3.37 
 −39 
 46 
 −4 
 
 
 parietal 
 L 
 Intraparietal cortex 
 −5.17 
 −44 
 −36 
 41 
 
 
 parietal 
 R 
 Parietal cortex 
 −3.36 
 29 
 −69 
 49 
 
 
 temporal 
 L 
 Middle temporal cortex 
 −5.43 
 −49 
 −56 
 −6 
 
 
 Emotional effect 
 
 
 
 
 
 
 
 
 Negative > Neutral 
 
 
 
 
 
 
 
 
 frontal 
 L 
 aPFC 
 4.98 
 −39 
 26 
 −9 
 
 
 frontal 
 R 
 Postcentral cortex 
 5.41 
 54 
 −21 
 29 
 
 
 frontal 
 R 
 Middle prefrontal cortex 
 5.00 
 44 
 −1 
 44 
 
 
 frontal 
 L 
 middle frontal 
 4.24 
 −44 
 29 
 19 
 
 
 frontal 
 L 
 Cingulated cortex 
 4.85 
 −9 
 −31 
 39 
 
 
 frontal 
 L 
 Premotor cortex 
 5.19 
 −41 
 −6 
 39 
 
 
 frontal 
 R 
 Premotor cortex 
 4.00 
 31 
 21 
 −39 
 
 
 frontal 
 R 
 inferior frontal cortex 
 3.89 
 46 
 29 
 −1 
 
 
 parietal 
 R 
 Precuneus 
 4.71 
 24 
 −49 
 46 
 
 
 parietal 
 R 
 Precuneus 
 6.01 
 34 
 −36 
 49 
 
 
 subcortical 
 LR 
 Amygdala 
 5.87 
 −24 
 −6 
 −9 
 
 
 subcortical 
 R 
 Amygdala 
 5.37 
 21 
 −1 
 −9 
 
 
 subcortical 
 R 
 Amygdala 
 4.91 
 29 
 −1 
 −24 
 
 
 subcortical 
 R 
 Thalamus 
 3.95 
 11 
 −16 
 −1 
 
 
 Negative < Neutral 
 
 
 
 
 
 
 
 
 frontal 
 R 
 aPFC 
 −5.09 
 36 
 49 
 −6 
 
 
 frontal 
 R 
 Middle frontal cortex 
 −5.20 
 41 
 41 
 19 
 
 
 frontal 
 R 
 Super. Frontal cortex 
 −4.39 
 24 
 21 
 49 
 
 
 parietal 
 R 
 Parietal cortex 
 −5.90 
 41 
 −56 
 34 
 
 
 parietal 
 L 
 Parietal cortex 
 −4.19 
 −36 
 −61 
 39 
 
 
 temporal 
 R 
 Middle temporal cortex 
 −5.21 
 54 
 −21 
 −16 
 
 
 Contextual effect 
 
 
 
 
 
 
 
 
 H > NH context 
 
 
 
 
 
 
 
 
 frontal 
 R 
 Middle frontal cortex 
 9.92 
 44 
 21 
 21 
 
 
 frontal 
 L 
 Middle frontal cortex 
 7.00 
 −41 
 16 
 29 
 
 
 frontal 
 R 
 Medial frontal cortex 
 3.79 
 9 
 51 
 26 
 
 
 frontal 
 L 
 aPFC 
 4.01 
 −4 
 36 
 −14 
 
 
 frontal 
 L 
 Medial frontal cortex 
 3.39 
 −4 
 49 
 41 
 
 
 parietal 
 L 
 Parietal cortex 
 7.52 
 −56 
 −26 
 24 
 
 
 subcortical 
 R 
 lingual/subcortical region 
 7.42 
 21 
 −54 
 1 
 
 
 subcortical 
 R 
 Amygdala 
 6.30 
 21 
 −6 
 −6 
 
 
 subcortical 
 L 
 Amygdala 
 5.77 
 −19 
 −9 
 −6 
 
 
 subcortical 
 L 
 Amygdala 
 6.54 
 −24 
 4 
 −16 
 
 
 subcortical 
 R 
 Parahippocampal cortex 
 4.17 
 41 
 −16 
 −21 
 
 
 subcortical 
 L 
 Thalamus 
 3.17 
 −14 
 −74 
 −34 
 
 
 temporal 
 R 
 Super. Temporal cortex 
 6.06 
 56 
 1 
 −16 
 
 
 temporal 
 L 
 Anterior temporal cortex 
 4.15 
 −39 
 −1 
 −29 
 
 
 
 LR 
 Occipital/temporal cortex 
 11.44 
 44 
 −61 
 6 
 
 
 H < NH context 
 
 
 
 
 
 
 
 
 occipital 
 R 
 Lingual gyrus 
 −5.21 
 21 
 −91 
 −6 
 
 
 occipital 
 R 
 Lingual gyrus 
 −4.29 
 6 
 −86 
 −1 
 
 
 parietal 
 R 
 Supermarginal gyrus 
 −2.75 
 41 
 −51 
 36 
 
 
 
 
 
 Table 3 
 
 Interaction effects among category, affect and context 
 
 
 
 
 Area 
 
 Region 
 F-value 
 x 
 y 
 z 
 
 
 
 
 Category by affect 
 
 
 
 
 
 
 
 
 frontal 
 L 
 Super. frontal cortex 
 18.16 
 −16 
 51 
 16 
 
 
 frontal 
 R 
 Orbital PFC 
 16.76 
 19 
 61 
 1 
 
 
 frontal 
 L 
 Orbital PFC 
 21.91 
 −26 
 56 
 4 
 
 
 frontal 
 R 
 Precentral cortex 
 24.59 
 56 
 4 
 34 
 
 
 frontal 
 R 
 Precentral cortex 
 17.55 
 56 
 −4 
 6 
 
 
 frontal 
 L 
 Medial frontal cortex 
 31.76 
 −6 
 6 
 51 
 
 
 frontal 
 L 
 Super. frontal cortex 
 30.13 
 −14 
 44 
 36 
 
 
 frontal 
 L 
 aPFC 
 19.54 
 −6 
 54 
 14 
 
 
 frontal 
 L 
 ACC 
 16.80 
 −14 
 39 
 4 
 
 
 occipital 
 R 
 Occipital cortex 
 18.53 
 4 
 −79 
 26 
 
 
 temporal 
 L 
 Anterior temporal cortex 
 19.99 
 −51 
 4 
 −19 
 
 
 temporal 
 L 
 Super. Temporal cortex 
 19.04 
 −39 
 −59 
 19 
 
 
 temporal 
 L 
 Anterior temporal cortex 
 17.50 
 −49 
 14 
 −19 
 
 
 subcortical 
 L 
 Amygdala 
 18.75 
 −31 
 −6 
 −11 
 
 
 subcortical 
 L 
 Amygdala 
 14.04 
 −14 
 −4 
 −11 
 
 
 Category by context 
 
 
 
 
 
 
 
 
 occipital 
 R 
 Middle occipital cortex 
 22.94 
 44 
 −69 
 −4 
 
 
 parietal 
 L 
 Precuneus 
 21.53 
 −11 
 −64 
 39 
 
 
 parietal 
 L 
 Precuneus 
 20.09 
 11 
 −56 
 39 
 
 
 temporal 
 L 
 Fusiform gyrus/PHG 
 19.45 
 −24 
 −41 
 1 
 
 
 temporal 
 R 
 Fusiform gyrus 
 19.62 
 39 
 −44 
 −14 
 
 
 temporal 
 L 
 Fusiform gyrus 
 16.58 
 −44 
 −39 
 −21 
 
 
 subcortical 
 L 
 Midbrain 
 14.82 
 −11 
 −16 
 −29 
 
 
 subcortical 
 R 
 Hippocampus 
 16.51 
 36 
 −36 
 −4 
 
 
 subcortical 
 L 
 Hippocampus 
 13.86 
 −16 
 −39 
 6 
 
 
 subcortical 
 L 
 Perirhinal cortex 
 19.64 
 −26 
 −21 
 −19 
 
 
 subcortical 
 L 
 Amygdala 
 14.04 
 −26 
 −1 
 −13 
 
 
 Affect by context 
 
 
 
 
 
 
 
 
 frontal 
 L 
 Inferior frontal cortex 
 60.74 
 −51 
 14 
 21 
 
 
 frontal 
 R 
 Inferior frontal cortex 
 34.86 
 39 
 21 
 24 
 
 
 frontal 
 L 
 aPFC 
 23.43 
 −16 
 49 
 19 
 
 
 frontal 
 R 
 aPFC 
 36.67 
 31 
 29 
 −11 
 
 
 frontal 
 L 
 aPFC 
 12.27 
 −29 
 29 
 −9 
 
 
 frontal 
 L 
 Medial frontal cortex 
 26.48 
 −1 
 34 
 39 
 
 
 frontal 
 L 
 Super. frontal cortex 
 14.75 
 −21 
 11 
 54 
 
 
 frontal 
 L 
 Precentral cortex 
 20.71 
 −34 
 −6 
 49 
 
 
 frontal 
 L 
 Insula 
 12.99 
 −26 
 21 
 14 
 
 
 occipital 
 R 
 Occipital cortex 
 22.29 
 26 
 −76 
 −16 
 
 
 occipital 
 L 
 Occipital cortex 
 12.86 
 −16 
 −76 
 −21 
 
 
 occipital 
 R 
 cuneus 
 12.91 
 1 
 −69 
 11 
 
 
 parietal 
 R 
 Precuneus 
 13.15 
 26 
 −54 
 34 
 
 
 temporal 
 L 
 Fusiform gyrus 
 45.55 
 −21 
 −86 
 −14 
 
 
 temporal 
 L 
 Super. Temporal cortex 
 23.65 
 −34 
 −76 
 21 
 
 
 temporal 
 R 
 Fusiform gyrus 
 22.38 
 44 
 −61 
 −14 
 
 
 temporal 
 R 
 Fusiform gyrus/PHG 
 27.50 
 21 
 −36 
 −9 
 
 
 temporal 
 R 
 Anterior temporal cortex 
 24.39 
 36 
 4 
 −26 
 
 
 temporal 
 L 
 Super. Temporal cortex 
 27.35 
 −46 
 −26 
 −1 
 
 
 subcortical 
 L 
 Midbrain 
 33.49 
 −4 
 −24 
 −19 
 
 
 subcortical 
 L 
 Thalamus 
 20.12 
 −11 
 −11 
 6 
 
 
 subcortical 
 L 
 PHG 
 14.62 
 −24 
 −66 
 −31 
 
 
 subcortical 
 L 
 Amygdala 
 14.58 
 −21 
 −6 
 −4 
 
 
 3-way interaction 
 
 
 
 
 
 
 
 
 frontal 
 L 
 aPFC 
 21.85 
 −34 
 41 
 −9 
 
 
 frontal 
 R 
 Inferior frontal cortex 
 22.85 
 54 
 21 
 21 
 
 
 frontal 
 R 
 Inferior frontal cortex 
 17.15 
 41 
 14 
 39 
 
 
 parietal 
 L 
 Superior parietal cortex 
 18.47 
 −19 
 −54 
 64 
 
 
 parietal 
 L 
 Precuneus 
 21.35 
 −14 
 −36 
 49 
 
 
 subcortical 
 L 
 Amygdala 
 6.01 
 −19 
 1 
 −16 
 
 
 
 
 
 Table 4 
 
 DCM parameters showing the estimated mean (SD) for the winning Family C in Hertz 
 
 
 
 
 
 NH-negative objects 
 H-negative animals 
 
 
 
 
 aPFC to amyg 
 0.14 (0.15) 
 0.08 (0.14) 
 
 
 Amyg to aPFC 
 0.02 (0.02) 
 0.03 (0.02) 
 
 
 C on aPFC to amyg 
 0.10 (0.18) 
 0.06 (0.22) 
 
 
 C on amyg to aPFC 
 −0.02 (0.24) 
 0.04 (0.10) 
 
 
 
 
 
 Note: C for conditions means the modulatory effect. 
 
 
 
 
