
 properties manuscript? 
 
 
 8910747 
 20835 
 J Cogn Neurosci 
 J Cogn Neurosci 
 
 Journal of cognitive neuroscience 
 
 0898-929X 
 1530-8898 
 
 
 26439272 
 5034353 
 10.1162/jocn_a_00891 
 NIHMS814086 
 
 
 Article 
 
 
 
 Cortical Thickness in Fusiform Face Area Predicts Face and Object Recognition Performance 
 
 
 
 
 McGugin 
 Rankin W. 
 
 1 
 
 
 
 Van Gulick 
 Ana E. 
 
 2 
 3 
 
 
 
 Gauthier 
 Isabel 
 
 1 
 
 
 1 Department of Psychology, Vanderbilt University, Nashville, TN, USA 
 2 University Libraries, Carnegie Mellon University, Pittsburgh, PA, USA 
 3 Center for the Neural Basis of Cognition, Carnegie Mellon University, Pittsburgh, PA, USA 
 
 * Correspondence to: Rankin W. McGugin, Department of Psychology, Vanderbilt University,  Rankin.McGugin@vanderbilt.edu , Phone: 615-416-1312, Fax: 615-322-4706 
 
 REGULAR MAIL (via U.S. Postal Service), Vanderbilt University, PMB 407817, 2301 Vanderbilt Place, Nashville, TN 37240-7817, USA 
 
 
 COURIER MAIL (via Fed Ex, UPS), Department of Psychology, 301 Wilson Hall, Vanderbilt University, Nashville, TN 37240, USA 
 
 
 
 2 
 9 
 2016 
 
 
 06 
 10 
 2015 
 
 
 2 
 2016 
 
 
 23 
 9 
 2016 
 
 28 
 2 
 282 
 294 
 
 
 This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law. 
 
 
 
 The fusiform face area (FFA) is defined by its selectivity for faces. Several studies have shown that the response of FFA to non-face objects can predict behavioral performance for these objects. However, one possible account is that experts pay more attention to objects in their domain of expertise, driving signals up. Here we show an effect of expertise with non-face objects in FFA that cannot be explained by differential attention to objects of expertise. We explore the relationship between cortical thickness of FFA and face and object recognition using the Cambridge Face Memory Test and Vanderbilt Expertise Test, respectively. We measured cortical thickness in functionally-defined regions in a group of men who evidenced functional expertise effects for cars in FFA. Performance with faces and objects together accounted for approximately 40% of the variance in cortical thickness of several FFA patches. While subjects with a thicker FFA cortex performed better with vehicles, those with a thinner FFA cortex performed better with faces and living objects. The results point to a domain-general role of FFA in object perception and reveal an interesting double dissociation that does not contrast faces and objects, but rather living and non-living objects. 
 
 
 Cortical thickness 
 Fusiform face area 
 Modularity of the mind 
 Object recognition 
 
 
 
 
 Introduction 
 Functional brain imaging research has offered strong support for localized functions in the brain. However, brain imaging findings often generate debate with respect to the attribution of specific cognitive functions to patterns of localized responses ( Burton et al., 2000 ;  Price & Devlin, 2003 ;  Shomstein & Yantis, 2006 ;  Grodzinsky & Santi, 2008 ). For instance, should we conceive of the FFA as a specialized module dedicated only to the processing of faces, with little if any role in the processing of other objects ( Kanwisher 2010 )? Or can we understand the strong selectivity for faces in FFA as resulting from expertise with faces, such that other objects with similar experience would also recruit the FFA ( Tarr & Gauthier, 2000 )? Questioning the evidence of domain-specificity in FFA is questioning some of the strongest evidence of domain-specificity in the visual system and the brain. 
 Fifteen years past the first experiment reporting expertise effects in FFA following training with novel objects called Greebles ( Gauthier & Tarr, 1997 ), several studies of individual variability in FFA BOLD response in real-world domains suggest that the response of FFA to non-face objects can predict behavioral performance for these objects (e.g.,  Bilalić et al. 2011 ;  Gauthier et al. 2000 ;  McGugin et al. 2014a ;  Xu 2005 ). Expertise effects are obtained in the very middle of the FFA ( McGugin et al. 2014b ), even in the most highly face-selective voxels in high-resolution scans ( McGugin et al. 2012a ). However, other studies have found no correlation between performance with cars and FFA response (e.g.,  Grill-Spector, Knouf & Kanwisher, 2004 ), or failed to replicate the Greeble training effect ( Brants, Wagemans & Op de Beeck, 2011 ) 1 . 
 One concern about expertise effects in the visual system is that they may be due to greater attention to objects of expertise ( Harel et al. 2010 ). This account has been challenged by demonstrations of robust expertise effects in FFA under conditions that reduce these effects in other visual areas ( McGugin et al. 2014a ;  2014b ). However, attention is a strong modulator of responses in visual cortex ( Pessoa, Kastner & Ungerleider, 2003 ), and it is plausible for people to pay more attention to objects of expertise (including faces). An attentional account of expertise effects of functional MRI data is difficult to rule out entirely. 
 Here we turn to the study of the structural correlates of face and object recognition ability and note that such expertise effects, whether they are related to functional effects or not, could not be explained by attention. Test-retest reliability of structural MRI data and, specifically, surface maps of CT, are highly reproducible with high intra-class correlations ( Wonderlick et al., 2008 ), allowing us to comfortably look at individual differences in regional CT. Measures of regional brain structure have been successfully associated with performance in a number of domains ( Golestani et al. 2002 ;  Schneider et al. 2005 ;  Hyde et al. 2006 ;  Shaw et al. 2006 ;  Narr et al. 2007 ;  Wong et al. 2008 ;  Karama et al. 2009 ;  Foster & Zatorre 2010; 
 Schwarzkopf et al. 2011 ;  Delon-Martin et al. 2013 ). These studies demonstrate individual differences in brain structure in the same areas where differences in BOLD activation are seen, and both types of brain reorganization are associated with domain-specific behavioral differences. Accordingly, we may expect CT in FFA to be related to behavioral face recognition performance ( Kanwisher et al. 1997 ;  Grill-Spector et al. 2004 ;  Xu 2005 ;  McGugin et al. 2012a ). 
 In one study with prosopagnosic patients, the right fusiform gyrus showed reduced grey matter volume relative to normal controls ( Garrido et al. 2009 ). But using healthy subjects, recent work ( Bi et al. 2014 ) found a negative correlation between cortical thickness in left FFA and improvements in a task involving judging the orientation of faces. This was not a face recognition task and so it is unclear whether face performance should also show the same negative correlation with CT or follow the general trend observed when performance in patients vs. controls is correlated with BOLD response. 
 We might also expect CT in FFA to be related to  object  recognition performance, based on functional effects of expertise in this region. However, one report found that expertise with cars was related to gray matter volume in the prefrontal cortex, but not in the fusiform gyrus ( Gilaie-Dotan et al. 2012 ). We chose to revisit this question because the aforementioned study used a group-averaged template, as is typical in brain morphometry, to look for brain areas whose structure might be related to behavior. Even when functional ROIs have been used in studies looking at brain structure ( Bi et al. 2014 ), they have typically been group-averaged ROIs. Within the fusiform gyrus, functional effects of expertise are spatially limited to two small face-selective areas ( Weiner et al. 2014 ) and are best revealed in individually defined ROIs. 
 We performed CT analyses in individually defined functional ROIs in a sample of twenty-seven men who were recruited to vary in their expertise for cars. We defined regions of interest functionally and individually. None of the prior work with CT used individual functional ROIs. In addition, our structural scans come from a sample of subjects who showed the expected positive correlation between behavioral performance with cars and FFA selectivity to cars in a prior study ( McGugin et al. 2014b ). Therefore, we are able to ask if CT predicts behavioral performance in subjects whose performance with cars was related to the BOLD selectivity for cars. Critically, however, there is no reason why cortical thickness should be specifically related to the object category(ies) used in our separate functional task. Brain structure could be related to performance with any object category. For this reason, we used behavioral performance for a variety of object categories and faces, in a battery of visual learning tasks (the Vanderbilt Expertise Test, VET ( McGugin et al., 2012b ) and the Cambridge Face Memory Test, CFMT ( Duchaine and Nakayama, 2006 )). VET performance for vehicles shows a stronger relationship with the CFMT in men than women ( McGugin et al. 2012b ). Because of such sex differences, and because the sample we used was composed of men (sex has too large of an effect on CT to justify including the three females in the original  McGugin et al., 2012a  study), we decided to index object recognition performance according to the two principle factors extracted from a principle component analysis of the VET results which, in prior work, also correlated with sex. The first factor corresponds to living objects (on which women generally performed better than men) and the second corresponds to non-living objects (on which men generally performed better than women ( McGugin et al. 2012b )). Thus, the behavioral indices of performance used here are the same measures as in several studies of expertise ( Gauthier et al. 2000 ;  Grill-Spector et al. 2004 ;  Rossion et al. 2004 ;  Gauthier et al. 2005 ;  Xu 2005 ;  Curby et al. 2009 ;  McGugin et al. 2014a; 
 2014b ). We average categories for which performance tends to be correlated, which may help detect small effects associated with each category. Because this study sample was recruited with regards to their car expertise, we also investigate correlations with car performance alone. 
 We hypothesized that we would find linear relationships between CT in FFA and performance for both faces and objects. Importantly, the literature contains examples of better performance in various domains that are associated with either thicker ( Foster & Zatorre, 2010 ;  Karama et al., 2009 ;  Narr et al., 2007 ;  Choi et al., 2008 ) or thinner ( Hyde et al., 2007 ;  Jung et al., 2010 ) cortex. For this reason, we do not formulate a prediction for the direction of the linear relations between performance and local cortical thickness, and we use two-tailed tests. 
 
 
 Methods 
 
 Subjects 
 Twenty-seven healthy right-handed men (range: 18–34; mean: 26 ± 4.7 years) participated as volunteers for a larger study that also included three women, aimed at investigating effects of behavioral expertise under conditions of visual clutter ( McGugin et al. 2014b ). The current work represents a new analysis of the structural data that was used in  McGugin et al. (2014b)  only as support for functional analyses. Informed written consent was obtained from each subject in accordance with guidelines of the institutional review board of Vanderbilt University and Vanderbilt University Medical Center. All subjects received monetary compensation for their participation and had normal or corrected-to-normal vision. One subject was discarded due to outlier performance (at or below chance of .33) for six of the eight object categories in the behavioral memory test. 
 
 
 Behavioral Assessments 
 All subjects completed three behavioral tasks outside the scanner: the Cambridge Face Memory Test (CFMT) ( Duchaine and Nakayama 2006 ), the Vanderbilt Expertise Test (VET) ( McGugin et al. 2012b ), and a sequential matching expertise test used to quantify individual skill at matching cars ( Gauthier et al. 2000 ;  Grill-Spector et al. 2004 ;  Rossion et al. 2004 ;  Gauthier et al. 2005 ;  Xu 2005 ;  Curby et al. 2009 ;  McGugin et al. 2012a ). See  Table 1  for descriptive statistics for all behavioral measures. 
 In the CFMT, subjects study three images (left 1/3 profile, frontal view, right 1/3 profile) of the first target face for three seconds per image, immediately followed by three test items where subjects select the studied image amongst two distractors. This introductory learning phase is repeated for the remaining five target faces. Subjects were then presented with 30 forced-choice test displays each containing one target face and two distractor faces. Subjects were instructed to select the face that matched one of the original six target faces. The matching faces varied from their original presentation by means of lighting, pose, or both. Next, subjects were again presented with the six target faces to study, followed by 24 test displays presented in Gaussian noise. For a complete description of the CFMT, see  Duchaine & Nakayama (2006) . 
 The VET ( McGugin et al. 2012b ) includes eight object categories blocked alphabetically: butterflies, cars, leaves, motorcycles, mushrooms, owls, planes, and wading birds. For each category, subjects studied a display with images from each of six species/models. For each test trial, one of the studied targets (identical images for the first twelve trials, or transfer images requiring generalization across viewpoint, size, and settings for the subsequent 36 trials) was presented with two distractors from another species/model in a forced-choice paradigm. The target image could occur in any of the three positions and subjects indicated which image of the triplet was the studied target. Before beginning the VET, participants rated themselves on their expertise with all tested categories (leaves, owls, butterflies, wading birds, mushrooms, cars, planes, and motorcycles), and also with faces, considering “interest in, years exposure to, knowledge of, and familiarity with each category”, where 1 represented the lowest reported skill level and 9 represented the highest. See  Table 1  for descriptive statistics of self-report (SR) scores. For a complete description of the VET, see  McGugin et al. (2012b) . 
 Principle component analysis has demonstrated that the underlying structure of the eight-category VET is largely explained by two independent factors that represent living and non-living objects. Therefore, we reduced VET performance to a Living Objects score (VET-LV; average of butterflies, leaves, mushrooms, owls, wading birds) and a Non-Living Objects score (VET-NL; average of cars, motorcycles, and planes). 
 The matching task has 112 sequential matching trials for each of three categories: cars, planes and birds (56 unique images/category). On each trial, a first stimulus appeared for 1000 ms, followed by a 500-ms mask and second stimulus that remained visible until subjects made a same or different response, or 5000 ms elapsed. Subjects judged if the two images showed cars/planes of the same make and model regardless of year, or birds of the same species. 
 
 
 MRI acquisition 
 Scanning was performed using a Philips 3-Tesla Intera Achieva MRI scanner with an eight-channel head coil located at the Vanderbilt University Institute for Imaging Science. High resolution (HR) T1-weighted anatomical volumes were acquired (TR, 8.93 ms; TE, 4.6 ms; flip angle, 9°; FOV, 256 × 256; slice thickness, 1 mm, no gap; in-plane resolution, 1 × 1 mm; 170 slices acquired in the sagittal plane). In a functional localizer run, we used standard gradient-echo echoplanar T2*-weighted imaging to obtain functional images (TR, 2000 ms; TE, 35 ms; flip angle, 79°; FOV, 192 × 192; slice thickness, 3 mm, no gap; in-plane resolution, 3 × 3 mm; 34 ascending interleaved slices acquired axially). 
 The structural scan was processed using Brain Voyager v2.6 ( www.brainvoyager.com ). First, steps were taken to prepare the brain for automatic correction of intensity inhomogeneities; the image background was cleaned, the brain was extracted, and the bias field was estimated and removed. The cerebellum and brainstem were manually removed for each brain. After automatic intensity inhomogeneity correction, the grey matter and white matter intensities were centered around intensity values of 100 and 160, respectively. Brains were then Talairach-normalized and interpolated to .5 × .5 × .5 mm resolution. The white/grey matter boundary was segmented, after which the grey matter/cerebrospinal fluid boundary (corresponding to the pial surface, or the outer boundary of the cortex) was labeled. 
 For the functional localizer scan, all images were presented with an Apple Macintosh computer running Matlab (MathWorks, Natick, MA) using the Psychophysics Toolbox extension ( Brainard 1997 ;  Pelli 1997 ). Stimuli were displayed on a rear-projection screen using an Eiki LC-X60 LDP projector with a Navitar zoom lens. 72 grayscale images (36 faces, 36 objects) were used in a 1-back detection task with 18 alternating blocks of faces or objects (16 images shown for 1s) and a 2 s fixation at the beginning and end of each block. Sensitivity did not differ for Face and Object blocks: (hit rate, false alarm rate) Face (0.92, 0.008), Object (0.93, 0.004). 
 Following the functional localizer scan, subjects completed eight runs using different combinations of images and tasks (See  McGugin et al. 2014b  for full details). To verify the face-selectivity of the ROIs in this subset of subjects, we analyzed only the first two of these experimental runs to obtain an independent measure of face selectivity in the ROIs defined in the functional localizers. These runs showed single objects presented in isolation in a blocked fMRI design with a 1-back repetition task of face, car or butterfly images. 
 
 
 Data Analysis 
 The HR T1-weighted structural scans were normalized to Talairach space. Functional data were analyzed using Brain Voyager ( www.brainvoyager.com ) and in-house Matlab scripts. Preprocessing included registration to the original (non-transformed) structural scan, slice scan time correction (cubic spline), 3D motion correction (trilinear/sinc interpolation) and temporal filtering (high-pass criterion of 2 cycles per run) with linear trend removal. 
 Regions of interest (ROIs) were defined using the Face>Object contrast from the face-localizer scan ( Table 2 ). For ROI analyses, no spatial smoothing was applied to the CT maps. We localized bilateral ROIs that responded more to faces than objects in the posterior fusiform gyrus (FFA1), middle fusiform gyrus (FFA2) ( Pinsk et al. 2009 ;  Weiner et al. 2010 ), and occipital face area (OFA), and more to objects than faces in the parahippocampal gyrus (PHG). To verify the face selectivity of these regions using functional data independent from the localizer, we examined the BOLD response to faces relative to a butterfly baseline (cars were not used because several subjects were car experts). As expected, there was a larger response to faces vs. butterflies in bilateral FFA1, FFA2, and OFA, and the opposite effect in object-defined regions in the PHG ( Table 2 ). 
 All ROIs were initially defined based on the 1 mm (interpolated) statistical maps using a fixed mm spread of activation to ensure consistency with reported sizes of these functional ROIs in the literature as well as consistency across subjects ( Table 1 ). However, to ensure that the signal was weighted per functional voxel, ROIs were subsequently down-sampled to functional (3 mm) resolution. Any functional voxel containing one or more 1 mm voxel from the initial ROI was considered to be part of the final ROI, thus leading to larger final ROIs relative to those initially defined. Functional voxels that were members of multiple initial ROIs were dropped from all final ROIs. This latter qualification avoided partial-volume effects with regard to functional region membership. 
 In addition to our functionally-defined ROIs, we anatomically defined an additional four regions in the precentral and frontal gyri to correspond to the regions where car expertise effects were reported in  Gilaie-Dotan et al. (2012) . We had no means to define this region functionally. The location and extent of these regions was fixed across all subjects (see  Table 4  legend). 
 To test whether CT varied as a function of ROI size and distance from the peak of face-selectivity, we defined four additional clusters for bilateral FFA1 and FFA2 in each individual. First, we localized the peak face-selective voxel of each ROI based on the localizer scan. We computed mean CT from this peak voxel, in addition to the 4, 16, and 60 contiguous voxels around this peak, following the spread of face-object activation. 
 For all ROIs, we computed the partial correlation between the mean CT over all voxels with each VET factor, regressing out the other VET factor as well as global CT and age, since CT has been shown as highly sensitive to age ( Shaw et al. 2008 ). Zero-order correlations and partial correlations for each ROI are presented in  Table 3 . All correlations between CT and behavioral performance were tested for bivariate outliers, which were denoted as points whose externally studentized residual was >3.5 or <−3.5. Partial correlations are reported in  Table 3 . 
 To perform group-level statistical data analyses on cortical thickness maps, we used an advanced, high-resolution, cortical matching approach ( Goebel et al. 2002 ;  2004 ;  Frost & Goebel 2012 ) to align brains using cortex curvature information (i.e., the gyral/sulcal folding patterns). Cortex-based alignment (CBA) operates in several phases during which individual hemispheres are morphed into spheres providing a parameterizable surface suited for across-subject non-rigid alignment. Alignment proceeds iteratively following a coarse-to-fine matching strategy, moving from highly smoothed curvature maps to minimally smoothed maps ( Goebel et al. 2002 ;  2004 ;  2006 ;  Frost & Goebel 2012 ). 
 CBA was used to compute average thickness maps across subjects. While cortical thickness measurements are performed in volume space in individual brains, they are performed in surface space for group analyses to benefit from cortical alignment. 
 During the segmentation procedure, all structural datasets were upsampled from the 1.0 mm iso-voxel acquisition resolution to 0.5 mm iso-voxel resolution using sinc interpolation. For whole-brain group analyses only, individual CT maps were smoothed by a factor of 2 times the size of the upsampled voxel, using 1mm FWHM. These smoothed maps were subsequently used as input in a group correlation analysis. 
 We used a corrected two-tail alpha of .05 for whole-brain analyses. These analyses seeking areas where cortical thickness correlated with VET-LV, VET-NL and CFMT performance failed to reveal significant clusters of activation. Whole-brain analyses are inherently less powerful than ROI analyses both due to correction for multiple comparisons and to the greater variance expected when subjects are compared in regions aligned according to gross anatomical rather than functional landmarks. 
 
 
 Cortical Thickness 
 Cortical thickness measurements in Brain Voyager QX are based on the Laplace method ( Jones et al. 2000 ). Three tissue classes are identified in the anatomical image based on a voxel’s intensity value, i: CSF (i < 75), GM (75 ≤ i ≤ 125) and WM (i > 125). For each gray matter voxel, a streamline is calculated - using a small step size of 0.1 and trilinear interpolation - by following a gradient in one direction and then the opposite direction to obtain a thickness measure for that gray matter voxel. 
 Measurement of cortical thickness of individual segmented cortical hemispheres is performed first in volume space, but can be projected on the surface with the help of gradient maps. See  Table 1  for descriptive statistics. 
 
 
 
 Results 
 
 Relationship between performance and cortical thickness 
 Just as living and non-living performance scores were computed, so were living and non-living self-report scores. Self-report scores of experience for living and non-living categories were significantly correlated (r=.48), and the only significant correlation between self-report and performance was that self-report for non-living objects negatively predicted VET-LV (r=−.45). These results are consistent with prior reports that self-reports generally do a poor job predicting performance ( McGugin et al. 2012a ), probably because we have limited opportunity to compare our perceptual skills to those of others. In addition, self-reports did not correlate significantly with CT in any ROI. 
 Table 3  provides correlations between our behavioral measures of performance with faces (CFMT) and living (VET-LV) and non-living (VET-NL) object categories, as well as the partial correlations that involve measures of cortical thickness (CT) in the various ROIs (we first regressed age and global CT out of the CT values within each ROI; see  Figure 1  and  Table 1  for CT averages and spreads). ( Figure 1  shows the distribution of raw scores for CFMT and VET.) Performance with faces and non-face objects showed no significant correlation in this sample, although each measure was reliable (Cronbach Alpha: VET-LV= .89; VET-NL=.91) and showed considerable variability ( Table 1 ). 
 Table 3  also presents the partial correlations between performance measures and CT across functional ROIs. The only significant effects were found in the FFAs ( Figures 2 – 3 ). The only significant positive correlation for VET was in rFFA2, where CT was related to VET-NL (r=.42) ( Figure 2 ). To correspond to the VET scores, we grouped the matching performance for cars and planes (r=.57), while birds was the only living category. Matching performance for cars/planes was correlated with VET-NL (r=.55), and showed a similar positive correlation with CT in rFFA2 (r=.43). Matching cars/planes produced the same positive correlation in the left FFAs, an effect that was not seen for VET scores (even when restricted to cars and planes, the correlations with the two left FFAs are both .24). We can only speculate that it is possible the requirements of the matching task tap better into left hemisphere representations, but this conjecture would have to be investigated. 
 In contrast to these positive correlations for cars/planes, VET-LV showed significant negative correlations with CT in the two left FFA ROIs ( Figure 3 ). Performance on the CFMT was negatively correlated with CT in rFFA1 ( Figure 2 ). The matching task for birds did not correlate with CT in any area, although the only negative correlation was observed in the lFFA2 where the relationship with VET-LV was also most negative. 
 Interestingly, even when we restrict our analyses to consider thickness in the single maximally face-selective voxel, the pattern observed at the larger size ROIs remains in lFFA1 (r VET-LV =−.49) and in rFFA2 (r VET-NL =.39). Other effects, however, were considerably reduced, including that of VET-LV in lFFA2 (r VET-LV =−.30) and of CFMT in rFFA1 (r CFMT =−.22). In addition to these ventral areas, we explicitly probed for frontal effects by defining four areas in the frontal and precentral gyri of all subjects. These four ROIs were placed in regions showing CT effects of car expertise in prior work ( Gilaie-Dotan et al. 2012 ). Only one region in the right superior frontal gyrus (rSFG) showed a positive correlation between behavioral performance (VET-LV) and regional CT (r=.41) ( Table 4 ). 
 Finally, in contrast to our functionally- and anatomically-defined ROI results, whole-brain correlation analyses performed at the group level in average brain space did not reveal any significant effects between behavior and CT, even at a liberal threshold. Note that maps in  Figures 2c  and  3c  depict average CT across all subjects irrespective of behavior. Due to individual differences in CT, as well as error in cortical registration, these group maps do not reflect the full range of CT variability found in individual subjects. 
 
 
 Multiple-regressions on cortical thickness 
 Performance with faces and objects was not strongly related, and as such, it is possible that they account for different parts of the variance in CT. We conducted multiple regressions to assess how much variance in CT these variables could explain together in each ROI. All three predictors (CFMT, VET-LV, and VET-NL) were entered simultaneously in a multiple regression. The results for the four FFA ROIs are shown in  Table 5 , including the zero-order correlations ( Table 3 ) for comparison with the partial correlations (note that they are not strictly speaking zero-order because age and global CT were regressed out, but they do not take into account any of the other behavioral measures). Neither the full models nor the partial correlations were significant in the other non-FFA functionally-defined ROIs. 
 These analyses allow us to ask how much unique variance is explained by each of the three measures. While the simple correlations reveal that VET-NL was a significant predictor of CT only in rFFA2, when VET-LV and CFMT are partialed out, both the right and left FFA1s also show the same positive correlation. This means that one or both of the other variables was suppressing this relation. We identified the suppressor by removing each variable in turn from the regressions. In the rFFA1, this suppressor variable was CFMT, and adding VET-LV had little influence on the VET-NL predictor. In the lFFA1, both of the other predictors were necessary for VET-NL to reach significance. In contrast, VET-LV remained a predictor in these multiple regressions, similar to when it was used as the sole behavioral predictor, in two areas: VET-LV accounted for unique variance (a negative correlation) in CT for both lFFA1 and lFFA2. Finally, there was unique variance in CT accounted for by the CFMT in both the right and left FFA1. 
 
 
 Relationship between functional and structural effects of expertise 
 The functional results for the present dataset were presented in  McGugin et al. 2014b  and revealed a significant relationship between the BOLD response to cars relative to faces in both FFAs of both hemispheres, and when the BOLD response to birds was used as a baseline, significant effects of car expertise in rFFA2, and both left FFAs. 
 Our finding that behavior for different categories can be related to the CT in the same area in different ways illustrates how difficult it would be to make predictions between such relative functional responses and CT measurements. The same ROI can yield many different responses for the same category depending on the task, whereas structural effects are stable and can reflect simultaneously the independent influence of many familiar categories. 
 Nonetheless, to test whether there was a link between the structural effects of CT and the functional BOLD-based effects of car expertise in  McGugin et al. (2014b) , we correlated across subjects the CT and the Michelson contrast ratios for cars (or faces) relative to birds ((Car − Bird)/(Car + Bird) and (Face − Bird)/(Face + Bird)), in each FFA ROI (4 standard resolution voxels). These functional responses were not significantly correlated with CT in any of the FFA ROIs (see  Table 6 ). The largest effect size is observed in the relationship between CT and the face response in rFFA1 (r=−.33, p=.12), which is in the same direction as the relation between CFMT and CT in this ROI. Future studies should consider functional responses to more object categories and the use of an unfamiliar object category as a baseline (so that effects can be investigated for each familiar category independently). 
 
 
 
 Discussion 
 We investigated how performance with objects and faces relate to CT in several individually-defined functional ROIs. Our use of functionally defined ROIs afforded greater sensitivity over standard methods that are based on anatomical averaging.  Gilaie-Dotan et al. (2012)  also looked at individually-defined FFAs and found no relation between CT and car expertise, although their sample was smaller (15 subjects for right FFA). Several other differences could explain why we found effects and they did not; e.g., we defined separate anterior and posterior FFAs and measured behavioral performance for more object categories. Our results suggest that when the peaks of face-selectivity are defined functionally, structural effects may be observed within very small regions centered on these peaks. We found a positive correlation between performance with non-living objects and CT in FFA, whereas the relationship for faces and living objects with CT, when found, was negative. These CT results are generally consistent with past functional results in linking FFA specialization to non-face recognition, but the directions of the effects were unexpected. In addition, we found no evidence of a relation between BOLD responses to cars and faces (relative to birds) and CT in FFA ROIs, but future work should consider using a non-familiar category as baseline to look at the relation between each familiar category and CT measurements. 
 To our knowledge, this is the first study looking at CT separately in the anterior and posterior parts of human FFA ( Pinsk et al. 2009 ;  Weiner et al. 2010 ). We found that behavioral performance with faces has a greater contribution to CT in posterior parts of the FFA bilaterally. However, in none of the FFA ROIs did we find a relationship with face performance  and not  with object performance. The current results present little evidence that any part of the FFA complex is selectively related to face but not object recognition. 
 Our results could be a function of the specific sample used in this study (male subjects, selected on the basis of high or low self-report of car expertise). In prior work, the relation between performance with faces and different object categories was found to be mediated by sex ( McGugin et al. 2012b ). In that work, women outperformed men on the VET-LV factor, whereas men performed better on the VET-NL factor (in this case, vehicles). When age and holistic processing of faces were partialed out, the unique variance explained by each VET factor was correlated with the CFMT, only for the sex-congruent category. Thus, it would be prudent not to generalize the present results to women: it is possible, albeit only a speculation, that the results in a sample of women might be a mirror image of those obtained here for men, with performance for living objects positively correlated with CT but performance for non-living objects negatively correlated with CT. This may also be predicted on the basis of several studies reporting that women show an advantage on verbal tasks with living objects and men for non-living objects ( McKenna and Parry 1994 ;  Laiacona et al. 1998 ;  Capitani et al. 1999 ;  Laws 1999 ). 
 Another consideration is that the functional definition of the FFA was based on a typical localizer that compared images of faces to images of man-made objects (tools, appliances, items of clothing etc). Prior work has suggested that the location of the FFA is not impacted by the type of baseline ( Berman et al. 2010 ), but we do not know of work that has compared localization based on a living vs. non-living comparison. We have no reason to believe that our results would vary if a different localizer was used, especially those effects that were essentially the same in a 1-voxel vs. a 60-voxel ROI. 
 Our findings of a negative correlation between CT and face recognition converge with recent results showing that CT in the FFA was negatively correlated with learning performance on a face orientation judgment task ( Bi et al. 2014 ). We found such a relationship in the right FFA1 (CT negatively correlated with face performance on the CFMT), while the previous work only found the effect in the left FFA (note that this learning study did not separate the two FFAs and used group-averaged ROI definitions). We also found that CT in both parts of the left FFA was negatively related to performance with living objects. Thus, our work considerably extends the Bi et al. finding to face recognition performance, and suggests that such a negative correlation may not be specific to the left FFA, nor to performance with faces. It does not, however, provide insight into the biological mechanism that underlies this negative relationship. Negative correlations with performance have been attributed to synaptic pruning resulting in the loss of non-preferred cortical connections in favor of those that support frequently used skills ( Giedd et al. 1999 ;  Gogtay et al. 2004 ;  Sowell et al. 2004 ). Another possible account is that the observed reduction in measured grey matter reflects an increase in myelination such that white matter growth encroaches upon what was previously classified as grey matter ( Paus 2005 ). This is consistent with recent results showing that fractional anisotropy of the white matter tracts from FFA to the anterior temporal lobe correlate with face recognition ability ( Gomez et al. 2015 ). It is possible that in our sample, those with thinner cortices also had larger white matter tracts connecting FFA to anterior areas. 
 By themselves, none of these accounts is sufficient to explain why the effect differs from the positive relationship obtained with non-living objects. We obtained positive  and  negative relationships with performance in the same subjects in the same areas, which may seem surprising but the multiple regression analyses suggest that the different effects are independent. One possible explanation is that performance with these different categories reflects different ages of acquisition for experience individuating objects (arguably faces, and perhaps also living objects, earlier than vehicles), with different mechanisms of plasticity operating at these different times. Face recognition could be learned early in life when pruning of large fiber tracts is taking place ( Bourgeois et al., 1989 ). In contrast, the recognition of vehicles could be learned much later in life, and as such may show thickening of cortex as in learning of skills in adulthood (e.g.,  Maguire et al., 2003 ;  Mårtensson et al, 2012 ). 
 The relationships we show are not causal: performance with a category would not  cause  CT, nor would CT  cause  performance, but rather it is more plausible that experience with a category would cause both performance and CT. These are conjectures that should be explored in future research. 
 Critically, we find that non-face recognition can be predicted by cortical thickness in the FFA, an effect that cannot be accounted for by attention and providing further evidence that this region is important for non-face object processing. This should not be taken to suggest that other regions in the brain are not also involved in the ability to recognize objects and could also be shaped structurally by such experience. We found only limited replication of the prefrontal areas where CT correlated with car expertise in prior work, but unlike in FFA, we did not have individual functional ROIs to rely on. The effects of experience on brain structure may be variable and require methods that allow for spatial displacement of ROIs across individuals (see also  Pinel et al. 2014 ). Finally, the structural effects of expertise have an interesting advantage over the more standard functional expertise effects: it could lead to a relatively faster accumulation of evidence across different labs, as a VET battery (free and available from authors) can be easily administered to subjects in the lab or online, before or after their participation in any study with a functional FFA localizer. 
 
 
 
 We thank Benjamin J. Tamber-Rosenau and Jennifer J. Richler for assistance. This work was supported by the NSF (SBE-0542013), the Vanderbilt Vision Research Center (P30-EY008126), and the National Eye Institute (R01 EY013441-06A2). 
 
 
 
 1 
 The Grill-Spector study used antique cars in the scanner when subjects were modern car experts (see Bukach et al., 2010 and the Brants study did not provide behavioral evidence for the same qualitative changes in perception as the original study. 
 
 
 
 
 
 
 
 Berman 
 MG 
 
 
 Park 
 J 
 
 
 Gonzalez 
 R 
 
 
 Polk 
 TA 
 
 
 Gehrke 
 A 
 
 
 Knaffla 
 S 
 
 
 Jonides 
 J 
 
 
 2010 
 Evaluating functional localizers: the case of the FFA 
 Neuroimage 
 50 
 56 
 71 
 20025980 
 
 
 
 
 
 
 Bi 
 T 
 
 
 Chen 
 J 
 
 
 Zhou 
 T 
 
 
 He 
 Y 
 
 
 Fang 
 F 
 
 
 2014 
 Function and Structure of Human Left Fusiform Cortex Are Closely Associated with Perceptual Learning of Faces 
 Curr Bio 
 24 
 222 
 227 
 24412207 
 
 
 
 
 
 
 Bilalić 
 M 
 
 
 Langner 
 R 
 
 
 Ulrich 
 R 
 
 
 Grodd 
 W 
 
 
 2011 
 Many Faces of Expertise: Fusiform Face Area in Chess Experts and Novices 
 J Neurosci 
 31 
 10206 
 10214 
 21752997 
 
 
 
 
 
 
 Bourgeois 
 JP 
 
 
 Jastreboff 
 PJ 
 
 
 Rakic 
 P 
 
 
 1989 
 Synaptogenesis in visual cortex of normal and preterm monkeys: evidence for intrinsic regulation of synaptic overproduction 
 Proc Natl Acad Sci USA 
 86 
 4297 
 4301 
 2726773 
 
 
 
 
 
 
 Brainard 
 DH 
 
 
 1997 
 The Psychophysics Toolbox 
 Spat Vis 
 10 
 433 
 436 
 9176952 
 
 
 
 
 
 
 Brants 
 M 
 
 
 Wagemans 
 J 
 
 
 Op de Beeck 
 H 
 
 
 2011 
 Activation of fusiform face area by Greebles is related to face similarity but not expertise 
 J Cogn Neurosci 
 23 
 3929 
 3958 
 
 
 
 
 
 
 Burton 
 MW 
 
 
 Small 
 SL 
 
 
 Blumstein 
 SE 
 
 
 2000 
 The role of segmentation in phonological processing: an fMRI investigation 
 J Cogn Neurosci 
 12 
 679 
 690 
 10936919 
 
 
 
 
 
 
 Capitani 
 E 
 
 
 Laiacona 
 M 
 
 
 Barbarotto 
 R 
 
 
 1999 
 Gender affects word retrieval of certain categories in semantic fluency tasks 
 Cortex 
 35 
 273 
 278 
 10369099 
 
 
 
 
 
 
 Choi 
 Y 
 
 
 Shamosh 
 N 
 
 
 Cho 
 S 
 
 
 DeYoung 
 C 
 
 
 Lee 
 M 
 
 
 Lee 
 J 
 
 
 Kim 
 S 
 
 
 Cho 
 Z 
 
 
 Kim 
 K 
 
 
 Gray 
 J 
 
 
 Lee 
 K 
 
 
 2008 
 Multiple bases of human intelligence revealed by cortical thickness and neural activation 
 J Neurosci 
 28 
 10323 
 10329 
 18842891 
 
 
 
 
 
 
 Curby 
 KM 
 
 
 Glazek 
 K 
 
 
 Gauthier 
 I 
 
 
 2009 
 A visual short-term memory advantage for objects of expertise 
 J Exp Psychol Hum Percept Perform 
 35 
 94 
 107 
 19170473 
 
 
 
 
 
 
 Delon-Martin 
 C 
 
 
 Plailly 
 J 
 
 
 Fonlupt 
 P 
 
 
 Veyrac 
 A 
 
 
 Royet 
 JP 
 
 
 2013 
 Perfumers’ expertise induces structural reorganization in olfactory brain regions 
 NeuroImage 
 68 
 55 
 62 
 23246995 
 
 
 
 
 
 
 Duchaine 
 B 
 
 
 Nakayama 
 K 
 
 
 2006 
 The Cambridge Face Memory Test: results for neurologically intact individuals and an investigation of its validity using inverted face stimuli and prosopagnosic participants 
 Neuropsychologia 
 44 
 576 
 585 
 16169565 
 
 
 
 
 
 
 Foster 
 NEV 
 
 
 Zatorre 
 RJ 
 
 
 2010 
 Cortical structure predicts success in performing musical transformation judgments 
 NeuroImage 
 53 
 26 
 36 
 20600982 
 
 
 
 
 
 
 Frost 
 MA 
 
 
 Goebel 
 R 
 
 
 2012 
 Measuring structural-functional correspondence: spatial variability of specialised brain regions after macro-anatomical alignment 
 Neuroimage 
 59 
 1369 
 1381 
 21875671 
 
 
 
 
 
 
 Garrido 
 L 
 
 
 Furl 
 N 
 
 
 Draganski 
 B 
 
 
 Weiskopf 
 N 
 
 
 Stevens 
 J 
 
 
 Tan 
 GCY 
 
 
 Driver 
 J 
 
 
 Dolan 
 RJ 
 
 
 Duchaine 
 B 
 
 
 2009 
 Voxel-based morphometry reveals reduced grey matter volume in the temporal cortex of developmental prosopagnosics 
 Brain 
 132 
 3443 
 3455 
 19887506 
 
 
 
 
 
 
 Gauthier 
 I 
 
 
 Curby 
 KM 
 
 
 Skudlarski 
 P 
 
 
 Epstein 
 RA 
 
 
 2005 
 Individual differences in FFA activity suggest independent processing at different spatial scales 
 Cogn Affect Behav Neurosci 
 5 
 222 
 234 
 16180628 
 
 
 
 
 
 
 Gauthier 
 I 
 
 
 Skudlarski 
 P 
 
 
 Gore 
 JC 
 
 
 Anderson 
 AW 
 
 
 2000 
 Expertise for cars and birds recruits brain areas involved in face recognition 
 Nat Neurosci 
 3 
 191 
 197 
 10649576 
 
 
 
 
 
 
 Gauthier 
 I 
 
 
 Tarr 
 MJ 
 
 
 1997 
 Becoming a “Greeble” expert: Exploring mechanisms for face recognition 
 Vision Res 
 37 
 1673 
 1682 
 9231232 
 
 
 
 
 
 
 Giedd 
 JN 
 
 
 Blumenthal 
 J 
 
 
 Jeffries 
 NO 
 
 
 Castellanos 
 FX 
 
 
 Liu 
 H 
 
 
 Zijdenbos 
 A 
 
 
 Paus 
 T 
 
 
 Evans 
 AC 
 
 
 Rapoport 
 JL 
 
 
 1999 
 Brain development during childhood and adolescence: a longitudinal MRI study 
 Nat Neurosci 
 2 
 861 
 863 
 10491603 
 
 
 
 
 
 
 Gilaie-Dotan 
 S 
 
 
 Harel 
 A 
 
 
 Bentin 
 S 
 
 
 Kanai 
 R 
 
 
 Rees 
 G 
 
 
 2012 
 Neuroanatomical correlates of visual car expertise 
 NeuroImage 
 62 
 147 
 153 
 22587898 
 
 
 
 
 
 
 Goebel 
 R 
 
 
 Staedtler 
 E 
 
 
 Munk 
 MHJ 
 
 
 Muckli 
 L 
 
 
 2002 
 Cortex-based alignment using functional and structural constraints 
 NeuroImage Supp 
 16 
 10533 
 
 
 
 
 
 
 Goebel 
 R 
 
 
 Hasson 
 U 
 
 
 Harel 
 M 
 
 
 Levy 
 I 
 
 
 Malach 
 R 
 
 
 2004 
 Statistical analyses across aligned cortical hemispheres reveal high-resolution population maps of human visual cortex 
 NeuroImage Supp 
 22 
 e975 
 
 
 
 
 
 
 Goebel 
 R 
 
 
 Esposito 
 F 
 
 
 Formisano 
 E 
 
 
 2006 
 Analysis of functional image analysis contest (FIAC) data with Brainvoyager QX: From single-subject to cortically aligned group general linear model analysis and self-organizing group independent component analysis 
 Human Brain Mapping 
 27 
 392 
 401 
 16596654 
 
 
 
 
 
 
 Gogtay 
 N 
 
 
 Giedd 
 JN 
 
 
 Lusk 
 L 
 
 
 Hayashi 
 KM 
 
 
 Greenstein 
 D 
 
 
 Vaituzis 
 AC 
 
 
 Nugent 
 TF 
 
 
 Herman 
 DH 
 
 
 Clasen 
 LS 
 
 
 Toga 
 AW 
 
 
 2004 
 Dynamic mapping of human cortical development during childhood through early adulthood 
 Proc Natl Acad Sci USA 
 101 
 8174 
 8179 
 15148381 
 
 
 
 
 
 
 Golestani 
 N 
 
 
 Paus 
 T 
 
 
 Zatorre 
 RJ 
 
 
 2002 
 Anatomical correlates of learning novel speech sounds 
 Neuron 
 35 
 997 
 1010 
 12372292 
 
 
 
 
 
 
 Gomez 
 J 
 
 
 
 2015 
 Functionally defined white matter reveals segregated pathways in human ventral temporal cortex associated with category-specific processing 
 Neuron 
 85 
 216 
 227 
 25569351 
 
 
 
 
 
 
 Grill-Spector 
 K 
 
 
 Knouf 
 N 
 
 
 Kanwisher 
 N 
 
 
 2004 
 The fusiform face area subserves face perception, not generic within-category identification 
 Nat Neurosci 
 7 
 555 
 562 
 15077112 
 
 
 
 
 
 
 Grodzinsky 
 Y 
 
 
 Santi 
 A 
 
 
 2008 
 The battle for Broca’s region 
 Trends Cogn Sci 
 12 
 474 
 480 
 18930695 
 
 
 
 
 
 
 Harel 
 A 
 
 
 Gilaie-Dotan 
 S 
 
 
 Malach 
 R 
 
 
 Bentin 
 S 
 
 
 2010 
 Top-Down Engagement Modulates the Neural Expressions of Visual Expertise 
 Cereb Cortex 
 20 
 2304 
 2318 
 20133358 
 
 
 
 
 
 
 Hyde 
 KL 
 
 
 
 2007 
 Cortical thickness in congenital amusia: when less is better than more 
 J Neurosci 
 27 
 13028 
 13032 
 18032676 
 
 
 
 
 
 
 Hyde 
 KL 
 
 
 Zatorre 
 RJ 
 
 
 Griffiths 
 TD 
 
 
 Lerch 
 JP 
 
 
 Peretz 
 I 
 
 
 2006 
 Morphometry of the amusic brain: a two-site study 
 Brain 
 129 
 2562 
 2570 
 16931534 
 
 
 
 
 
 
 Jones 
 SE 
 
 
 Buchbinder 
 BR 
 
 
 Aharon 
 I 
 
 
 2000 
 Three-dimensional mapping of cortical thickness using Laplace’s equation 
 Hum Brain Mapp 
 11 
 12 
 32 
 10997850 
 
 
 
 
 
 
 Jung 
 RE 
 
 
 
 2010 
 Neuroanatomy of creativity 
 Hum Brain Mapp 
 31 
 398 
 409 
 19722171 
 
 
 
 
 
 
 Kanwisher 
 N 
 
 
 2010 
 Functional specificity in the human brain: A window into the functional architecture of the mind 
 Proc Natl Acad Sci USA 
 107 
 11163 
 11170 
 20484679 
 
 
 
 
 
 
 Kanwisher 
 N 
 
 
 McDermott 
 J 
 
 
 Chun 
 MM 
 
 
 1997 
 The fusiform face area: a module in human extrastriate cortex specialized for face perception 
 J Neurosci 
 17 
 4302 
 4311 
 9151747 
 
 
 
 
 
 
 Karama 
 S 
 
 
 Ad-Dab’bagh 
 Y 
 
 
 Haier 
 RJ 
 
 
 Deary 
 IJ 
 
 
 Lyttelton 
 OC 
 
 
 Lepage 
 C 
 
 
 Evans 
 AC 
 
 
 2009 
 Positive association between cognitive ability and cortical thickness in a representative US sample of healthy 6 to 18 year-olds 
 Intelligence 
 37 
 145 
 155 
 20161325 
 
 
 
 
 
 
 Laiacona 
 M 
 
 
 Barbarotto 
 R 
 
 
 Capitani 
 E 
 
 
 1998 
 Semantic category dissociations in naming: is there a gender effect in Alzheimer’s disease? 
 Neuropsychologia 
 36 
 407 
 419 
 9699949 
 
 
 
 
 
 
 Laws 
 KR 
 
 
 1999 
 Gender affects naming latencies for living and nonliving things: implications for familiarity 
 Cortex 
 35 
 729 
 733 
 10656639 
 
 
 
 
 
 
 Maguire 
 EA 
 
 
 Woollett 
 K 
 
 
 Spiers 
 HJ 
 
 
 2006 
 London taxi drivers and bus drivers: a structural MRI and neuropsychological analysis 
 Hippocampus 
 16 
 1091e1101 
 17024677 
 
 
 
 
 
 
 Mårtensson 
 J 
 
 
 Eriksson 
 J 
 
 
 Bodammer 
 NC 
 
 
 Lindgren 
 M 
 
 
 Johansson 
 M 
 
 
 Nyberg 
 L 
 
 
 
 2012 
 Growth of languagerelated brain areas after foreign language learning 
 NeuroImage 
 63 
 240e244 
 22750568 
 
 
 
 
 
 
 McGugin 
 RW 
 
 
 Gatenby 
 C 
 
 
 Gore 
 J 
 
 
 Gauthier 
 I 
 
 
 2012a 
 High-resolution imaging of expertise reveals reliable object selectivity in the FFA related to perceptual performance 
 Proc Natl Acad Sci USA 
 109 
 17063 
 17068 
 23027970 
 
 
 
 
 
 
 McGugin 
 RW 
 
 
 Newton 
 AT 
 
 
 Gore 
 J 
 
 
 Gauthier 
 I 
 
 
 2014a 
 Robust expertise effects in right FFA 
 J Neuropsychol 
 63 
 135 
 144 
 
 
 
 
 
 
 McGugin 
 RW 
 
 
 Richler 
 JJ 
 
 
 Herzmann 
 G 
 
 
 Speegle 
 M 
 
 
 Gauthier 
 I 
 
 
 2012b 
 The Vanderbilt Expertise Test reveals domain-general and domain-specific sex effects in object recognition 
 Vision Res 
 69 
 10 
 22 
 22877929 
 
 
 
 
 
 
 McGugin 
 RW 
 
 
 Van Gulick 
 AE 
 
 
 Tamber-Rosenau 
 BJ 
 
 
 Ross 
 DA 
 
 
 Gauthier 
 I 
 
 
 2014b 
 Expertise effects in face-selective areas are robust to clutter and diverted attention, but not to competition 
 Cereb Cortex 
 10.1093/cercor/bhu060 
 
 
 
 
 
 
 McKenna 
 P 
 
 
 Parry 
 R 
 
 
 1994 
 Category specificity in the naming of natural and man-made objects: Normative data from adults and children 
 Neuropsychol Rehabilitation 
 4 
 255 
 281 
 
 
 
 
 
 
 Narr 
 KL 
 
 
 Woods 
 RP 
 
 
 Thompson 
 PM 
 
 
 Szeszko 
 P 
 
 
 Robinson 
 D 
 
 
 Dimtcheva 
 T 
 
 
 Gurbani 
 M 
 
 
 Toga 
 AW 
 
 
 Bilder 
 RM 
 
 
 2007 
 Relationships between IQ and Regional Cortical Gray Matter Thickness in Healthy Adults 
 Cereb Cortex 
 17 
 2163 
 2171 
 17118969 
 
 
 
 
 
 
 Paus 
 T 
 
 
 2005 
 Mapping brain maturation and cognitive development during adolescence 
 Trends Cogn Sci 
 9 
 60 
 68 
 15668098 
 
 
 
 
 
 
 Pelli 
 DG 
 
 
 1997 
 The VideoToolbox software for visual psychophysics: transforming numbers into movies 
 Spat Vis 
 10 
 437 
 442 
 9176953 
 
 
 
 
 
 
 Pessoa 
 L 
 
 
 Kastner 
 S 
 
 
 Ungerleider 
 LG 
 
 
 2003 
 Neuroimaging studies of attention: from modulation of sensory processing to top-down control 
 J Neurosci 
 23 
 3990 
 3998 
 12764083 
 
 
 
 
 
 
 Pinel 
 P 
 
 
 
 2014 
 Genetic and environmental influences on the visual word from and fusiform face areas 
 Cerebral Cortex 
 10.1093/cercor/bhu048 
 
 
 
 
 
 
 Pinsk 
 MA 
 
 
 Arcaro 
 M 
 
 
 Weiner 
 KS 
 
 
 Kalkus 
 JF 
 
 
 Inati 
 SJ 
 
 
 Gross 
 CG 
 
 
 Kastner 
 S 
 
 
 2009 
 Neural Representations of Faces and Body Parts in Macaque and Human Cortex: A Comparative fMRI Study 
 J Neurophysiol 
 101 
 2581 
 2600 
 19225169 
 
 
 
 
 
 
 Price 
 CJ 
 
 
 Devlin 
 JT 
 
 
 2003 
 The myth of the visual word form area 
 Neuroimage 
 19 
 473 
 481 
 12880781 
 
 
 
 
 
 
 Rossion 
 B 
 
 
 Kung 
 C-C 
 
 
 Tarr 
 MJ 
 
 
 2004 
 Visual expertise with nonface objects leads to competition with the early perceptual processing of faces in the human occipitotemporal cortex 
 Proc Natl Acad Sci USA 
 101 
 14521 
 14526 
 15448209 
 
 
 
 
 
 
 Schneider 
 P 
 
 
 Sluming 
 V 
 
 
 Roberts 
 N 
 
 
 Scherg 
 M 
 
 
 Goebel 
 R 
 
 
 Specht 
 HJ 
 
 
 Dosch 
 HG 
 
 
 Bleeck 
 S 
 
 
 Stippich 
 C 
 
 
 Rupp 
 A 
 
 
 2005 
 Structural and functional asymmetry of lateral Heschl’s gyrus reflects pitch perception preference 
 Nat Neurosci 
 8 
 1241 
 1247 
 16116442 
 
 
 
 
 
 
 Schwarzkopf 
 DS 
 
 
 Song 
 C 
 
 
 Rees 
 G 
 
 
 2011 
 The surface area of human V1 predicts the subjective experience of object size 
 Nat Neurosci 
 14 
 28 
 30 
 21131954 
 
 
 
 
 
 
 Shaw 
 P 
 
 
 Greenstein 
 D 
 
 
 Lerch 
 J 
 
 
 Clasen 
 L 
 
 
 Lenroot 
 R 
 
 
 Gogtay 
 N 
 
 
 Evans 
 A 
 
 
 Rapoport 
 J 
 
 
 Giedd 
 J 
 
 
 2006 
 Intellectual ability and cortical development in children and adolescents 
 Nature 
 440 
 676 
 679 
 16572172 
 
 
 
 
 
 
 Shaw 
 P 
 
 
 
 2008 
 Neurodevelopmental trajectories of the human cerebral cortex 
 J Neurosci 
 28 
 3586 
 3594 
 18385317 
 
 
 
 
 
 
 Shomstein 
 S 
 
 
 Yantis 
 S 
 
 
 2006 
 Parietal cortex mediates voluntary control of spatial and nonspatial auditory attention 
 J Neurosci 
 26 
 435 
 439 
 16407540 
 
 
 
 
 
 
 Sowell 
 ER 
 
 
 Thompson 
 PM 
 
 
 Leonard 
 CM 
 
 
 Welcome 
 SE 
 
 
 Kan 
 E 
 
 
 Toga 
 AW 
 
 
 2004 
 Longitudinal mapping of cortical thickness and brain growth in normal children 
 J Neurosci 
 24 
 8223 
 8231 
 15385605 
 
 
 
 
 
 
 Tarr 
 MJ 
 
 
 Gauthier 
 I 
 
 
 2000 
 FFA: A flexible fusiform area for subordinate-level visual processing automatized by expertise 
 Nat Neurosci 
 3 
 764769 
 
 
 
 
 
 
 Weiner 
 KS 
 
 
 Sayres 
 R 
 
 
 Vinberg 
 J 
 
 
 Grill-Spector 
 K 
 
 
 2010 
 fMRI-adaptation and category selectivity in human ventral temporal cortex: regional differences across time scales 
 J Neurophysiol 
 103 
 3349 
 3365 
 20375251 
 
 
 
 
 
 
 Weiner 
 KS 
 
 
 
 2014 
 The mid-fusiform sulcus: A landmark identifying both cytoarchitectonic and functional divisions of human ventral temporal cortex 
 NeuroImage 
 84 
 453 
 465 
 24021838 
 
 
 
 
 
 
 Wonderlick 
 JS 
 
 
 
 2009 
 Reliability of MRI-derived cortical and subcortical morphometric measures: effects of pulse sequence, voxel geometry, and parallel imagine 
 NeuroImage 
 44 
 1324 
 1333 
 19038349 
 
 
 
 
 
 
 Wong 
 PCM 
 
 
 Warrier 
 CM 
 
 
 Penhune 
 VB 
 
 
 Roy 
 AK 
 
 
 Sadehh 
 A 
 
 
 Parrish 
 TB 
 
 
 Zatorre 
 RJ 
 
 
 2008 
 Volume of left Heschl’s Gyrus and linguistic pitch learning 
 Cereb Cortex 
 18 
 828 
 836 
 17652466 
 
 
 
 
 
 
 Xu 
 Y 
 
 
 2005 
 Revisiting the role of the fusiform face area in visual expertise 
 Cereb Cortex 
 15 
 1234 
 1242 
 15677350 
 
 
 
 
 
 
 Figure 1 
 
 Dotplot depicting the behavioral performance in the CFMT (represented by the face stimulus) and the VET, grouped into VET-living (VET-LV: butterflies, leaves, mushrooms, owls, and wading birds) and VET-non-living (VET-NL: cars, motorcycles, and planes) categories. Each dot represents the accuracy of a given subject, and the horizontal bars represent the mean accuracy across subjects for a given category. The scatterplot to the right shows the relationship between standardized measures of VET-LV and VET-NL. 
 
 
 
 
 Figure 2 
 
 (a) Scatterplots showing the significant partial correlations (regressing out subject age and global cortical thickness) between behavioral performance on faces (CFMT; left) and behavioral performance on non-living object categories (VET-NL; right) with regional CT in rFFA1 and rFFA2, respectively. Colored points in the scatterplots correspond to the individual inflated hemispheres shown in (b). (b) Four inflated right hemispheres, selected to demonstrate the most extreme (thickest or thinnest) FFA cortices as depicted by the scatterplots in (a). Subject-specific maps of cortical thickness are overlaid on the corresponding inflated hemispheres, with functionally-defined face- (FFA1/FFA2/OFA) and object-selective (parahippocampal gyrus, PHG) regions of interest outlined on top of the cortical thickness map. (c) Group-averaged cortical thickness map overlaid on the group-averaged inflated right hemisphere, with group-averaged coordinates for the center of rFFA1, rFFA2 and rOFA overlaid. Also labeled are the occipital temporal sulcus (OTS) and collateral sulcus (CoS). The dashed box represents the field of view for the hemispheres represented in (b). 
 
 
 
 
 Figure 3 
 
 (a) Scatterplots showing the significant partial correlations (regressing out subject age and global cortical thickness) between behavioral performance on living object categories (VET-LV) with regional CT in lFFA1 (left) and lFFA2 (right). Colored points in the scatterplots correspond to colored bars above the individual inflated hemispheres represented in (b). (b) Four inflated left hemispheres, selected to demonstrate the most extreme (thickest or thinnest) FFA cortices as depicted by the scatterplots in (a). Subject-specific maps of cortical thickness are overlaid on the corresponding inflated hemispheres, with functionally-defined face- (FFA1/FFA2/OFA) and object-selective (parahippocampal gyrus, PHG) regions of interest outlined on top of the cortical thickness map. (c) Group-averaged cortical thickness map overlaid on the group-averaged inflated left hemisphere, with group-averaged coordinates for the center of lFFA1, lFFA2 and lOFA overlaid. Also labeled are the occipital temporal sulcus (OTS) and Collateral sulcus (CoS). The dashed box represents the field of view for the hemispheres represented in (b). 
 
 
 
 
 Table 1 
 
 Descriptive statistics. 
 
 
 
 
 
 Average Cortical Thickness (std dev) 
 Range 
 
 
 
 
 Right FFA1 
 2.4 (0.3) 
 1.53 – 2.95 
 
 
 Right FFA2 
 2.7 (0.3) 
 2.17 – 3.58 
 
 
 Right OFA 
 2.4 (0.7) 
 1.75 – 5.05 
 
 
 Right PHG 
 2.4 (0.4) 
 1.38 – 3.25 
 
 
 Left FFA1 
 2.3 (0.4) 
 1.43 – 3.71 
 
 
 Left FFA2 
 2.6 (0.5) 
 1.44 – 3.51 
 
 
 Left OFA 
 2.2 (0.4) 
 1.21 – 3.1 
 
 
 Left PHG 
 2.5 (0.4) 
 1.8 – 3.94 
 
 
 Global CT 
 2.5 (0.3) 
 1.8 – 2.9 
 
 
 Age 
 26 (4.7) 
 18 – 34 
 
 
 
 
 
 
 CFMT_all 
 0.8 (0.1) 
 0.57 – 0.96 
 
 
 VET-LV 
 0.6 (0.1) 
 0.47 – 0.69 
 
 
 VET-NL 
 0.7 (0.1) 
 0.40 – 0.84 
 
 
 Matching-Bird 
 1.3 (0.4) 
 0.56 – 2.14 
 
 
 Matching-Car/Plane 
 0.6 (0.7) 
 −0.54 – 2.17 
 
 
 
 
 
 
 SR-LV 
 2.2 (1) 
 1 – 5.2 
 
 
 SR-NL 
 4.2 (1.7) 
 1 – 7.67 
 
 
 
 
 
 Table 2 
 
 Localization of regions of interest. 
 
 
 
 
 
 N 
 Mean Talairach coordinates for peak face-selective voxel ± SD 
 Face Selectivity (Face – Butterfly) [95% CI] 
 t-test of mean Face-selectivity: t-statistic (p-value) 
 
 
 
 
 Right FFA1 
 26 
 40, −59, −23 (4, 8, 5) 
 0.31 [0.22, 0.40] 
 6.95 (<.0001) 
 
 
 Right FFA2 
 24 
 40, −38, −22 (3, 7, 4) 
 0.28 [0.23, 0.34] 
 9.58 (<.0001) 
 
 
 Right OFA 
 24 
 29, −84, −23 (9, 7, 7) 
 0.17 [0.09, 0.26] 
 4.02 (.0004) 
 
 
 Right PHG 
 27 
 27, −55, −19 (3, 6, 4) 
 −0.23 [−0.26, −0.19] 
 −11.40 (<.0001) 
 
 
 Left FFA1 
 27 
 −39, −59, −24 (4, 8, 5) 
 0.19 [0.12, 0.26] 
 5.00 (<.0001) 
 
 
 Left FFA2 
 24 
 −40, −40, −24 (4, 7, 6) 
 0.18 [0.13, 0.23] 
 6.72 (<.0001) 
 
 
 Left OFA 
 23 
 −34, −80, −24 (9, 8, 5) 
 0.18 [0.08, 0.28] 
 3.55 (.0015) 
 
 
 Left PHG 
 27 
 −29, −53, −19 (4, 7, 4) 
 −0.27 [−0.31, −0.22] 
 −11.64 (<.0001) 
 
 
 
 
 
 Table 3 
 
 Correlations across variables. Top: Zero-order correlations amongst behavioral variables: VET-living (VET-LV), VET-non-living (VET-NL), perceptual matching test with Birds (Match-Bird), average of perceptual matching test with Cars & Planes (Match-Car/Plane), and memory for faces (CFMT). Bottom: Partial correlations between behavior and regional CT with subject age and global CT regressed out. (Note, regressing out age alone did not qualitatively change the results.) Significant correlations (.p<.05) are indicated in bold. We applied FDR corrections (Benjamini & Hochberg, 1995) to each ROI for the three tests entered into multiple regression analyses – VET-LV, VET-NL, and CFMT ( Table 5 ); the VET-NL correlation in rFFA2 failed to pass threshold. 
 
 
 
 
 
 VET-LV 
 VET-NL 
 CFMT 
 Match-Bird 
 Match-Car/Plane 
 
 
 
 
 
 
 
 
 
 
 VET-LV 
 
 – 
 
 
 
 
 
 
 
 VET-NL 
 
 0.27 
 – 
 
 
 
 
 
 
 CFMT 
 
 0.11 
 0.3 
 – 
 
 
 
 
 
 Match-Bird 
 
 0.12 
 −0.06 
 −0.16 
 – 
 
 
 
 
 Match-Car/Plane 
 
 −0.35 
 
 0.55 
 
 0.1 
 0.1 
 – 
 
 
 
 
 
 
 
 
 r FFA1 
 
 0.04 
 0.28 
 
 −0.46 
 
 0.17 
 0.26 
 
 
 
 r FFA2 
 
 −0.07 
 
 0.42 
 
 −0.1 
 0.07 
 
 0.43 
 
 
 
 
 l FFA1 
 
 
 −0.5 
 
 0.17 
 −0.3 
 0.14 
 
 0.58 
 
 
 
 
 l FFA2 
 
 
 −0.68 
 
 0.05 
 −0.18 
 −0.11 
 
 0.53 
 
 
 
 
 r OFA 
 
 −0.25 
 0.02 
 −0.11 
 0.03 
 0.24 
 
 
 
 l OFA 
 
 −0.3 
 −0.08 
 −0.31 
 0.14 
 0.1 
 
 
 
 r PHG 
 
 0.05 
 0.24 
 0.21 
 0.13 
 0.16 
 
 
 
 l PHG 
 
 −0.18 
 −0.05 
 −0.11 
 0.21 
 0.22 
 
 
 
 
 
 
 
 
 
 
 Table 4 
 
 Partial correlations across behavioral measures and anatomically-defined volumes matched with those in which car expertise effects on CT were observed in  Gilaie Dotan et al. (2012) . Regions were defined based on the MNI coordinates (transformed to Talairach using Matlab (MathWorks, Natick, MA)) and sizes reported in  Gilaie Dotan et al. (2012) 
 Table 1  and were identical for all participants. Regions included Left anterior inferior frontal gyrus (l aIFG): Tal (−42, 32, −1), volume (174 mm 3 ); Right inferior precentral sulcus (r IPC): Tal (47, 1, 2), volume (520 mm 3 ); Right superior frontal gyrus (r SFG): Tal (12, 53, 10), volume (47 mm 3 ); Right middle frontal gyrus (r MFG): Tal (29, 18, 37), volume (27 mm 3 ). Behavioral measures included VET-living (VET-LV), VET-non-living (VET-NL) and faces (CFMT). We find a significant correlation between VET-LV and CT in the right SFG region, after we regress out the influence of global CT and age (r=.41, p=.028). 
 
 
 
 
 
 VET-LV 
 VET-NL 
 CFMT 
 
 
 
 
 
 l aIFG 
 
 −0.13 
 −0.13 
 0.24 
 
 
 
 r iPC 
 
 0.19 
 0.22 
 −0.08 
 
 
 
 r MFG 
 
 −0.07 
 −0.22 
 −0.11 
 
 
 
 r SFG 
 
 
 0.41 
 
 0.14 
 0.28 
 
 
 
 
 
 Table 5 
 
 Multiple regressions in the FFAs. 
 
 
 
 
 CT in right FFA1 (age and global CT partialed out) 
 n=25 
 
 
 
 RSq-adj = 33.2% 
 
 
 
 
 
 
 
 
 
 
 
 
 B 
 
 SE 
 
 
 t 
 
 
 p 
 
 
 partial r 
 
 
 0–order r 
 
 
 
 
 
 Intercept 
 −0.0092 
 0.0402 
 −0.229 
 0.821 
 
 
 
 
 CFMT 
 −0.1540 
 0.0445 
 −3.46 
 0.002 
 −0.60* 
 −0.46* 
 
 
 VET LV 
 −0.0005 
 0.0741 
 −0.007 
 0.995 
 0.00   
 0.04   
 
 
 VET NL 
 0.1720 
 0.0655 
 2.63 
 0.016 
 0.50* 
 0.28   
 
 
 
 
 
 
 CT in right FFA2 (age and global CT partialed out) 
 n=26 
 
 
 
 RSq-adj = 13.7% 
 
 
 
 
 
 
 
 
 
 
 
 
 B 
 
 SE 
 
 
 t 
 
 
 p 
 
 
 partial r 
 
 
 0−order r 
 
 
 
 
 
 Intercept 
 0.0033 
 0.0653 
 0.051 
 0.960 
 
 
 
 
 CFMT 
 −0.0846 
 0.0694 
 −1.22 
 0.238 
 −0.10   
 −0.27   
 
 
 VET LV 
 −0.0632 
 0.1261 
 −0.501 
 0.622 
 −0.07   
 −0.11   
 
 
 VET NL 
 0.2620 
 0.1058 
 2.48 
 0.023 
 0.42* 
 0.49* 
 
 
 
 
 
 
 CT in left FFA1 (age and global CT partialed out) 
 n=23 
 
 
 
 RSq-adj = 39.9% 
 
 
 
 
 
 
 
 
 
 
 
 
 B 
 
 SE 
 
 
 t 
 
 
 p 
 
 
 partial r 
 
 
 0-order r 
 
 
 
 
 
 Intercept 
 1.1785 
 0.5287 
 2.23 
 0.036 
 
 
 
 
 CFMT 
 −1.4826 
 0.6598 
 −2.25 
 0.035 
 −0.43* 
 −0.30   
 
 
 VET LV 
 −0.4517 
 0.1261 
 −3.58 
 0.002 
 −0.61* 
 −0.50* 
 
 
 VET NL 
 0.2858 
 0.1119 
 2.56 
 0.018 
 0.48* 
 0.17   
 
 
 
 
 
 
 CT in left FFA2 (age and global CT partialed out) 
 n=23 
 
 
 
 RSq-adj = 42.5% 
 
 
 
 
 
 
 
 
 
 
 
 
 B 
 
 SE 
 
 
 t 
 
 
 p 
 
 
 partial r 
 
 
 0-order r 
 
 
 
 
 
 Intercept 
 0.4692 
 0.5963 
 0.787 
 0.44 
 
 
 
 
 CFMT 
 −0.5700 
 0.7413 
 −0.769 
 0.45 
 −0.17   
 −0.18   
 
 
 VET LV 
 −0.6236 
 0.1486 
 −4.2 
 0.00 
 −0.69* 
 −0.68* 
 
 
 VET NL 
 0.1380 
 0.1277 
 1.08 
 0.29 
 0.24   
 0.05   
 
 
 
 
 
 Table 6 
 
 Correlations of functional selectivity for faces with CT in each ROI (at a size of four 3mm 3  voxels). No correlations reached significance at p<.05. 
 
 
 
 
 
 rFFA1 
 rFFA2 
 lFFA1 
 lFFA2 
 
 
 
 
 fMRI C-B 
 0.04 
 −0.11 
 0.13 
 −0.06 
 
 
 fMRI F-B 
 −0.33 
 −0.12 
 −0.15 
 0.29 
 
 
 
 
 
